<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  Module 3: Concepts and Principles of Machine Learning in Healthcare
  #


  8 The Transformer Architecture for Sequences
  #



  Q1: What is the Transformer architecture and why was it developed?
  #

Transformers were introduced to address the limitations of RNNs, particularly:

Their inability to parallelize training across sequence elements.
Difficulty in learning long-range dependencies.

Transformers revolutionized NLP by enabling faster and more scalable learning on large text datasets.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_8_transformer_architecture_for_sequences/">
  <meta property="og:site_name" content="AI in Healthcare">
  <meta property="og:title" content="AI in Healthcare">
  <meta property="og:description" content="Module 3: Concepts and Principles of Machine Learning in Healthcare # 8 The Transformer Architecture for Sequences # Q1: What is the Transformer architecture and why was it developed? # Transformers were introduced to address the limitations of RNNs, particularly:
Their inability to parallelize training across sequence elements. Difficulty in learning long-range dependencies. Transformers revolutionized NLP by enabling faster and more scalable learning on large text datasets.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="healthcare-domain">
<title>M3 8 Transformer Architecture for Sequences | AI in Healthcare</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="http://localhost:1313/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_8_transformer_architecture_for_sequences/">
<link rel="stylesheet" href="/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.16a93de72023fde77fd06ba72411096c49b011712fd739cbb51d2238937f1402.js" integrity="sha256-Fqk95yAj/ed/0GunJBEJbEmwEXEv1znLtR0iOJN/FAI=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>AI in Healthcare</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>













  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/healthcare-domain/" class="">Healthcare Domain</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-006e92286777b45b0a28d3a2365a3a67" class="toggle" checked />
    <label for="section-006e92286777b45b0a28d3a2365a3a67" class="flex justify-between">
      <a href="/healthcare-domain/learning/" class="">Learning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-85db45cdb58d083b8b67335f89ad3916" class="toggle" checked />
    <label for="section-85db45cdb58d083b8b67335f89ad3916" class="flex justify-between">
      <a href="/healthcare-domain/learning/ai-in-healthcare/" class="">AI in Healthcare</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c1_healthcare/" class="">C1 Introduction to Healthcare</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/" class="">C2 Clinical Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/" class="">C3 ML Healthcare</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_10_advanced_computer_vision_and_wrap_up/" class="">M3 10 Advanced Computer Vision and Wrap Up</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_1_introduction_to_deep_learning_and_neural_networks/" class="">M3 1 Introduction to Deep Learning and Neural Networks</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_2_deep_learning_and_neural_networks/" class="">M3 2 Deep Learning and Neural Networks</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_3_cross_entropy_loss/" class="">M3 3 Cross Entropy Loss</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_4_gradient_descent/" class="">M3 4 Gradient Descent</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_5_representing_unstructured_image_and_text_data/" class="">M3 5 Representing Unstructured Image and Text Data</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_6_convolutional_neural_networks/" class="">M3 6 Convolutional Neural Networks</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_7_nlp_and_recurrent_neural_networks/" class="">M3 7 Nlp and Recurrent Neural Networks</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_8_transformer_architecture_for_sequences/" class="active">M3 8 Transformer Architecture for Sequences</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/m3_9_advanced_neural_network_architectures/" class="">M3 9 Advanced Neural Network Architectures</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/module3_qna_summary/" class="">Module3 Qn a Summary</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/ai-in-healthcare/c4_ai_evaluation/" class="">C4 AI Evaluations</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>C5 Capstone Projects</span>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-317e9b0f08275c48e5b214edfaed8be3" class="toggle"  />
    <label for="section-317e9b0f08275c48e5b214edfaed8be3" class="flex justify-between">
      <a href="/healthcare-domain/learning/causal-inference-rwd/" class="">Causal Inference RWD</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1ec69014a5624ba0393a04a30874fb12" class="toggle"  />
    <label for="section-1ec69014a5624ba0393a04a30874fb12" class="flex justify-between">
      <a href="/healthcare-domain/learning/clinical-data-science/" class="">Clinical Data Science</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-70fa49cb3f8f56f52a5e1b787c860d19" class="toggle"  />
    <label for="section-70fa49cb3f8f56f52a5e1b787c860d19" class="flex justify-between">
      <a href="/healthcare-domain/learning/hands-on-healthcare-data/" class="">Hands-On Healthcare Data</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/hands-on-healthcare-data/ch4_ehr/" class="">Ch4 EHR</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/learning/hands-on-healthcare-data/ch6_graph_ml/" class="">Ch6 ML and Graph Analytics</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-432f1263c64ec7f8147f13ab5b1f0abf" class="toggle"  />
    <label for="section-432f1263c64ec7f8147f13ab5b1f0abf" class="flex justify-between">
      <a href="/healthcare-domain/data/" class="">Healthcare Data</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/data/healthcare_layers/" class="">Healthcare Data Layers</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/data/healthcare_sources/" class="">Healthcare Data Sources</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/terminology/" class="">Healthcare Glossary</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare-domain/tools/" class="">Infromatics Tools</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ai-workflows/" class="">AI Workflows</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-34244c046af3dd0acc0bbb74c663a8d3" class="toggle"  />
    <label for="section-34244c046af3dd0acc0bbb74c663a8d3" class="flex justify-between">
      <a href="/ai-workflows/nlp-llm-genai/" class="">NLP→LLMs→GenAI</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-84a2fcdd2f4a95b774882e612724819f" class="toggle"  />
    <label for="section-84a2fcdd2f4a95b774882e612724819f" class="flex justify-between">
      <a href="/ai-workflows/nlp-llm-genai/5-day-genai-google/" class="">5-Day GenAI with Google</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/nlp-llm-genai/5-day-genai-google/day1_foundational_llm_text_generation/" class="">Day1 Foundational Llm Text Generation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/nlp-llm-genai/5-day-genai-google/day1_prompt_engineering/" class="">Day1 Prompt Engineering</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/nlp-llm-genai/5-day-genai-google/day2_embeddings_vectordb/" class="">Day2 Embeddings Vector Db</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/nlp-llm-genai/5-day-genai-google/day3_generative_agents/" class="">Day3 Generative Agents</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/nlp-llm-genai/5-day-genai-google/day4_domainspecific_llms/" class="">Day4 Domain Specific Llms</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/nlp-llm-genai/5-day-genai-google/day5_mlops/" class="">Day5 Mlops</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-c3b518d59c6ca41d32658ed3b7cde75b" class="toggle"  />
    <label for="section-c3b518d59c6ca41d32658ed3b7cde75b" class="flex justify-between">
      <a href="/ai-workflows/structural-reasoning/" class="">Structural Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-2421eaaa685219c6f46672d27e449bd9" class="toggle"  />
    <label for="section-2421eaaa685219c6f46672d27e449bd9" class="flex justify-between">
      <a href="/ai-workflows/structural-reasoning/causality/" class="">Causality</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/structural-reasoning/causality/causal-ai/" class="">Causal AI</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/structural-reasoning/causality/causal-inference/" class="">Causal Inference</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d6d02c58ad32163fbbfe0ca920604379" class="toggle"  />
    <label for="section-d6d02c58ad32163fbbfe0ca920604379" class="flex justify-between">
      <a role="button" class="">Graphs</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/structural-reasoning/graphs/graphrag/" class="">GraphRAG</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/structural-reasoning/graphs/knowledge-graphs/" class="">Knowledge Graphs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-f57a08bac84df3f46191c3cbf417807e" class="toggle"  />
    <label for="section-f57a08bac84df3f46191c3cbf417807e" class="flex justify-between">
      <a href="/ai-workflows/mlops/" class="">MLOps</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/mlops/ai_cloud_comparision/" class="">Ai Cloud Comparision</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/mlops/clinical_nlp_genai/" class="">Clinical Nlp Gen Ai</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-9320ef7c915cdbbdf424ec3265b5d32b" class="toggle"  />
    <label for="section-9320ef7c915cdbbdf424ec3265b5d32b" class="flex justify-between">
      <a href="/projects/" class="">Projects</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ipark/" class="">Inhee Park, PhD - Resume</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>










  
<ul>
  
  <li>
    <a href="https://www.linkedin.com/in/inheepark/"  target="_blank" rel="noopener">
        ╰──LinkedIn
      </a>
  </li>
  
  <li>
    <a href="https://github.com/imipark/"  target="_blank" rel="noopener">
        ╰──GitHub
      </a>
  </li>
  
  <li>
    <a href="/posts/"  target="_blank" rel="noopener">
        ╰──Blog
      </a>
  </li>
  
  <li>
    <a href="https://iparkirk.github.io"  target="_blank" rel="noopener">
        ╰──Old Web
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>M3 8 Transformer Architecture for Sequences</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#module-3-concepts-and-principles-of-machine-learning-in-healthcare">Module 3: Concepts and Principles of Machine Learning in Healthcare</a>
      <ul>
        <li><a href="#8-the-transformer-architecture-for-sequences">8 The Transformer Architecture for Sequences</a>
          <ul>
            <li><a href="#q1-what-is-the-transformer-architecture-and-why-was-it-developed"><strong>Q1: What is the Transformer architecture and why was it developed?</strong></a></li>
            <li><a href="#q2-what-is-self-attention-and-how-does-it-work-in-transformers"><strong>Q2: What is self-attention and how does it work in Transformers?</strong></a></li>
            <li><a href="#q3-how-do-transformers-handle-the-order-of-tokens-in-a-sequence"><strong>Q3: How do Transformers handle the order of tokens in a sequence?</strong></a></li>
            <li><a href="#q4-what-are-the-key-components-of-a-transformer-architecture"><strong>Q4: What are the key components of a Transformer architecture?</strong></a></li>
            <li><a href="#q5-how-are-transformers-used-in-healthcare-applications"><strong>Q5: How are Transformers used in healthcare applications?</strong></a></li>
            <li><a href="#-key-takeaways">🔑 <strong>Key Takeaways</strong>:</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="module-3-concepts-and-principles-of-machine-learning-in-healthcare">
  Module 3: Concepts and Principles of Machine Learning in Healthcare
  <a class="anchor" href="#module-3-concepts-and-principles-of-machine-learning-in-healthcare">#</a>
</h1>
<h2 id="8-the-transformer-architecture-for-sequences">
  8 The Transformer Architecture for Sequences
  <a class="anchor" href="#8-the-transformer-architecture-for-sequences">#</a>
</h2>
<hr>
<h3 id="q1-what-is-the-transformer-architecture-and-why-was-it-developed">
  <strong>Q1: What is the Transformer architecture and why was it developed?</strong>
  <a class="anchor" href="#q1-what-is-the-transformer-architecture-and-why-was-it-developed">#</a>
</h3>
<p>Transformers were introduced to address the limitations of RNNs, particularly:</p>
<ul>
<li>Their <strong>inability to parallelize</strong> training across sequence elements.</li>
<li>Difficulty in learning <strong>long-range dependencies</strong>.</li>
</ul>
<p>Transformers revolutionized NLP by enabling faster and more scalable learning on large text datasets.</p>
<p>-&gt; What is the core mechanism that allows Transformers to process sequences?</p>
<hr>
<h3 id="q2-what-is-self-attention-and-how-does-it-work-in-transformers">
  <strong>Q2: What is self-attention and how does it work in Transformers?</strong>
  <a class="anchor" href="#q2-what-is-self-attention-and-how-does-it-work-in-transformers">#</a>
</h3>
<p>Self-attention enables the model to <strong>weigh the importance of each word</strong> in a sequence relative to others:</p>
<ul>
<li>Every word attends to every other word, regardless of position.</li>
<li>Enables context-rich representations.</li>
<li>Allows learning dependencies without relying on sequence order.</li>
</ul>
<p>-&gt; Without a sequential structure, how do Transformers know the order of inputs?</p>
<hr>
<h3 id="q3-how-do-transformers-handle-the-order-of-tokens-in-a-sequence">
  <strong>Q3: How do Transformers handle the order of tokens in a sequence?</strong>
  <a class="anchor" href="#q3-how-do-transformers-handle-the-order-of-tokens-in-a-sequence">#</a>
</h3>
<p>Transformers use <strong>positional encoding</strong> to inject information about token positions:</p>
<ul>
<li>Adds sine and cosine-based vectors to embeddings.</li>
<li>Ensures the model retains <strong>positional context</strong>.</li>
<li>Critical for meaning in structured sequences like clinical narratives.</li>
</ul>
<p>-&gt; How are Transformers structured beyond attention?</p>
<hr>
<h3 id="q4-what-are-the-key-components-of-a-transformer-architecture">
  <strong>Q4: What are the key components of a Transformer architecture?</strong>
  <a class="anchor" href="#q4-what-are-the-key-components-of-a-transformer-architecture">#</a>
</h3>
<p>Each Transformer block includes:</p>
<ul>
<li><strong>Multi-head self-attention</strong>: Captures diverse relational patterns.</li>
<li><strong>Feedforward layers</strong>: Add non-linearity and depth.</li>
<li><strong>Layer normalization and residual connections</strong>: Stabilize training and enable deeper networks.</li>
</ul>
<p>Stacks of these blocks form powerful encoders and decoders for various tasks.</p>
<p>-&gt; What has the impact of Transformers been in healthcare?</p>
<hr>
<h3 id="q5-how-are-transformers-used-in-healthcare-applications">
  <strong>Q5: How are Transformers used in healthcare applications?</strong>
  <a class="anchor" href="#q5-how-are-transformers-used-in-healthcare-applications">#</a>
</h3>
<p>Transformers have enabled:</p>
<ul>
<li><strong>Clinical language models</strong> like ClinicalBERT.</li>
<li><strong>De-identification</strong>, <strong>ICD code prediction</strong>, <strong>note summarization</strong>.</li>
<li>Strong results in text-heavy workflows like billing, research, and patient monitoring.</li>
</ul>
<hr>
<h3 id="-key-takeaways">
  🔑 <strong>Key Takeaways</strong>:
  <a class="anchor" href="#-key-takeaways">#</a>
</h3>
<ul>
<li>Transformers replaced RNNs as the dominant architecture for sequence modeling.</li>
<li>Self-attention allows parallelism and rich context learning.</li>
<li>Positional encodings inject order into non-sequential data.</li>
<li>Used extensively in clinical NLP through pretrained models and fine-tuning.</li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#module-3-concepts-and-principles-of-machine-learning-in-healthcare">Module 3: Concepts and Principles of Machine Learning in Healthcare</a>
      <ul>
        <li><a href="#8-the-transformer-architecture-for-sequences">8 The Transformer Architecture for Sequences</a>
          <ul>
            <li><a href="#q1-what-is-the-transformer-architecture-and-why-was-it-developed"><strong>Q1: What is the Transformer architecture and why was it developed?</strong></a></li>
            <li><a href="#q2-what-is-self-attention-and-how-does-it-work-in-transformers"><strong>Q2: What is self-attention and how does it work in Transformers?</strong></a></li>
            <li><a href="#q3-how-do-transformers-handle-the-order-of-tokens-in-a-sequence"><strong>Q3: How do Transformers handle the order of tokens in a sequence?</strong></a></li>
            <li><a href="#q4-what-are-the-key-components-of-a-transformer-architecture"><strong>Q4: What are the key components of a Transformer architecture?</strong></a></li>
            <li><a href="#q5-how-are-transformers-used-in-healthcare-applications"><strong>Q5: How are Transformers used in healthcare applications?</strong></a></li>
            <li><a href="#-key-takeaways">🔑 <strong>Key Takeaways</strong>:</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












