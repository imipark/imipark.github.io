<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="


Data Curation and LLMs 




  Q1: What is the background of LLMs discussed?
  #


LLMs like ChatGPT, GPT-4, and Llama are sequence models trained to predict the next token.
They use unsupervised pre-training on massive internet-scale corpora and can solve various NLP tasks.


  Q2: What are the applications of LLMs discussed?
  #


Zero-shot prompting
Few-shot prompting


  Q3: What is the focus of this lecture?
  #


Using LLMs for data curation
Evaluating LLM output data
Curation for LLM pre-training and application fine-tuning


  Q4: How are LLMs used for data curation?
  #


They act as powerful, flexible, and computationally inexpensive reasoning engines for text data curation.


  Q5: How was PII detection handled traditionally vs with LLMs?
  #


Traditional: Custom regex rules.
With LLMs: Zero-shot prompting to detect a wider range of PII without needing extensive rule-writing.


  Q6: How can grammar checking be improved with LLMs?
  #


Traditional: Rule-based systems like LanguageTool.
LLM-based: Fine-tuning LLMs on curated grammatical acceptability datasets like CoLA.


  Q7: What is a major challenge in working with LLM outputs?
  #


Hallucinations, where LLMs produce confidently incorrect information.


  Q8: How can we evaluate LLM outputs more reliably?
  #


Use a stronger LLM (e.g., GPT-4) to judge the outputs of weaker LLMs.


  Q9: What evidence supports LLM-based evaluation?
  #


AlpaGasus fine-tuning project showed better results by curating higher-quality data points evaluated by GPT-3.5 and GPT-4.


  Q10: What is the challenge of using LLMs to evaluate other LLMs?
  #


It risks circular evaluation (turtles all the way down) if the same LLMs are involved in both generation and evaluation.


  Q11: What method helps with LLM uncertainty quantification?
  #


Natural Language Inference (NLI)-based techniques that check for answer contradictions.


  Q12: What are the key stages of data curation for LLM pre-training?
  #


Focus on corpus quality because errors are difficult to &ldquo;un-learn.&rdquo;
Use supervised fine-tuning and reinforcement learning from human feedback.


  Q13: How does data curation differ for LLM applications?
  #


Zero-shot prompting
Few-shot prompting
Retrieval-augmented generation
Supervised fine-tuning


  Q14: Why is fine-tuning important for LLM applications?
  #


Fine-tuning provides the best task-specific performance.
It enables training smaller models to match large model performance through synthetic data generation.


  Q15: How is synthetic data curated for LLM fine-tuning?
  #


Generate synthetic data using a powerful LLM.
Use uncertainty quantification to retain only high-confidence examples.
Train classifiers to filter out unrealistic synthetic data.


  Q16: What is the future trend in data curation for LLMs?
  #


Growth of powerful multi-modal LLMs and new tools like CleanVision and GPT-4 to automate and improve data quality.



  References
  #


Karpathy on LLM prompting
Scrubadub for regex-based PII detection
LanguageTool grammar checker
CoLA dataset
AlpaGasus paper
Trustworthy Language Models (TLM)
Textbooks Are All You Need (Li et al., 2023)
Stanford Alpaca project
CleanVision project
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://imipark.github.io/ai-workflows/data/data-centric-ai/data-curation-llms/">
  <meta property="og:site_name" content="AI Reasoning">
  <meta property="og:title" content="Data Curation and LLMs">
  <meta property="og:description" content="Data Curation and LLMs Q1: What is the background of LLMs discussed? # LLMs like ChatGPT, GPT-4, and Llama are sequence models trained to predict the next token. They use unsupervised pre-training on massive internet-scale corpora and can solve various NLP tasks. Q2: What are the applications of LLMs discussed? # Zero-shot prompting Few-shot prompting Q3: What is the focus of this lecture? # Using LLMs for data curation Evaluating LLM output data Curation for LLM pre-training and application fine-tuning Q4: How are LLMs used for data curation? # They act as powerful, flexible, and computationally inexpensive reasoning engines for text data curation. Q5: How was PII detection handled traditionally vs with LLMs? # Traditional: Custom regex rules. With LLMs: Zero-shot prompting to detect a wider range of PII without needing extensive rule-writing. Q6: How can grammar checking be improved with LLMs? # Traditional: Rule-based systems like LanguageTool. LLM-based: Fine-tuning LLMs on curated grammatical acceptability datasets like CoLA. Q7: What is a major challenge in working with LLM outputs? # Hallucinations, where LLMs produce confidently incorrect information. Q8: How can we evaluate LLM outputs more reliably? # Use a stronger LLM (e.g., GPT-4) to judge the outputs of weaker LLMs. Q9: What evidence supports LLM-based evaluation? # AlpaGasus fine-tuning project showed better results by curating higher-quality data points evaluated by GPT-3.5 and GPT-4. Q10: What is the challenge of using LLMs to evaluate other LLMs? # It risks circular evaluation (turtles all the way down) if the same LLMs are involved in both generation and evaluation. Q11: What method helps with LLM uncertainty quantification? # Natural Language Inference (NLI)-based techniques that check for answer contradictions. Q12: What are the key stages of data curation for LLM pre-training? # Focus on corpus quality because errors are difficult to “un-learn.” Use supervised fine-tuning and reinforcement learning from human feedback. Q13: How does data curation differ for LLM applications? # Zero-shot prompting Few-shot prompting Retrieval-augmented generation Supervised fine-tuning Q14: Why is fine-tuning important for LLM applications? # Fine-tuning provides the best task-specific performance. It enables training smaller models to match large model performance through synthetic data generation. Q15: How is synthetic data curated for LLM fine-tuning? # Generate synthetic data using a powerful LLM. Use uncertainty quantification to retain only high-confidence examples. Train classifiers to filter out unrealistic synthetic data. Q16: What is the future trend in data curation for LLMs? # Growth of powerful multi-modal LLMs and new tools like CleanVision and GPT-4 to automate and improve data quality. References # Karpathy on LLM prompting Scrubadub for regex-based PII detection LanguageTool grammar checker CoLA dataset AlpaGasus paper Trustworthy Language Models (TLM) Textbooks Are All You Need (Li et al., 2023) Stanford Alpaca project CleanVision project">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="ai-workflows">
<title>Data Curation and LLMs | AI Reasoning</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="https://imipark.github.io/ai-workflows/data/data-centric-ai/data-curation-llms/">
<link rel="stylesheet" href="/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.4ddc672eeb84245fa7864c180b2b6afa0c779ad1eedcf805d6cdf4d6d9e1195c.js" integrity="sha256-TdxnLuuEJF&#43;nhkwYCytq&#43;gx3mtHu3PgF1s301tnhGVw=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>AI Reasoning</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>













  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ai-workflows/" class="">AI Reasoning Stack</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7f3f4cf59430750c2ad109248c8c879b" class="toggle" checked />
    <label for="section-7f3f4cf59430750c2ad109248c8c879b" class="flex justify-between">
      <a href="/ai-workflows/data/" class="">Data</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fc566bddf8394fb4d0c5cff688d2febc" class="toggle" checked />
    <label for="section-fc566bddf8394fb4d0c5cff688d2febc" class="flex justify-between">
      <a href="/ai-workflows/data/data-centric-ai/" class="">Data-Centric AI (DCAI)</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cff08f084db31c8732ef81d1fe1c4130" class="toggle"  />
    <label for="section-cff08f084db31c8732ef81d1fe1c4130" class="flex justify-between">
      <a href="/ai-workflows/genai/" class="">GenAI</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-63b806a012c3062adb6281022ca8468f" class="toggle"  />
    <label for="section-63b806a012c3062adb6281022ca8468f" class="flex justify-between">
      <a href="/ai-workflows/genai/5-day-genai-google-2025/" class="">5-Day GenAI with Google 2005</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day1_foundational_llm_text_generation/" class="">Day 1 - Foundational LLMs &amp; Text Generation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day1_prompt_engineering/" class="">Day 1 – Prompt Engineering</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day2_embeddings_vectordb/" class="">Day 2 – Embeddings &amp; Vector Databases</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day3_generative_agents/" class="">Day 3 – Generative Agents</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day4_domainspecific_llms/" class="">Day 4 – Domain-Specific LLMs</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day5_mlops/" class="">Day 5 – MLOps for Generative AI</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/multimodel_llms/" class="">Multimodal LLMs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-17ba62e37c896ad50105fedeb71549dd" class="toggle"  />
    <label for="section-17ba62e37c896ad50105fedeb71549dd" class="flex justify-between">
      <a href="/ai-workflows/reasoning/" class="">Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cd94e161670d28ecff992edf840d76e8" class="toggle"  />
    <label for="section-cd94e161670d28ecff992edf840d76e8" class="flex justify-between">
      <a href="/ai-workflows/reasoning/causality/" class="">Causality</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-ai/" class="">Causal AI</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-inference/" class="">Causal Inference</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7e468aa05ceb7c844f07a2e754606b76" class="toggle"  />
    <label for="section-7e468aa05ceb7c844f07a2e754606b76" class="flex justify-between">
      <a href="/ai-workflows/reasoning/graph-reasoning/" class="">Graph Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/graphrag/" class="">GraphRAG</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/knowledge-graphs/" class="">Knowledge Graphs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="toggle"  />
    <label for="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="flex justify-between">
      <a href="/ai-workflows/rlhf/" class="">RLHF</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b1afcafdefac57f3420f64e23d73f05d" class="toggle"  />
    <label for="section-b1afcafdefac57f3420f64e23d73f05d" class="flex justify-between">
      <a href="/ai-workflows/rlhf/rlhf2006/" class="">RLHF 2006</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/rlhf/rlhf2006/instruct_gpt_codes_params/" class="">Instruct Gpt Codes Params</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ca53d32fab0e1a54fdf5627349d86bfc" class="toggle"  />
    <label for="section-ca53d32fab0e1a54fdf5627349d86bfc" class="flex justify-between">
      <a href="/ai-workflows/eval/" class="">Eval</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/healthcare/" class="">Healthcare</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="toggle"  />
    <label for="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/" class="">Domain</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-45ba5974905f86df95925365835eadbb" class="toggle"  />
    <label for="section-45ba5974905f86df95925365835eadbb" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/ai-in-healthcare/" class="">AI in Healthcare</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/" class="">C2 Clinical Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/" class="">C3 ML Healthcare</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/" class="">C4 AI Evaluations</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c5_capstone/" class="">C5 Capstone Projects</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9722ba71bf098ab02c3220d6e8d9056f" class="toggle"  />
    <label for="section-9722ba71bf098ab02c3220d6e8d9056f" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/hands-on-healthcare-data/" class="">Hands-On Healthcare Data</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/data/" class="">Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/clinical_ai/" class="">AI Applications</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ipark/" class="">Inhee Park, PhD - Resume</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>










  
<ul>
  
  <li>
    <a href="https://www.linkedin.com/in/inheepark/"  target="_blank" rel="noopener">
        ╰──LinkedIn
      </a>
  </li>
  
  <li>
    <a href="https://github.com/imipark/"  target="_blank" rel="noopener">
        ╰──GitHub
      </a>
  </li>
  
  <li>
    <a href="/posts/"  target="_blank" rel="noopener">
        ╰──Blog
      </a>
  </li>
  
  <li>
    <a href="https://iparkirk.github.io"  target="_blank" rel="noopener">
        ╰──Old Web
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Data Curation and LLMs</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#q1-what-is-the-background-of-llms-discussed">Q1: What is the background of LLMs discussed?</a></li>
            <li><a href="#q2-what-are-the-applications-of-llms-discussed">Q2: What are the applications of LLMs discussed?</a></li>
            <li><a href="#q3-what-is-the-focus-of-this-lecture">Q3: What is the focus of this lecture?</a></li>
            <li><a href="#q4-how-are-llms-used-for-data-curation">Q4: How are LLMs used for data curation?</a></li>
            <li><a href="#q5-how-was-pii-detection-handled-traditionally-vs-with-llms">Q5: How was PII detection handled traditionally vs with LLMs?</a></li>
            <li><a href="#q6-how-can-grammar-checking-be-improved-with-llms">Q6: How can grammar checking be improved with LLMs?</a></li>
            <li><a href="#q7-what-is-a-major-challenge-in-working-with-llm-outputs">Q7: What is a major challenge in working with LLM outputs?</a></li>
            <li><a href="#q8-how-can-we-evaluate-llm-outputs-more-reliably">Q8: How can we evaluate LLM outputs more reliably?</a></li>
            <li><a href="#q9-what-evidence-supports-llm-based-evaluation">Q9: What evidence supports LLM-based evaluation?</a></li>
            <li><a href="#q10-what-is-the-challenge-of-using-llms-to-evaluate-other-llms">Q10: What is the challenge of using LLMs to evaluate other LLMs?</a></li>
            <li><a href="#q11-what-method-helps-with-llm-uncertainty-quantification">Q11: What method helps with LLM uncertainty quantification?</a></li>
            <li><a href="#q12-what-are-the-key-stages-of-data-curation-for-llm-pre-training">Q12: What are the key stages of data curation for LLM pre-training?</a></li>
            <li><a href="#q13-how-does-data-curation-differ-for-llm-applications">Q13: How does data curation differ for LLM applications?</a></li>
            <li><a href="#q14-why-is-fine-tuning-important-for-llm-applications">Q14: Why is fine-tuning important for LLM applications?</a></li>
            <li><a href="#q15-how-is-synthetic-data-curated-for-llm-fine-tuning">Q15: How is synthetic data curated for LLM fine-tuning?</a></li>
            <li><a href="#q16-what-is-the-future-trend-in-data-curation-for-llms">Q16: What is the future trend in data curation for LLMs?</a></li>
            <li><a href="#references">References</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><p align="center">
<img src="/images/AIR_logo.png" alt="AI Reasoning Logo" width="200"/>
<strong style="font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;">
Data Curation and LLMs 
</strong>
</p>
<hr>
<h3 id="q1-what-is-the-background-of-llms-discussed">
  Q1: What is the background of LLMs discussed?
  <a class="anchor" href="#q1-what-is-the-background-of-llms-discussed">#</a>
</h3>
<ul>
<li>LLMs like ChatGPT, GPT-4, and Llama are sequence models trained to predict the next token.</li>
<li>They use unsupervised pre-training on massive internet-scale corpora and can solve various NLP tasks.</li>
</ul>
<h3 id="q2-what-are-the-applications-of-llms-discussed">
  Q2: What are the applications of LLMs discussed?
  <a class="anchor" href="#q2-what-are-the-applications-of-llms-discussed">#</a>
</h3>
<ul>
<li>Zero-shot prompting</li>
<li>Few-shot prompting</li>
</ul>
<h3 id="q3-what-is-the-focus-of-this-lecture">
  Q3: What is the focus of this lecture?
  <a class="anchor" href="#q3-what-is-the-focus-of-this-lecture">#</a>
</h3>
<ul>
<li>Using LLMs for data curation</li>
<li>Evaluating LLM output data</li>
<li>Curation for LLM pre-training and application fine-tuning</li>
</ul>
<h3 id="q4-how-are-llms-used-for-data-curation">
  Q4: How are LLMs used for data curation?
  <a class="anchor" href="#q4-how-are-llms-used-for-data-curation">#</a>
</h3>
<ul>
<li>They act as powerful, flexible, and computationally inexpensive reasoning engines for text data curation.</li>
</ul>
<h3 id="q5-how-was-pii-detection-handled-traditionally-vs-with-llms">
  Q5: How was PII detection handled traditionally vs with LLMs?
  <a class="anchor" href="#q5-how-was-pii-detection-handled-traditionally-vs-with-llms">#</a>
</h3>
<ul>
<li>Traditional: Custom regex rules.</li>
<li>With LLMs: Zero-shot prompting to detect a wider range of PII without needing extensive rule-writing.</li>
</ul>
<h3 id="q6-how-can-grammar-checking-be-improved-with-llms">
  Q6: How can grammar checking be improved with LLMs?
  <a class="anchor" href="#q6-how-can-grammar-checking-be-improved-with-llms">#</a>
</h3>
<ul>
<li>Traditional: Rule-based systems like LanguageTool.</li>
<li>LLM-based: Fine-tuning LLMs on curated grammatical acceptability datasets like CoLA.</li>
</ul>
<h3 id="q7-what-is-a-major-challenge-in-working-with-llm-outputs">
  Q7: What is a major challenge in working with LLM outputs?
  <a class="anchor" href="#q7-what-is-a-major-challenge-in-working-with-llm-outputs">#</a>
</h3>
<ul>
<li>Hallucinations, where LLMs produce confidently incorrect information.</li>
</ul>
<h3 id="q8-how-can-we-evaluate-llm-outputs-more-reliably">
  Q8: How can we evaluate LLM outputs more reliably?
  <a class="anchor" href="#q8-how-can-we-evaluate-llm-outputs-more-reliably">#</a>
</h3>
<ul>
<li>Use a stronger LLM (e.g., GPT-4) to judge the outputs of weaker LLMs.</li>
</ul>
<h3 id="q9-what-evidence-supports-llm-based-evaluation">
  Q9: What evidence supports LLM-based evaluation?
  <a class="anchor" href="#q9-what-evidence-supports-llm-based-evaluation">#</a>
</h3>
<ul>
<li>AlpaGasus fine-tuning project showed better results by curating higher-quality data points evaluated by GPT-3.5 and GPT-4.</li>
</ul>
<h3 id="q10-what-is-the-challenge-of-using-llms-to-evaluate-other-llms">
  Q10: What is the challenge of using LLMs to evaluate other LLMs?
  <a class="anchor" href="#q10-what-is-the-challenge-of-using-llms-to-evaluate-other-llms">#</a>
</h3>
<ul>
<li>It risks circular evaluation (turtles all the way down) if the same LLMs are involved in both generation and evaluation.</li>
</ul>
<h3 id="q11-what-method-helps-with-llm-uncertainty-quantification">
  Q11: What method helps with LLM uncertainty quantification?
  <a class="anchor" href="#q11-what-method-helps-with-llm-uncertainty-quantification">#</a>
</h3>
<ul>
<li>Natural Language Inference (NLI)-based techniques that check for answer contradictions.</li>
</ul>
<h3 id="q12-what-are-the-key-stages-of-data-curation-for-llm-pre-training">
  Q12: What are the key stages of data curation for LLM pre-training?
  <a class="anchor" href="#q12-what-are-the-key-stages-of-data-curation-for-llm-pre-training">#</a>
</h3>
<ul>
<li>Focus on corpus quality because errors are difficult to &ldquo;un-learn.&rdquo;</li>
<li>Use supervised fine-tuning and reinforcement learning from human feedback.</li>
</ul>
<h3 id="q13-how-does-data-curation-differ-for-llm-applications">
  Q13: How does data curation differ for LLM applications?
  <a class="anchor" href="#q13-how-does-data-curation-differ-for-llm-applications">#</a>
</h3>
<ul>
<li>Zero-shot prompting</li>
<li>Few-shot prompting</li>
<li>Retrieval-augmented generation</li>
<li>Supervised fine-tuning</li>
</ul>
<h3 id="q14-why-is-fine-tuning-important-for-llm-applications">
  Q14: Why is fine-tuning important for LLM applications?
  <a class="anchor" href="#q14-why-is-fine-tuning-important-for-llm-applications">#</a>
</h3>
<ul>
<li>Fine-tuning provides the best task-specific performance.</li>
<li>It enables training smaller models to match large model performance through synthetic data generation.</li>
</ul>
<h3 id="q15-how-is-synthetic-data-curated-for-llm-fine-tuning">
  Q15: How is synthetic data curated for LLM fine-tuning?
  <a class="anchor" href="#q15-how-is-synthetic-data-curated-for-llm-fine-tuning">#</a>
</h3>
<ul>
<li>Generate synthetic data using a powerful LLM.</li>
<li>Use uncertainty quantification to retain only high-confidence examples.</li>
<li>Train classifiers to filter out unrealistic synthetic data.</li>
</ul>
<h3 id="q16-what-is-the-future-trend-in-data-curation-for-llms">
  Q16: What is the future trend in data curation for LLMs?
  <a class="anchor" href="#q16-what-is-the-future-trend-in-data-curation-for-llms">#</a>
</h3>
<ul>
<li>Growth of powerful multi-modal LLMs and new tools like CleanVision and GPT-4 to automate and improve data quality.</li>
</ul>
<hr>
<h3 id="references">
  References
  <a class="anchor" href="#references">#</a>
</h3>
<ul>
<li><a href="https://twitter.com/karpathy/status/1654892810590650376">Karpathy on LLM prompting</a></li>
<li><a href="https://github.com/LeapBeyond/scrubadub">Scrubadub for regex-based PII detection</a></li>
<li><a href="https://github.com/languagetool-org/languagetool">LanguageTool grammar checker</a></li>
<li><a href="https://nyu-mll.github.io/CoLA/">CoLA dataset</a></li>
<li><a href="https://arxiv.org/pdf/2307.08701.pdf">AlpaGasus paper</a></li>
<li><a href="https://arxiv.org/pdf/2308.16175.pdf">Trustworthy Language Models (TLM)</a></li>
<li><a href="https://arxiv.org/abs/2309.05463">Textbooks Are All You Need (Li et al., 2023)</a></li>
<li><a href="https://github.com/tatsu-lab/stanford_alpaca">Stanford Alpaca project</a></li>
<li><a href="https://github.com/cleanlab/cleanvision">CleanVision project</a></li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#q1-what-is-the-background-of-llms-discussed">Q1: What is the background of LLMs discussed?</a></li>
            <li><a href="#q2-what-are-the-applications-of-llms-discussed">Q2: What are the applications of LLMs discussed?</a></li>
            <li><a href="#q3-what-is-the-focus-of-this-lecture">Q3: What is the focus of this lecture?</a></li>
            <li><a href="#q4-how-are-llms-used-for-data-curation">Q4: How are LLMs used for data curation?</a></li>
            <li><a href="#q5-how-was-pii-detection-handled-traditionally-vs-with-llms">Q5: How was PII detection handled traditionally vs with LLMs?</a></li>
            <li><a href="#q6-how-can-grammar-checking-be-improved-with-llms">Q6: How can grammar checking be improved with LLMs?</a></li>
            <li><a href="#q7-what-is-a-major-challenge-in-working-with-llm-outputs">Q7: What is a major challenge in working with LLM outputs?</a></li>
            <li><a href="#q8-how-can-we-evaluate-llm-outputs-more-reliably">Q8: How can we evaluate LLM outputs more reliably?</a></li>
            <li><a href="#q9-what-evidence-supports-llm-based-evaluation">Q9: What evidence supports LLM-based evaluation?</a></li>
            <li><a href="#q10-what-is-the-challenge-of-using-llms-to-evaluate-other-llms">Q10: What is the challenge of using LLMs to evaluate other LLMs?</a></li>
            <li><a href="#q11-what-method-helps-with-llm-uncertainty-quantification">Q11: What method helps with LLM uncertainty quantification?</a></li>
            <li><a href="#q12-what-are-the-key-stages-of-data-curation-for-llm-pre-training">Q12: What are the key stages of data curation for LLM pre-training?</a></li>
            <li><a href="#q13-how-does-data-curation-differ-for-llm-applications">Q13: How does data curation differ for LLM applications?</a></li>
            <li><a href="#q14-why-is-fine-tuning-important-for-llm-applications">Q14: Why is fine-tuning important for LLM applications?</a></li>
            <li><a href="#q15-how-is-synthetic-data-curated-for-llm-fine-tuning">Q15: How is synthetic data curated for LLM fine-tuning?</a></li>
            <li><a href="#q16-what-is-the-future-trend-in-data-curation-for-llms">Q16: What is the future trend in data curation for LLMs?</a></li>
            <li><a href="#references">References</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












