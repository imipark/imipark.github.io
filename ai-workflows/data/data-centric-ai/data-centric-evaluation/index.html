<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="


Data-Centric Evaluation of ML Models 



Instead of only asking how accurate, we ask why and where does the model fail ‚Äî and whether the data itself causes it.


  
      
          Aspect
          Model-Centric Evaluation
          Data-Centric Evaluation
      
  
  
      
          Focus
          Overall model score
          Specific weaknesses tied to data
      
      
          Metrics
          Accuracy, ROC, etc.
          Slice-specific accuracy, Error analysis
      
      
          Blind spots
          Hide rare data failures
          Detect hidden failures in data
      
      
          Error tracing
          Hard
          Directly trace errors to dirty/outlier/bias data
      
      
          Example
          &ldquo;95% accurate model!&rdquo;
          &ldquo;Fails badly on young users with rare diseases&rdquo;
      
      
          Mindset
          Improve model tuning
          Fix the dataset (quality, balance, coverage)
      
  


  Q1: What is the typical ML workflow before deployment?
  #


Collect data and define the ML task.
Explore and preprocess the data.
Train a straightforward model.
Investigate shortcomings in the model and dataset.
Improve dataset and model iteratively.
Deploy the model and monitor for new issues.


  Q2: Why is model evaluation critical?
  #


Evaluation affects practical outcomes in real-world applications.
Poor evaluation choices can lead to misleading or harmful models.


  Q3: What are examples of evaluation metrics for classification?
  #


Accuracy, balanced accuracy, precision, recall, log loss, AUROC, calibration error.


  Q4: What are some pitfalls in model evaluation?
  #


Data leakage by using non-held-out data.
Misspecified metrics hiding failures in subpopulations.
Validation data not representing deployment settings.
Label errors.


  Q5: How is text generation model evaluation different?
  #


Human evaluations (üëçüëé or Likert scales).
LLM evaluations with multiple criteria.
Automated metrics like ROUGE, BLEU, and Perplexity.


  Q6: What is a data slice?
  #


A subset of the dataset sharing a common characteristic, e.g., different sensor types, demographics.


  Q7: Why is it insufficient to delete sensitive features to address slice fairness?
  #


Slice membership information may be correlated with other features.


  Q8: How can we improve model performance for underperforming slices?
  #


Use a more flexible model.
Over-sample the minority subgroup.
Collect more data from the subgroup.
Engineer new features that better capture subgroup specifics.


  Q9: How to discover underperforming subpopulations?
  #


Sort validation examples by loss.
Cluster high-loss examples to find commonalities.


  Q10: What are typical causes of wrong predictions?
  #


Incorrect labels.
Examples that do not belong to any class.
Outlier examples.
Model type limitations.
Conflicting or noisy dataset labels.


  Q11: What actions can address wrong predictions?
  #


Correct labels.
Remove fundamentally unpredictable examples.
Augment or normalize outlier examples.
Fit better model architectures or do feature engineering.
Enrich the dataset to distinguish overlapping classes.


  Q12: What is the concept of leave-one-out influence?
  #


Measure the impact of omitting a datapoint on the model‚Äôs validation performance.


  Q13: What is Data Shapley?
  #


A method that averages the influence of a datapoint over all subsets containing it, providing a fairer measure of its importance.


  Q14: How can we approximate influence?
  #


Monte Carlo sampling methods.
Closed-form approximations for simple models like linear regression and k-NN.


  Q15: Why review influential samples?
  #


Correcting highly influential mislabeled examples can lead to significant accuracy improvements.



  References
  #


Cook‚Äôs Distance (Linear Regression Influence)
Similarity Search Scaling for Big Data (Johnson et al., 2019)
Trustworthy Data Influence Estimation
Confident Learning and Cleanlab Project
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://imipark.github.io/ai-workflows/data/data-centric-ai/data-centric-evaluation/">
  <meta property="og:site_name" content="AI Reasoning">
  <meta property="og:title" content="Data-Centric Evaluation of ML Models">
  <meta property="og:description" content="Data-Centric Evaluation of ML Models Instead of only asking how accurate, we ask why and where does the model fail ‚Äî and whether the data itself causes it. Aspect Model-Centric Evaluation Data-Centric Evaluation Focus Overall model score Specific weaknesses tied to data Metrics Accuracy, ROC, etc. Slice-specific accuracy, Error analysis Blind spots Hide rare data failures Detect hidden failures in data Error tracing Hard Directly trace errors to dirty/outlier/bias data Example ‚Äú95% accurate model!‚Äù ‚ÄúFails badly on young users with rare diseases‚Äù Mindset Improve model tuning Fix the dataset (quality, balance, coverage) Q1: What is the typical ML workflow before deployment? # Collect data and define the ML task. Explore and preprocess the data. Train a straightforward model. Investigate shortcomings in the model and dataset. Improve dataset and model iteratively. Deploy the model and monitor for new issues. Q2: Why is model evaluation critical? # Evaluation affects practical outcomes in real-world applications. Poor evaluation choices can lead to misleading or harmful models. Q3: What are examples of evaluation metrics for classification? # Accuracy, balanced accuracy, precision, recall, log loss, AUROC, calibration error. Q4: What are some pitfalls in model evaluation? # Data leakage by using non-held-out data. Misspecified metrics hiding failures in subpopulations. Validation data not representing deployment settings. Label errors. Q5: How is text generation model evaluation different? # Human evaluations (üëçüëé or Likert scales). LLM evaluations with multiple criteria. Automated metrics like ROUGE, BLEU, and Perplexity. Q6: What is a data slice? # A subset of the dataset sharing a common characteristic, e.g., different sensor types, demographics. Q7: Why is it insufficient to delete sensitive features to address slice fairness? # Slice membership information may be correlated with other features. Q8: How can we improve model performance for underperforming slices? # Use a more flexible model. Over-sample the minority subgroup. Collect more data from the subgroup. Engineer new features that better capture subgroup specifics. Q9: How to discover underperforming subpopulations? # Sort validation examples by loss. Cluster high-loss examples to find commonalities. Q10: What are typical causes of wrong predictions? # Incorrect labels. Examples that do not belong to any class. Outlier examples. Model type limitations. Conflicting or noisy dataset labels. Q11: What actions can address wrong predictions? # Correct labels. Remove fundamentally unpredictable examples. Augment or normalize outlier examples. Fit better model architectures or do feature engineering. Enrich the dataset to distinguish overlapping classes. Q12: What is the concept of leave-one-out influence? # Measure the impact of omitting a datapoint on the model‚Äôs validation performance. Q13: What is Data Shapley? # A method that averages the influence of a datapoint over all subsets containing it, providing a fairer measure of its importance. Q14: How can we approximate influence? # Monte Carlo sampling methods. Closed-form approximations for simple models like linear regression and k-NN. Q15: Why review influential samples? # Correcting highly influential mislabeled examples can lead to significant accuracy improvements. References # Cook‚Äôs Distance (Linear Regression Influence) Similarity Search Scaling for Big Data (Johnson et al., 2019) Trustworthy Data Influence Estimation Confident Learning and Cleanlab Project">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="ai-workflows">
<title>Data-Centric Evaluation of ML Models | AI Reasoning</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="https://imipark.github.io/ai-workflows/data/data-centric-ai/data-centric-evaluation/">
<link rel="stylesheet" href="/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.c4e10013ea577c4e1908c5eaa1f1303fe07b484ac90714514291bb2f12aaae31.js" integrity="sha256-xOEAE&#43;pXfE4ZCMXqofEwP&#43;B7SErJBxRRQpG7LxKqrjE=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>AI Reasoning</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>













  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ai-workflows/" class="">AI Reasoning Stack</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7f3f4cf59430750c2ad109248c8c879b" class="toggle" checked />
    <label for="section-7f3f4cf59430750c2ad109248c8c879b" class="flex justify-between">
      <a href="/ai-workflows/data/" class="">Data</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fc566bddf8394fb4d0c5cff688d2febc" class="toggle" checked />
    <label for="section-fc566bddf8394fb4d0c5cff688d2febc" class="flex justify-between">
      <a href="/ai-workflows/data/data-centric-ai/" class="">Data-Centric AI (DCAI)</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cff08f084db31c8732ef81d1fe1c4130" class="toggle"  />
    <label for="section-cff08f084db31c8732ef81d1fe1c4130" class="flex justify-between">
      <a href="/ai-workflows/genai/" class="">GenAI</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-63b806a012c3062adb6281022ca8468f" class="toggle"  />
    <label for="section-63b806a012c3062adb6281022ca8468f" class="flex justify-between">
      <a href="/ai-workflows/genai/5-day-genai-google-2025/" class="">5-Day GenAI with Google 2005</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day1_foundational_llm_text_generation/" class="">Day 1 - Foundational LLMs &amp; Text Generation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day1_prompt_engineering/" class="">Day 1 ‚Äì Prompt Engineering</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day2_embeddings_vectordb/" class="">Day 2 ‚Äì Embeddings &amp; Vector Databases</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day3_generative_agents/" class="">Day 3 ‚Äì Generative Agents</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day4_domainspecific_llms/" class="">Day 4 ‚Äì Domain-Specific LLMs</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day5_mlops/" class="">Day 5 ‚Äì MLOps for Generative AI</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/multimodel_llms/" class="">Multimodal LLMs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-17ba62e37c896ad50105fedeb71549dd" class="toggle"  />
    <label for="section-17ba62e37c896ad50105fedeb71549dd" class="flex justify-between">
      <a href="/ai-workflows/reasoning/" class="">Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cd94e161670d28ecff992edf840d76e8" class="toggle"  />
    <label for="section-cd94e161670d28ecff992edf840d76e8" class="flex justify-between">
      <a href="/ai-workflows/reasoning/causality/" class="">Causality</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-ai/" class="">Causal AI</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-inference/" class="">Causal Inference</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7e468aa05ceb7c844f07a2e754606b76" class="toggle"  />
    <label for="section-7e468aa05ceb7c844f07a2e754606b76" class="flex justify-between">
      <a href="/ai-workflows/reasoning/graph-reasoning/" class="">Graph Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/graphrag/" class="">GraphRAG</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/knowledge-graphs/" class="">Knowledge Graphs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="toggle"  />
    <label for="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="flex justify-between">
      <a href="/ai-workflows/rlhf/" class="">RLHF</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b1afcafdefac57f3420f64e23d73f05d" class="toggle"  />
    <label for="section-b1afcafdefac57f3420f64e23d73f05d" class="flex justify-between">
      <a href="/ai-workflows/rlhf/rlhf2006/" class="">RLHF 2006</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/rlhf/rlhf2006/instruct_gpt_codes_params/" class="">Instruct Gpt Codes Params</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ca53d32fab0e1a54fdf5627349d86bfc" class="toggle"  />
    <label for="section-ca53d32fab0e1a54fdf5627349d86bfc" class="flex justify-between">
      <a href="/ai-workflows/eval/" class="">Eval</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/healthcare/" class="">Healthcare</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="toggle"  />
    <label for="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/" class="">Domain</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-45ba5974905f86df95925365835eadbb" class="toggle"  />
    <label for="section-45ba5974905f86df95925365835eadbb" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/ai-in-healthcare/" class="">AI in Healthcare</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/" class="">C2 Clinical Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/" class="">C3 ML Healthcare</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/" class="">C4 AI Evaluations</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c5_capstone/" class="">C5 Capstone Projects</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9722ba71bf098ab02c3220d6e8d9056f" class="toggle"  />
    <label for="section-9722ba71bf098ab02c3220d6e8d9056f" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/hands-on-healthcare-data/" class="">Hands-On Healthcare Data</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/data/" class="">Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/clinical_ai/" class="">AI Applications</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ipark/" class="">Inhee Park, PhD - Resume</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>










  
<ul>
  
  <li>
    <a href="https://www.linkedin.com/in/inheepark/"  target="_blank" rel="noopener">
        ‚ï∞‚îÄ‚îÄLinkedIn
      </a>
  </li>
  
  <li>
    <a href="https://github.com/imipark/"  target="_blank" rel="noopener">
        ‚ï∞‚îÄ‚îÄGitHub
      </a>
  </li>
  
  <li>
    <a href="/posts/"  target="_blank" rel="noopener">
        ‚ï∞‚îÄ‚îÄBlog
      </a>
  </li>
  
  <li>
    <a href="https://iparkirk.github.io"  target="_blank" rel="noopener">
        ‚ï∞‚îÄ‚îÄOld Web
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Data-Centric Evaluation of ML Models</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#q1-what-is-the-typical-ml-workflow-before-deployment">Q1: What is the typical ML workflow before deployment?</a></li>
            <li><a href="#q2-why-is-model-evaluation-critical">Q2: Why is model evaluation critical?</a></li>
            <li><a href="#q3-what-are-examples-of-evaluation-metrics-for-classification">Q3: What are examples of evaluation metrics for classification?</a></li>
            <li><a href="#q4-what-are-some-pitfalls-in-model-evaluation">Q4: What are some pitfalls in model evaluation?</a></li>
            <li><a href="#q5-how-is-text-generation-model-evaluation-different">Q5: How is text generation model evaluation different?</a></li>
            <li><a href="#q6-what-is-a-data-slice">Q6: What is a data slice?</a></li>
            <li><a href="#q7-why-is-it-insufficient-to-delete-sensitive-features-to-address-slice-fairness">Q7: Why is it insufficient to delete sensitive features to address slice fairness?</a></li>
            <li><a href="#q8-how-can-we-improve-model-performance-for-underperforming-slices">Q8: How can we improve model performance for underperforming slices?</a></li>
            <li><a href="#q9-how-to-discover-underperforming-subpopulations">Q9: How to discover underperforming subpopulations?</a></li>
            <li><a href="#q10-what-are-typical-causes-of-wrong-predictions">Q10: What are typical causes of wrong predictions?</a></li>
            <li><a href="#q11-what-actions-can-address-wrong-predictions">Q11: What actions can address wrong predictions?</a></li>
            <li><a href="#q12-what-is-the-concept-of-leave-one-out-influence">Q12: What is the concept of leave-one-out influence?</a></li>
            <li><a href="#q13-what-is-data-shapley">Q13: What is Data Shapley?</a></li>
            <li><a href="#q14-how-can-we-approximate-influence">Q14: How can we approximate influence?</a></li>
            <li><a href="#q15-why-review-influential-samples">Q15: Why review influential samples?</a></li>
            <li><a href="#references">References</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><p align="center">
<img src="/images/AIR_logo.png" alt="AI Reasoning Logo" width="200"/>
<strong style="font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;">
Data-Centric Evaluation of ML Models 
</strong>
</p>
<ul>
<li>Instead of only asking <strong>how accurate</strong>, we ask <strong>why and where does the model fail</strong> ‚Äî and whether the data itself causes it.</li>
</ul>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Aspect</th>
          <th style="text-align: left">Model-Centric Evaluation</th>
          <th style="text-align: left"><strong>Data-Centric Evaluation</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">Focus</td>
          <td style="text-align: left">Overall model score</td>
          <td style="text-align: left">Specific weaknesses tied to data</td>
      </tr>
      <tr>
          <td style="text-align: left">Metrics</td>
          <td style="text-align: left">Accuracy, ROC, etc.</td>
          <td style="text-align: left">Slice-specific accuracy, Error analysis</td>
      </tr>
      <tr>
          <td style="text-align: left">Blind spots</td>
          <td style="text-align: left">Hide rare data failures</td>
          <td style="text-align: left">Detect hidden failures in data</td>
      </tr>
      <tr>
          <td style="text-align: left">Error tracing</td>
          <td style="text-align: left">Hard</td>
          <td style="text-align: left">Directly trace errors to dirty/outlier/bias data</td>
      </tr>
      <tr>
          <td style="text-align: left">Example</td>
          <td style="text-align: left">&ldquo;95% accurate model!&rdquo;</td>
          <td style="text-align: left">&ldquo;Fails badly on young users with rare diseases&rdquo;</td>
      </tr>
      <tr>
          <td style="text-align: left">Mindset</td>
          <td style="text-align: left">Improve model tuning</td>
          <td style="text-align: left">Fix the dataset (quality, balance, coverage)</td>
      </tr>
  </tbody>
</table>
<h3 id="q1-what-is-the-typical-ml-workflow-before-deployment">
  Q1: What is the typical ML workflow before deployment?
  <a class="anchor" href="#q1-what-is-the-typical-ml-workflow-before-deployment">#</a>
</h3>
<ul>
<li>Collect data and define the ML task.</li>
<li>Explore and preprocess the data.</li>
<li>Train a straightforward model.</li>
<li>Investigate shortcomings in the model and dataset.</li>
<li>Improve dataset and model iteratively.</li>
<li>Deploy the model and monitor for new issues.</li>
</ul>
<h3 id="q2-why-is-model-evaluation-critical">
  Q2: Why is model evaluation critical?
  <a class="anchor" href="#q2-why-is-model-evaluation-critical">#</a>
</h3>
<ul>
<li>Evaluation affects practical outcomes in real-world applications.</li>
<li>Poor evaluation choices can lead to misleading or harmful models.</li>
</ul>
<h3 id="q3-what-are-examples-of-evaluation-metrics-for-classification">
  Q3: What are examples of evaluation metrics for classification?
  <a class="anchor" href="#q3-what-are-examples-of-evaluation-metrics-for-classification">#</a>
</h3>
<ul>
<li>Accuracy, balanced accuracy, precision, recall, log loss, AUROC, calibration error.</li>
</ul>
<h3 id="q4-what-are-some-pitfalls-in-model-evaluation">
  Q4: What are some pitfalls in model evaluation?
  <a class="anchor" href="#q4-what-are-some-pitfalls-in-model-evaluation">#</a>
</h3>
<ul>
<li>Data leakage by using non-held-out data.</li>
<li>Misspecified metrics hiding failures in subpopulations.</li>
<li>Validation data not representing deployment settings.</li>
<li>Label errors.</li>
</ul>
<h3 id="q5-how-is-text-generation-model-evaluation-different">
  Q5: How is text generation model evaluation different?
  <a class="anchor" href="#q5-how-is-text-generation-model-evaluation-different">#</a>
</h3>
<ul>
<li>Human evaluations (üëçüëé or Likert scales).</li>
<li>LLM evaluations with multiple criteria.</li>
<li>Automated metrics like ROUGE, BLEU, and Perplexity.</li>
</ul>
<h3 id="q6-what-is-a-data-slice">
  Q6: What is a data slice?
  <a class="anchor" href="#q6-what-is-a-data-slice">#</a>
</h3>
<ul>
<li>A subset of the dataset sharing a common characteristic, e.g., different sensor types, demographics.</li>
</ul>
<h3 id="q7-why-is-it-insufficient-to-delete-sensitive-features-to-address-slice-fairness">
  Q7: Why is it insufficient to delete sensitive features to address slice fairness?
  <a class="anchor" href="#q7-why-is-it-insufficient-to-delete-sensitive-features-to-address-slice-fairness">#</a>
</h3>
<ul>
<li>Slice membership information may be correlated with other features.</li>
</ul>
<h3 id="q8-how-can-we-improve-model-performance-for-underperforming-slices">
  Q8: How can we improve model performance for underperforming slices?
  <a class="anchor" href="#q8-how-can-we-improve-model-performance-for-underperforming-slices">#</a>
</h3>
<ul>
<li>Use a more flexible model.</li>
<li>Over-sample the minority subgroup.</li>
<li>Collect more data from the subgroup.</li>
<li>Engineer new features that better capture subgroup specifics.</li>
</ul>
<h3 id="q9-how-to-discover-underperforming-subpopulations">
  Q9: How to discover underperforming subpopulations?
  <a class="anchor" href="#q9-how-to-discover-underperforming-subpopulations">#</a>
</h3>
<ul>
<li>Sort validation examples by loss.</li>
<li>Cluster high-loss examples to find commonalities.</li>
</ul>
<h3 id="q10-what-are-typical-causes-of-wrong-predictions">
  Q10: What are typical causes of wrong predictions?
  <a class="anchor" href="#q10-what-are-typical-causes-of-wrong-predictions">#</a>
</h3>
<ul>
<li>Incorrect labels.</li>
<li>Examples that do not belong to any class.</li>
<li>Outlier examples.</li>
<li>Model type limitations.</li>
<li>Conflicting or noisy dataset labels.</li>
</ul>
<h3 id="q11-what-actions-can-address-wrong-predictions">
  Q11: What actions can address wrong predictions?
  <a class="anchor" href="#q11-what-actions-can-address-wrong-predictions">#</a>
</h3>
<ul>
<li>Correct labels.</li>
<li>Remove fundamentally unpredictable examples.</li>
<li>Augment or normalize outlier examples.</li>
<li>Fit better model architectures or do feature engineering.</li>
<li>Enrich the dataset to distinguish overlapping classes.</li>
</ul>
<h3 id="q12-what-is-the-concept-of-leave-one-out-influence">
  Q12: What is the concept of leave-one-out influence?
  <a class="anchor" href="#q12-what-is-the-concept-of-leave-one-out-influence">#</a>
</h3>
<ul>
<li>Measure the impact of omitting a datapoint on the model‚Äôs validation performance.</li>
</ul>
<h3 id="q13-what-is-data-shapley">
  Q13: What is Data Shapley?
  <a class="anchor" href="#q13-what-is-data-shapley">#</a>
</h3>
<ul>
<li>A method that averages the influence of a datapoint over all subsets containing it, providing a fairer measure of its importance.</li>
</ul>
<h3 id="q14-how-can-we-approximate-influence">
  Q14: How can we approximate influence?
  <a class="anchor" href="#q14-how-can-we-approximate-influence">#</a>
</h3>
<ul>
<li>Monte Carlo sampling methods.</li>
<li>Closed-form approximations for simple models like linear regression and k-NN.</li>
</ul>
<h3 id="q15-why-review-influential-samples">
  Q15: Why review influential samples?
  <a class="anchor" href="#q15-why-review-influential-samples">#</a>
</h3>
<ul>
<li>Correcting highly influential mislabeled examples can lead to significant accuracy improvements.</li>
</ul>
<hr>
<h3 id="references">
  References
  <a class="anchor" href="#references">#</a>
</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Cook%27s_distance">Cook‚Äôs Distance (Linear Regression Influence)</a></li>
<li><a href="https://arxiv.org/abs/1702.08734">Similarity Search Scaling for Big Data (Johnson et al., 2019)</a></li>
<li><a href="https://ojs.aaai.org/index.php/AAAI/article/view/20591">Trustworthy Data Influence Estimation</a></li>
<li><a href="https://github.com/cleanlab/cleanlab">Confident Learning and Cleanlab Project</a></li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#q1-what-is-the-typical-ml-workflow-before-deployment">Q1: What is the typical ML workflow before deployment?</a></li>
            <li><a href="#q2-why-is-model-evaluation-critical">Q2: Why is model evaluation critical?</a></li>
            <li><a href="#q3-what-are-examples-of-evaluation-metrics-for-classification">Q3: What are examples of evaluation metrics for classification?</a></li>
            <li><a href="#q4-what-are-some-pitfalls-in-model-evaluation">Q4: What are some pitfalls in model evaluation?</a></li>
            <li><a href="#q5-how-is-text-generation-model-evaluation-different">Q5: How is text generation model evaluation different?</a></li>
            <li><a href="#q6-what-is-a-data-slice">Q6: What is a data slice?</a></li>
            <li><a href="#q7-why-is-it-insufficient-to-delete-sensitive-features-to-address-slice-fairness">Q7: Why is it insufficient to delete sensitive features to address slice fairness?</a></li>
            <li><a href="#q8-how-can-we-improve-model-performance-for-underperforming-slices">Q8: How can we improve model performance for underperforming slices?</a></li>
            <li><a href="#q9-how-to-discover-underperforming-subpopulations">Q9: How to discover underperforming subpopulations?</a></li>
            <li><a href="#q10-what-are-typical-causes-of-wrong-predictions">Q10: What are typical causes of wrong predictions?</a></li>
            <li><a href="#q11-what-actions-can-address-wrong-predictions">Q11: What actions can address wrong predictions?</a></li>
            <li><a href="#q12-what-is-the-concept-of-leave-one-out-influence">Q12: What is the concept of leave-one-out influence?</a></li>
            <li><a href="#q13-what-is-data-shapley">Q13: What is Data Shapley?</a></li>
            <li><a href="#q14-how-can-we-approximate-influence">Q14: How can we approximate influence?</a></li>
            <li><a href="#q15-why-review-influential-samples">Q15: Why review influential samples?</a></li>
            <li><a href="#references">References</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












