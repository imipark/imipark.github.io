<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GenAI Systems on AI Reasoning</title>
    <link>http://localhost:1313/ai-workflows/genai-systems/</link>
    <description>Recent content in GenAI Systems on AI Reasoning</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/ai-workflows/genai-systems/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Transformer Attention: Full Conceptual Breakdown</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/transformer_attention_concepts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/transformer_attention_concepts/</guid>
      <description>&lt;h1 id=&#34;transformer-attention-full-conceptual-breakdown&#34;&gt;&#xA;  Transformer Attention: Full Conceptual Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#transformer-attention-full-conceptual-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document summarizes an in-depth discussion on attention mechanisms in Transformers, with a special focus on vocabulary embeddings, Q/K/V matrices, and multi-head attention.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-1-understanding-the-self-attention-image&#34;&gt;&#xA;  üìå 1. Understanding the Self-Attention Image&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-1-understanding-the-self-attention-image&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The image shows a &lt;strong&gt;single-head self-attention&lt;/strong&gt; computation.&lt;/li&gt;&#xA;&lt;li&gt;Each &lt;strong&gt;row&lt;/strong&gt; is a token (element) at a &lt;strong&gt;position&lt;/strong&gt;, with a feature vector (embedding).&lt;/li&gt;&#xA;&lt;li&gt;The &lt;strong&gt;attention weights&lt;/strong&gt; (left column) are used to compute a &lt;strong&gt;weighted sum&lt;/strong&gt; over these vectors.&lt;/li&gt;&#xA;&lt;li&gt;The final output vector is shown at the bottom ‚Äî this is the attention output for one token.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-2-element-vs-position&#34;&gt;&#xA;  üîç 2. Element vs. Position&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-2-element-vs-position&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Element&lt;/strong&gt;: the actual word or token in the input sequence.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Position&lt;/strong&gt;: the index of the element in the sequence.&lt;/li&gt;&#xA;&lt;li&gt;Though tightly coupled (1:1), they are conceptually different.&lt;/li&gt;&#xA;&lt;li&gt;Transformers rely on &lt;strong&gt;positional encoding&lt;/strong&gt; to retain order, since attention alone is orderless.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-3-how-attention-scores-are-computed&#34;&gt;&#xA;  ü§ñ 3. How Attention Scores Are Computed&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-3-how-attention-scores-are-computed&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Input embeddings X&lt;/strong&gt; are projected into:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding How to Use BERT&#39;s CLS Token for Classification</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/bert_cls_classification_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/bert_cls_classification_summary/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Date:&lt;/strong&gt; 2025-03-31&lt;/p&gt;&#xA;&lt;h2 id=&#34;-question&#34;&gt;&#xA;  ‚ùì Question&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-question&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;How can we use the &lt;code&gt;[CLS]&lt;/code&gt; token (i.e., &lt;code&gt;h_cls&lt;/code&gt;) from the last layer of BERT for classification tasks? Given that the BERT output has shape &lt;code&gt;[batch_size, sequence_length, hidden_size]&lt;/code&gt;, how is it valid to pass only &lt;code&gt;[batch_size, hidden_size]&lt;/code&gt; to a &lt;code&gt;nn.Linear(hidden_size, num_classes)&lt;/code&gt; without flattening the sequence? And why don&amp;rsquo;t we flatten the whole sequence ‚Äî wouldn&amp;rsquo;t that destroy order?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-answer&#34;&gt;&#xA;  ‚úÖ Answer&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-answer&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-bert-output-and-the-cls-token&#34;&gt;&#xA;  üîπ BERT Output and the &lt;code&gt;[CLS]&lt;/code&gt; Token&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-bert-output-and-the-cls-token&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;BERT outputs a tensor of shape:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Self-Attention in Transformers: A Visual Breakdown</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/self_attention_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/self_attention_summary/</guid>
      <description>&lt;h1 id=&#34;-understanding-self-attention-in-transformers-a-visual-breakdown&#34;&gt;&#xA;  üîç Understanding Self-Attention in Transformers: A Visual Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-understanding-self-attention-in-transformers-a-visual-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document summarizes key questions about self-attention, embedding vectors, positions, and the input matrix in Transformers ‚Äî using the image you provided as the foundation.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-what-is-happening-in-the-diagram&#34;&gt;&#xA;  üß† What Is Happening in the Diagram?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-what-is-happening-in-the-diagram&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The figure shows how &lt;strong&gt;self-attention&lt;/strong&gt; computes the output for a specific position (&amp;ldquo;detection&amp;rdquo;) by:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Generating &lt;strong&gt;attention weights&lt;/strong&gt; between that position and &lt;strong&gt;all other positions&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Using those weights to compute a &lt;strong&gt;weighted sum&lt;/strong&gt; of the input feature vectors.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/attention.png&#34; alt=&#34;Self-Attention Diagram&#34; /&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
