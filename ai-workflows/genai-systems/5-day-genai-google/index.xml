<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>5-Day GenAI with Google on AI Reasoning</title>
    <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/</link>
    <description>Recent content in 5-Day GenAI with Google on AI Reasoning</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Day 1 - Foundational LLMs &amp; Text Generation</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day1_foundational_llm_text_generation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day1_foundational_llm_text_generation/</guid>
      <description>&lt;h2 id=&#34;day-1---foundational-llms--text-generation&#34;&gt;&#xA;  Day 1 - Foundational LLMs &amp;amp; Text Generation&amp;quot;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-1---foundational-llms--text-generation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;foundations-of-llms&#34;&gt;&#xA;  &lt;strong&gt;Foundations of LLMs&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#foundations-of-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-why-llms-matter&#34;&gt;&#xA;  1. Why LLMs Matter&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-llms-matter&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Traditional NLP systems were narrow, but Large Language Models (LLMs) offer general-purpose capabilities like translation, Q&amp;amp;A, and summarization—all without explicit task-specific programming.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ How do LLMs work under the hood?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-what-powers-llms-the-transformer&#34;&gt;&#xA;  2. What Powers LLMs: The Transformer&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-powers-llms-the-transformer&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;The Transformer is the core architecture enabling LLMs. Unlike RNNs that process data sequentially, Transformers handle inputs in parallel using &lt;strong&gt;self-attention&lt;/strong&gt;, allowing them to model long-range dependencies more efficiently and scale training.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 1 – Prompt Engineering</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day1_prompt_engineering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day1_prompt_engineering/</guid>
      <description>&lt;h2 id=&#34;day-1--prompt-engineering&#34;&gt;&#xA;  Day 1 – Prompt Engineering&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-1--prompt-engineering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-why-prompt-engineering-matters&#34;&gt;&#xA;  1. Why Prompt Engineering Matters&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-prompt-engineering-matters&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;need for controlling LLM behavior&lt;/em&gt;. Although everyone can write prompts, crafting high-quality prompts is complex. The model, structure, tone, and context all affect the outcome. Prompt engineering is an iterative process requiring optimization and experimentation.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ how do we guide LLMs effectively without retraining them?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-how-llms-predict-text&#34;&gt;&#xA;  2. How LLMs Predict Text&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-how-llms-predict-text&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;LLMs are &lt;em&gt;token prediction machines&lt;/em&gt;. They predict the next likely token based on previous tokens and training data. Prompt engineering means designing inputs that lead the model toward the desired outputs using this prediction mechanism.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 2 – Embeddings &amp; Vector Databases</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day2_embeddings_vectordb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day2_embeddings_vectordb/</guid>
      <description>&lt;h2 id=&#34;day-2--embeddings--vector-databases&#34;&gt;&#xA;  Day 2 – Embeddings &amp;amp; Vector Databases&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-2--embeddings--vector-databases&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-why-embeddings&#34;&gt;&#xA;  1. Why Embeddings?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We begin with the &lt;em&gt;core problem of representing diverse data types&lt;/em&gt;. Images, text, audio, and structured data all need to be compared, retrieved, and clustered. Embeddings map these into a shared vector space where similarity can be computed numerically.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ how can we measure and preserve semantic meaning across different data types?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-mapping-data-to-vector-space&#34;&gt;&#xA;  2. Mapping Data to Vector Space&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-mapping-data-to-vector-space&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Embeddings reduce dimensionality while preserving meaning. For example, just like latitude and longitude embed Earth’s surface into 2D coordinates, BERT embeds text into 768D space. Distances represent semantic similarity.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 3 – Generative Agents</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day3_generative_agents/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day3_generative_agents/</guid>
      <description>&lt;h2 id=&#34;day-3--generative-agents&#34;&gt;&#xA;  Day 3 – Generative Agents&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-3--generative-agents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-what-are-generative-agents&#34;&gt;&#xA;  1. What Are Generative Agents?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-what-are-generative-agents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;definition of agents&lt;/em&gt;—AI systems designed to achieve goals by perceiving their environment and taking actions using tools. Unlike static LLMs, generative agents combine models, tools, and orchestration to interact with the world dynamically.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ what components make these agents truly autonomous and intelligent?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-agent-architecture-breakdown&#34;&gt;&#xA;  2. Agent Architecture Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-agent-architecture-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;An agent’s architecture includes:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 4 – Domain-Specific LLMs</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day4_domainspecific_llms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day4_domainspecific_llms/</guid>
      <description>&lt;h2 id=&#34;day-4--domain-specific-llms&#34;&gt;&#xA;  Day 4 – Domain-Specific LLMs&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-4--domain-specific-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-the-rise-of-specialized-llms&#34;&gt;&#xA;  1. The Rise of Specialized LLMs&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-the-rise-of-specialized-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;evolution of LLMs&lt;/em&gt; from general-purpose to domain-specific tools. This shift was driven by challenges in fields like cybersecurity and medicine, where technical language and sensitive use cases demand more than general knowledge.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ why do general-purpose LLMs struggle in specialized domains?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-the-challenges-in-cybersecurity&#34;&gt;&#xA;  2. The Challenges in Cybersecurity&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-the-challenges-in-cybersecurity&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Cybersecurity experts face three main issues: rapidly evolving threats, repetitive manual work (toil), and a shortage of skilled talent. These bottlenecks make it hard to keep up with modern security needs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 5 – MLOps for Generative AI</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day5_mlops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day5_mlops/</guid>
      <description>&lt;h2 id=&#34;day-5--mlops-for-generative-ai&#34;&gt;&#xA;  Day 5 – MLOps for Generative AI&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-5--mlops-for-generative-ai&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-introduction&#34;&gt;&#xA;  1. Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;The rise of &lt;strong&gt;foundation models&lt;/strong&gt; and &lt;strong&gt;generative AI (gen AI)&lt;/strong&gt; has brought a paradigm shift in how we build and deploy AI systems. From selecting architectures to managing prompts and grounding outputs in real data, traditional MLOps needs adaptation.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;So how do we evolve MLOps for this new generative world?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-what-are-devops-and-mlops&#34;&gt;&#xA;  2. What Are DevOps and MLOps?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-are-devops-and-mlops&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DevOps&lt;/strong&gt;: Automation + collaboration for software delivery (CI/CD, testing, reliability)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MLOps&lt;/strong&gt;: Adds ML-specific needs:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data validation&lt;/li&gt;&#xA;&lt;li&gt;Model evaluation&lt;/li&gt;&#xA;&lt;li&gt;Monitoring&lt;/li&gt;&#xA;&lt;li&gt;Experiment tracking&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;These core principles set the stage, but gen AI has unique needs.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
