<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="


Inputs and Data Preparation for Multimodal LLMs



Multimodal LLMs are language models that can process and reason over multiple data types, especially:

Text
Images
(Optionally: audio, video, or other modalities)

They are designed to understand both visual and linguistic context, enabling tasks like visual question answering, image captioning, grounding, and perception-based reasoning.


  üñºÔ∏è &#43; üí¨ Input Format
  #

Inputs typically include:

Image(s): RGB images, optionally annotated (e.g., bounding boxes, circles)
Text Prompt: Task instruction or question (e.g., &ldquo;Which object is closer?&rdquo;)
Answer Choices (optional): For classification-style tasks like BLINK

inputs = {
  &#34;images&#34;: [...],   # preprocessed (resized, normalized) tensors or raw image paths
  &#34;text&#34;: &#34;Which point is closer to the camera? (A) A (B) B&#34;
}
Some APIs accept JSON-style mixed prompts with interleaved text and image tokens.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://imipark.github.io/ai-workflows/genai-systems/multimodel_llms/data_prep/">
  <meta property="og:site_name" content="AI Reasoning">
  <meta property="og:title" content="Inputs and Data Preparation for Multimodal LLMs">
  <meta property="og:description" content="Inputs and Data Preparation for Multimodal LLMs Multimodal LLMs are language models that can process and reason over multiple data types, especially:
Text Images (Optionally: audio, video, or other modalities) They are designed to understand both visual and linguistic context, enabling tasks like visual question answering, image captioning, grounding, and perception-based reasoning.
üñºÔ∏è &#43; üí¨ Input Format # Inputs typically include:
Image(s): RGB images, optionally annotated (e.g., bounding boxes, circles) Text Prompt: Task instruction or question (e.g., ‚ÄúWhich object is closer?‚Äù) Answer Choices (optional): For classification-style tasks like BLINK inputs = { &#34;images&#34;: [...], # preprocessed (resized, normalized) tensors or raw image paths &#34;text&#34;: &#34;Which point is closer to the camera? (A) A (B) B&#34; } Some APIs accept JSON-style mixed prompts with interleaved text and image tokens.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="ai-workflows">
<title>Inputs and Data Preparation for Multimodal LLMs | AI Reasoning</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="https://imipark.github.io/ai-workflows/genai-systems/multimodel_llms/data_prep/">
<link rel="stylesheet" href="/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.a0efbe41a7b1c6f20d16b2d51ba7430c4d0d9b69849963c0c682ad9812647b67.js" integrity="sha256-oO&#43;&#43;QaexxvINFrLVG6dDDE0Nm2mEmWPAxoKtmBJke2c=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>AI Reasoning</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>













  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ai-workflows/" class="">AI Reasoning Stack</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-f8e502c34e18a04e1c3aecf192b0355a" class="toggle"  />
    <label for="section-f8e502c34e18a04e1c3aecf192b0355a" class="flex justify-between">
      <a href="/ai-workflows/data-modeling/" class="">Data Modeling</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-906a2243f4790a09188fae70fbc32dbd" class="toggle"  />
    <label for="section-906a2243f4790a09188fae70fbc32dbd" class="flex justify-between">
      <a href="/ai-workflows/data-modeling/data-centric-ai/" class="">Data-Centric AI (DCAI)</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-5bf1c216f4b747bd7c2f992550ff09a1" class="toggle" checked />
    <label for="section-5bf1c216f4b747bd7c2f992550ff09a1" class="flex justify-between">
      <a href="/ai-workflows/genai-systems/" class="">GenAI Systems</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8cbfd420d91de13f61964bf971127312" class="toggle"  />
    <label for="section-8cbfd420d91de13f61964bf971127312" class="flex justify-between">
      <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/" class="">5-Day GenAI with Google 2005</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day1_foundational_llm_text_generation/" class="">Day 1 - Foundational LLMs &amp; Text Generation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day1_prompt_engineering/" class="">Day 1 ‚Äì Prompt Engineering</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day2_embeddings_vectordb/" class="">Day 2 ‚Äì Embeddings &amp; Vector Databases</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day3_generative_agents/" class="">Day 3 ‚Äì Generative Agents</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day4_domainspecific_llms/" class="">Day 4 ‚Äì Domain-Specific LLMs</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day5_mlops/" class="">Day 5 ‚Äì MLOps for Generative AI</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/multimodel_llms/" class="">Multimodal LLMs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-17ba62e37c896ad50105fedeb71549dd" class="toggle"  />
    <label for="section-17ba62e37c896ad50105fedeb71549dd" class="flex justify-between">
      <a href="/ai-workflows/reasoning/" class="">Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cd94e161670d28ecff992edf840d76e8" class="toggle"  />
    <label for="section-cd94e161670d28ecff992edf840d76e8" class="flex justify-between">
      <a href="/ai-workflows/reasoning/causality/" class="">Causality</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-ai/" class="">Causal AI</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-inference/" class="">Causal Inference</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7e468aa05ceb7c844f07a2e754606b76" class="toggle"  />
    <label for="section-7e468aa05ceb7c844f07a2e754606b76" class="flex justify-between">
      <a href="/ai-workflows/reasoning/graph-reasoning/" class="">Graph Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/graphrag/" class="">GraphRAG</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/knowledge-graphs/" class="">Knowledge Graphs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="toggle"  />
    <label for="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="flex justify-between">
      <a href="/ai-workflows/rlhf/" class="">RLHF</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b1afcafdefac57f3420f64e23d73f05d" class="toggle"  />
    <label for="section-b1afcafdefac57f3420f64e23d73f05d" class="flex justify-between">
      <a href="/ai-workflows/rlhf/rlhf2006/" class="">RLHF 2006</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/rlhf/rlhf2006/instruct_gpt_codes_params/" class="">Instruct Gpt Codes Params</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ca53d32fab0e1a54fdf5627349d86bfc" class="toggle"  />
    <label for="section-ca53d32fab0e1a54fdf5627349d86bfc" class="flex justify-between">
      <a href="/ai-workflows/eval/" class="">AI Evaluation</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/healthcare/" class="">Healthcare</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="toggle"  />
    <label for="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/" class="">Domain</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-45ba5974905f86df95925365835eadbb" class="toggle"  />
    <label for="section-45ba5974905f86df95925365835eadbb" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/ai-in-healthcare/" class="">AI in Healthcare</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/" class="">C2 Clinical Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/" class="">C3 ML Healthcare</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/" class="">C4 AI Evaluations</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c5_capstone/" class="">C5 Capstone Projects</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9722ba71bf098ab02c3220d6e8d9056f" class="toggle"  />
    <label for="section-9722ba71bf098ab02c3220d6e8d9056f" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/hands-on-healthcare-data/" class="">Hands-On Healthcare Data</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/data/" class="">Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/clinical_ai/" class="">AI Applications</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ipark/" class="">Inhee Park, PhD - Resume</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>










  
<ul>
  
  <li>
    <a href="https://www.linkedin.com/in/inheepark/"  target="_blank" rel="noopener">
        ‚ï∞‚îÄ‚îÄLinkedIn
      </a>
  </li>
  
  <li>
    <a href="https://github.com/imipark/"  target="_blank" rel="noopener">
        ‚ï∞‚îÄ‚îÄGitHub
      </a>
  </li>
  
  <li>
    <a href="/posts/"  target="_blank" rel="noopener">
        ‚ï∞‚îÄ‚îÄBlog
      </a>
  </li>
  
  <li>
    <a href="https://iparkirk.github.io"  target="_blank" rel="noopener">
        ‚ï∞‚îÄ‚îÄOld Web
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Inputs and Data Preparation for Multimodal LLMs</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#---input-format">üñºÔ∏è + üí¨ Input Format</a></li>
            <li><a href="#data-preparation-pipeline">Data Preparation Pipeline</a></li>
            <li><a href="#example-entry-blink-style">Example Entry (BLINK-style)</a></li>
            <li><a href="#use-cases">Use Cases</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><p align="center">
<img src="/images/AIR_logo.png" alt="AI Reasoning Logo" width="200"/>
<strong style="font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;">
Inputs and Data Preparation for Multimodal LLMs
</strong>
</p>
<hr>
<p>Multimodal LLMs are language models that can process and reason over <strong>multiple data types</strong>, especially:</p>
<ul>
<li><strong>Text</strong></li>
<li><strong>Images</strong></li>
<li><em>(Optionally: audio, video, or other modalities)</em></li>
</ul>
<p>They are designed to understand <strong>both visual and linguistic context</strong>, enabling tasks like visual question answering, image captioning, grounding, and perception-based reasoning.</p>
<hr>
<h3 id="---input-format">
  üñºÔ∏è + üí¨ Input Format
  <a class="anchor" href="#---input-format">#</a>
</h3>
<p>Inputs typically include:</p>
<ul>
<li><strong>Image(s)</strong>: RGB images, optionally annotated (e.g., bounding boxes, circles)</li>
<li><strong>Text Prompt</strong>: Task instruction or question (e.g., &ldquo;Which object is closer?&rdquo;)</li>
<li><strong>Answer Choices</strong> (optional): For classification-style tasks like BLINK</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>inputs <span style="color:#04a5e5;font-weight:bold">=</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#40a02b">&#34;images&#34;</span>: [<span style="color:#04a5e5;font-weight:bold">...</span>],   <span style="color:#9ca0b0;font-style:italic"># preprocessed (resized, normalized) tensors or raw image paths</span>
</span></span><span style="display:flex;"><span>  <span style="color:#40a02b">&#34;text&#34;</span>: <span style="color:#40a02b">&#34;Which point is closer to the camera? (A) A (B) B&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Some APIs accept JSON-style mixed prompts with interleaved text and image tokens.</p>
<hr>
<h3 id="data-preparation-pipeline">
  Data Preparation Pipeline
  <a class="anchor" href="#data-preparation-pipeline">#</a>
</h3>
<ol>
<li>
<p><strong>Image Collection</strong><br>
Use open datasets (COCO, LVIS, IIW, WikiArt) or your own; resize consistently (e.g., 224x224 or 1024px).</p>
</li>
<li>
<p><strong>Visual Prompt Annotation</strong><br>
Add circles (keypoints), boxes (objects), or masks (regions) using tools like OpenCV, CVAT, or FiftyOne.</p>
</li>
<li>
<p><strong>Text Prompt Design</strong><br>
Write clear, natural or templated questions.</p>
<ul>
<li>e.g., &ldquo;Which image completes the jigsaw?&rdquo;</li>
<li>e.g., &ldquo;Is the laptop to the left of the bear?&rdquo;</li>
</ul>
</li>
<li>
<p><strong>Label Encoding</strong></p>
<ul>
<li>Classification: (A), (B), (C), (D)</li>
<li>Generation: Free-text string</li>
<li>Evaluation: Ground-truth match or similarity</li>
</ul>
</li>
</ol>
<hr>
<h3 id="example-entry-blink-style">
  Example Entry (BLINK-style)
  <a class="anchor" href="#example-entry-blink-style">#</a>
</h3>
<div class="highlight"><pre tabindex="0" style="color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#8839ef">&#34;image_1&#34;</span>: <span style="color:#40a02b">&#34;img001.jpg&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#8839ef">&#34;image_2&#34;</span>: <span style="color:#40a02b">&#34;img002.jpg&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#8839ef">&#34;prompt&#34;</span>: <span style="color:#40a02b">&#34;Which point corresponds to the reference point (REF)? (A) A (B) B (C) C (D) D&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#8839ef">&#34;visual_prompts&#34;</span>: {
</span></span><span style="display:flex;"><span>    <span style="color:#8839ef">&#34;ref_point&#34;</span>: [<span style="color:#d20f39">x</span><span style="color:#fe640b">1</span>, <span style="color:#d20f39">y</span><span style="color:#fe640b">1</span>],
</span></span><span style="display:flex;"><span>    <span style="color:#8839ef">&#34;candidates&#34;</span>: [[<span style="color:#d20f39">x</span><span style="color:#fe640b">2</span>, <span style="color:#d20f39">y</span><span style="color:#fe640b">2</span>], [<span style="color:#d20f39">x</span><span style="color:#fe640b">3</span>, <span style="color:#d20f39">y</span><span style="color:#fe640b">3</span>], [<span style="color:#d20f39">x</span><span style="color:#fe640b">4</span>, <span style="color:#d20f39">y</span><span style="color:#fe640b">4</span>], [<span style="color:#d20f39">x</span><span style="color:#fe640b">5</span>, <span style="color:#d20f39">y</span><span style="color:#fe640b">5</span>]]
</span></span><span style="display:flex;"><span>  },
</span></span><span style="display:flex;"><span>  <span style="color:#8839ef">&#34;answer&#34;</span>: <span style="color:#40a02b">&#34;C&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><hr>
<h3 id="use-cases">
  Use Cases
  <a class="anchor" href="#use-cases">#</a>
</h3>
<ul>
<li>Visual Question Answering (VQA)</li>
<li>Visual Grounding &amp; Alignment</li>
<li>Perception-based Evaluation (e.g., BLINK)</li>
<li>Medical Image Reasoning</li>
<li>Image Captioning / Retrieval</li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#---input-format">üñºÔ∏è + üí¨ Input Format</a></li>
            <li><a href="#data-preparation-pipeline">Data Preparation Pipeline</a></li>
            <li><a href="#example-entry-blink-style">Example Entry (BLINK-style)</a></li>
            <li><a href="#use-cases">Use Cases</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












