<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="


Data-Centric AI



Reference: MIT Data-Centric AI course


  
      
          Topic Q&amp;A Summary
      
  
  
      
          1. Data-Centric AI vs. Model-Centric AI
      
      
          2. Label Errors and Confident Learning
      
      
          3. Advanced Confident Learning, LLM and GenAI applications
      
      
          4. Class Imbalance, Outliers, and Distribution Shift
      
      
          5. Dataset Creation and Curation
      
      
          6. Data-centric Evaluation of ML Models
      
      
          7. Data Curation for LLMs
      
      
          8. Growing or Compressing Datasets
      
      
          9. Interpretability in Data-Centric ML
      
      
          10. Encoding Human Priors: Data Augmentation and Prompt Engineering
      
      
          11. Data Privacy and Security
      
  


  Q1: How does Data-Centric AI differ from Model-Centric AI?
  #


Model-Centric AI improves models assuming fixed data.
Data-Centric AI improves data quality, coverage, and structure, recognizing data as the bottleneck for model success.


  Q2: Why are Label Errors and Confident Learning crucial?
  #


Label errors silently degrade model performance.
Confident Learning identifies mislabeled data points using model predictions and corrects them systematically.


  Q3: What advances exist in Confident Learning and LLM/GenAI applications?
  #


Advanced Confident Learning enhances robustness to noisy outputs.
It&rsquo;s applied to improve foundation models like LLMs by cleaning training and synthetic data.


  Q4: How are Class Imbalance, Outliers, and Distribution Shift handled?
  #


Class imbalance is managed via over/under-sampling, SMOTE, and weighting.
Outliers are detected using isolation techniques or autoencoders.
Distribution shifts are diagnosed and corrected with careful monitoring and adaptation.


  Q5: What is essential about Dataset Creation and Curation?
  #


Good datasets start with thoughtful design, balanced sampling, and robust label validation.
Crowdsourcing must be augmented with consensus models like Dawid-Skene or CROWDLAB.


  Q6: How does Data-Centric Evaluation of ML Models change standard practices?
  #


Not just global metrics: need slice-based evaluation, error analysis, and influence functions.
Subpopulations and rare cases must be properly assessed.


  Q7: How is Data Curation for LLMs unique?
  #


LLMs memorize training data deeply.
Curating high-quality fine-tuning datasets, synthetic data filtering, and evaluation by uncertainty quantification is critical.


  Q8: What role does Growing or Compressing Datasets play?
  #


Active learning grows datasets smartly by labeling only informative samples.
Core-set selection compresses datasets while preserving model performance, making training efficient.


  Q9: How does Interpretability relate to Data-Centric AI?
  #


Models are only as interpretable as their features.
Human-in-the-loop feature engineering ensures features are understandable, relevant, and actionable.


  Q10: How do we Encode Human Priors into Models?
  #


Via Data Augmentation: enriching datasets to encode invariances (e.g., rotation, Mixup).
Via Prompt Engineering: guiding LLMs at inference time with careful input manipulation.


  Q11: How do we secure Data Privacy and Security?
  #


ML models risk leaking sensitive information.
Defenses include membership inference mitigation, differential privacy, model regularization, and careful threat modeling.


  Q12: How does the full picture of Data-Centric AI flow?
  #


Frame the problem with a Data-Centric mindset.
Curate a well-constructed, balanced, and interpretable dataset.
Detect and fix label errors, outliers, and bias early.
Train models, but always re-evaluate data quality after errors.
Focus evaluations on slices and high-loss examples.
Grow datasets when needed (active learning) or compress intelligently (core-sets).
Secure models against privacy attacks.
Continuously refine, because data evolves in deployment.


  Q13: Final Takeaway
  #


In Data-Centric AI, data is the model.
Every improvement — in accuracy, fairness, robustness, trust, and security — roots back to the data.
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://imipark.github.io/ai-workflows/data-modeling/data-centric-ai/">
  <meta property="og:site_name" content="AI Reasoning">
  <meta property="og:title" content="Data-Centric AI (DCAI)">
  <meta property="og:description" content="Data-Centric AI Reference: MIT Data-Centric AI course Topic Q&amp;A Summary 1. Data-Centric AI vs. Model-Centric AI 2. Label Errors and Confident Learning 3. Advanced Confident Learning, LLM and GenAI applications 4. Class Imbalance, Outliers, and Distribution Shift 5. Dataset Creation and Curation 6. Data-centric Evaluation of ML Models 7. Data Curation for LLMs 8. Growing or Compressing Datasets 9. Interpretability in Data-Centric ML 10. Encoding Human Priors: Data Augmentation and Prompt Engineering 11. Data Privacy and Security Q1: How does Data-Centric AI differ from Model-Centric AI? # Model-Centric AI improves models assuming fixed data. Data-Centric AI improves data quality, coverage, and structure, recognizing data as the bottleneck for model success. Q2: Why are Label Errors and Confident Learning crucial? # Label errors silently degrade model performance. Confident Learning identifies mislabeled data points using model predictions and corrects them systematically. Q3: What advances exist in Confident Learning and LLM/GenAI applications? # Advanced Confident Learning enhances robustness to noisy outputs. It’s applied to improve foundation models like LLMs by cleaning training and synthetic data. Q4: How are Class Imbalance, Outliers, and Distribution Shift handled? # Class imbalance is managed via over/under-sampling, SMOTE, and weighting. Outliers are detected using isolation techniques or autoencoders. Distribution shifts are diagnosed and corrected with careful monitoring and adaptation. Q5: What is essential about Dataset Creation and Curation? # Good datasets start with thoughtful design, balanced sampling, and robust label validation. Crowdsourcing must be augmented with consensus models like Dawid-Skene or CROWDLAB. Q6: How does Data-Centric Evaluation of ML Models change standard practices? # Not just global metrics: need slice-based evaluation, error analysis, and influence functions. Subpopulations and rare cases must be properly assessed. Q7: How is Data Curation for LLMs unique? # LLMs memorize training data deeply. Curating high-quality fine-tuning datasets, synthetic data filtering, and evaluation by uncertainty quantification is critical. Q8: What role does Growing or Compressing Datasets play? # Active learning grows datasets smartly by labeling only informative samples. Core-set selection compresses datasets while preserving model performance, making training efficient. Q9: How does Interpretability relate to Data-Centric AI? # Models are only as interpretable as their features. Human-in-the-loop feature engineering ensures features are understandable, relevant, and actionable. Q10: How do we Encode Human Priors into Models? # Via Data Augmentation: enriching datasets to encode invariances (e.g., rotation, Mixup). Via Prompt Engineering: guiding LLMs at inference time with careful input manipulation. Q11: How do we secure Data Privacy and Security? # ML models risk leaking sensitive information. Defenses include membership inference mitigation, differential privacy, model regularization, and careful threat modeling. Q12: How does the full picture of Data-Centric AI flow? # Frame the problem with a Data-Centric mindset. Curate a well-constructed, balanced, and interpretable dataset. Detect and fix label errors, outliers, and bias early. Train models, but always re-evaluate data quality after errors. Focus evaluations on slices and high-loss examples. Grow datasets when needed (active learning) or compress intelligently (core-sets). Secure models against privacy attacks. Continuously refine, because data evolves in deployment. Q13: Final Takeaway # In Data-Centric AI, data is the model. Every improvement — in accuracy, fairness, robustness, trust, and security — roots back to the data.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="website">
<title>Data-Centric AI (DCAI) | AI Reasoning</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="https://imipark.github.io/ai-workflows/data-modeling/data-centric-ai/">
<link rel="stylesheet" href="/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.4014c58b4ff93b711a1e1d78f5ec4df7c78de5b479f64af51be6af1f4dace7eb.js" integrity="sha256-QBTFi0/5O3EaHh149exN98eN5bR59kr1G&#43;avH02s5&#43;s=" crossorigin="anonymous"></script>
<link rel="alternate" type="application/rss+xml" href="https://imipark.github.io/ai-workflows/data-modeling/data-centric-ai/index.xml" title="AI Reasoning" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>AI Reasoning</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>













  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ai-workflows/" class="">AI Reasoning Stack</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-f8e502c34e18a04e1c3aecf192b0355a" class="toggle" checked />
    <label for="section-f8e502c34e18a04e1c3aecf192b0355a" class="flex justify-between">
      <a href="/ai-workflows/data-modeling/" class="">Data Modeling</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-906a2243f4790a09188fae70fbc32dbd" class="toggle" checked />
    <label for="section-906a2243f4790a09188fae70fbc32dbd" class="flex justify-between">
      <a href="/ai-workflows/data-modeling/data-centric-ai/" class="active">Data-Centric AI (DCAI)</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-5bf1c216f4b747bd7c2f992550ff09a1" class="toggle"  />
    <label for="section-5bf1c216f4b747bd7c2f992550ff09a1" class="flex justify-between">
      <a href="/ai-workflows/genai-systems/" class="">GenAI Systems</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8cbfd420d91de13f61964bf971127312" class="toggle"  />
    <label for="section-8cbfd420d91de13f61964bf971127312" class="flex justify-between">
      <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/" class="">5-Day GenAI with Google 2005</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day1_foundational_llm_text_generation/" class="">Day 1 - Foundational LLMs &amp; Text Generation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day1_prompt_engineering/" class="">Day 1 – Prompt Engineering</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day2_embeddings_vectordb/" class="">Day 2 – Embeddings &amp; Vector Databases</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day3_generative_agents/" class="">Day 3 – Generative Agents</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day4_domainspecific_llms/" class="">Day 4 – Domain-Specific LLMs</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day5_mlops/" class="">Day 5 – MLOps for Generative AI</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/multimodel_llms/" class="">Multimodal LLMs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-17ba62e37c896ad50105fedeb71549dd" class="toggle"  />
    <label for="section-17ba62e37c896ad50105fedeb71549dd" class="flex justify-between">
      <a href="/ai-workflows/reasoning/" class="">Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cd94e161670d28ecff992edf840d76e8" class="toggle"  />
    <label for="section-cd94e161670d28ecff992edf840d76e8" class="flex justify-between">
      <a href="/ai-workflows/reasoning/causality/" class="">Causality</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-ai/" class="">Causal AI</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-inference/" class="">Causal Inference</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7e468aa05ceb7c844f07a2e754606b76" class="toggle"  />
    <label for="section-7e468aa05ceb7c844f07a2e754606b76" class="flex justify-between">
      <a href="/ai-workflows/reasoning/graph-reasoning/" class="">Graph Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/graphrag/" class="">GraphRAG</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/knowledge-graphs/" class="">Knowledge Graphs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="toggle"  />
    <label for="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="flex justify-between">
      <a href="/ai-workflows/rlhf/" class="">RLHF</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b1afcafdefac57f3420f64e23d73f05d" class="toggle"  />
    <label for="section-b1afcafdefac57f3420f64e23d73f05d" class="flex justify-between">
      <a href="/ai-workflows/rlhf/rlhf2006/" class="">RLHF 2006</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/rlhf/rlhf2006/instruct_gpt_codes_params/" class="">Instruct Gpt Codes Params</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ca53d32fab0e1a54fdf5627349d86bfc" class="toggle"  />
    <label for="section-ca53d32fab0e1a54fdf5627349d86bfc" class="flex justify-between">
      <a href="/ai-workflows/eval/" class="">AI Evaluation</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/healthcare/" class="">Healthcare</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="toggle"  />
    <label for="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/" class="">Domain</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-45ba5974905f86df95925365835eadbb" class="toggle"  />
    <label for="section-45ba5974905f86df95925365835eadbb" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/ai-in-healthcare/" class="">AI in Healthcare</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/" class="">C2 Clinical Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/" class="">C3 ML Healthcare</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/" class="">C4 AI Evaluations</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c5_capstone/" class="">C5 Capstone Projects</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9722ba71bf098ab02c3220d6e8d9056f" class="toggle"  />
    <label for="section-9722ba71bf098ab02c3220d6e8d9056f" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/hands-on-healthcare-data/" class="">Hands-On Healthcare Data</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/data/" class="">Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/clinical_ai/" class="">AI Applications</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ipark/" class="">Inhee Park, PhD - Resume</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>










  
<ul>
  
  <li>
    <a href="https://www.linkedin.com/in/inheepark/"  target="_blank" rel="noopener">
        ╰──LinkedIn
      </a>
  </li>
  
  <li>
    <a href="https://github.com/imipark/"  target="_blank" rel="noopener">
        ╰──GitHub
      </a>
  </li>
  
  <li>
    <a href="/posts/"  target="_blank" rel="noopener">
        ╰──Blog
      </a>
  </li>
  
  <li>
    <a href="https://iparkirk.github.io"  target="_blank" rel="noopener">
        ╰──Old Web
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Data-Centric AI (DCAI)</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#q1-how-does-data-centric-ai-differ-from-model-centric-ai">Q1: How does Data-Centric AI differ from Model-Centric AI?</a></li>
            <li><a href="#q2-why-are-label-errors-and-confident-learning-crucial">Q2: Why are Label Errors and Confident Learning crucial?</a></li>
            <li><a href="#q3-what-advances-exist-in-confident-learning-and-llmgenai-applications">Q3: What advances exist in Confident Learning and LLM/GenAI applications?</a></li>
            <li><a href="#q4-how-are-class-imbalance-outliers-and-distribution-shift-handled">Q4: How are Class Imbalance, Outliers, and Distribution Shift handled?</a></li>
            <li><a href="#q5-what-is-essential-about-dataset-creation-and-curation">Q5: What is essential about Dataset Creation and Curation?</a></li>
            <li><a href="#q6-how-does-data-centric-evaluation-of-ml-models-change-standard-practices">Q6: How does Data-Centric Evaluation of ML Models change standard practices?</a></li>
            <li><a href="#q7-how-is-data-curation-for-llms-unique">Q7: How is Data Curation for LLMs unique?</a></li>
            <li><a href="#q8-what-role-does-growing-or-compressing-datasets-play">Q8: What role does Growing or Compressing Datasets play?</a></li>
            <li><a href="#q9-how-does-interpretability-relate-to-data-centric-ai">Q9: How does Interpretability relate to Data-Centric AI?</a></li>
            <li><a href="#q10-how-do-we-encode-human-priors-into-models">Q10: How do we Encode Human Priors into Models?</a></li>
            <li><a href="#q11-how-do-we-secure-data-privacy-and-security">Q11: How do we secure Data Privacy and Security?</a></li>
            <li><a href="#q12-how-does-the-full-picture-of-data-centric-ai-flow">Q12: How does the full picture of Data-Centric AI flow?</a></li>
            <li><a href="#q13-final-takeaway">Q13: Final Takeaway</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><p align="center">
<img src="/images/AIR_logo.png" alt="AI Reasoning Logo" width="200"/>
<strong style="font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;">
Data-Centric AI
</strong>
</p>
<ul>
<li>Reference: <a href="https://dcai.csail.mit.edu/">MIT Data-Centric AI course</a></li>
</ul>
<table>
  <thead>
      <tr>
          <th>Topic Q&amp;A Summary</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/data-centric-vs-model-centric/">1. Data-Centric AI vs. Model-Centric AI</a></td>
      </tr>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/label-errors/">2. Label Errors and Confident Learning</a></td>
      </tr>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/advanced-confident-learning/">3. Advanced Confident Learning, LLM and GenAI applications</a></td>
      </tr>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/class-imbalance-outliers-distribution-shift/">4. Class Imbalance, Outliers, and Distribution Shift</a></td>
      </tr>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/dataset-creation-curation/">5. Dataset Creation and Curation</a></td>
      </tr>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/data-centric-evaluation/">6. Data-centric Evaluation of ML Models</a></td>
      </tr>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/data-curation-llms/">7. Data Curation for LLMs</a></td>
      </tr>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/growing-or-compressing-datasets/">8. Growing or Compressing Datasets</a></td>
      </tr>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/interpretability-data-centric-ml/">9. Interpretability in Data-Centric ML</a></td>
      </tr>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/encoding-human-priors/">10. Encoding Human Priors: Data Augmentation and Prompt Engineering</a></td>
      </tr>
      <tr>
          <td><a href="/ai-workflows/data-modeling/data-centric-ai/data-privacy-security/">11. Data Privacy and Security</a></td>
      </tr>
  </tbody>
</table>
<h3 id="q1-how-does-data-centric-ai-differ-from-model-centric-ai">
  Q1: How does Data-Centric AI differ from Model-Centric AI?
  <a class="anchor" href="#q1-how-does-data-centric-ai-differ-from-model-centric-ai">#</a>
</h3>
<ul>
<li>Model-Centric AI improves models assuming fixed data.</li>
<li>Data-Centric AI improves data quality, coverage, and structure, recognizing data as the bottleneck for model success.</li>
</ul>
<h3 id="q2-why-are-label-errors-and-confident-learning-crucial">
  Q2: Why are Label Errors and Confident Learning crucial?
  <a class="anchor" href="#q2-why-are-label-errors-and-confident-learning-crucial">#</a>
</h3>
<ul>
<li>Label errors silently degrade model performance.</li>
<li>Confident Learning identifies mislabeled data points using model predictions and corrects them systematically.</li>
</ul>
<h3 id="q3-what-advances-exist-in-confident-learning-and-llmgenai-applications">
  Q3: What advances exist in Confident Learning and LLM/GenAI applications?
  <a class="anchor" href="#q3-what-advances-exist-in-confident-learning-and-llmgenai-applications">#</a>
</h3>
<ul>
<li>Advanced Confident Learning enhances robustness to noisy outputs.</li>
<li>It&rsquo;s applied to improve foundation models like LLMs by cleaning training and synthetic data.</li>
</ul>
<h3 id="q4-how-are-class-imbalance-outliers-and-distribution-shift-handled">
  Q4: How are Class Imbalance, Outliers, and Distribution Shift handled?
  <a class="anchor" href="#q4-how-are-class-imbalance-outliers-and-distribution-shift-handled">#</a>
</h3>
<ul>
<li>Class imbalance is managed via over/under-sampling, SMOTE, and weighting.</li>
<li>Outliers are detected using isolation techniques or autoencoders.</li>
<li>Distribution shifts are diagnosed and corrected with careful monitoring and adaptation.</li>
</ul>
<h3 id="q5-what-is-essential-about-dataset-creation-and-curation">
  Q5: What is essential about Dataset Creation and Curation?
  <a class="anchor" href="#q5-what-is-essential-about-dataset-creation-and-curation">#</a>
</h3>
<ul>
<li>Good datasets start with thoughtful design, balanced sampling, and robust label validation.</li>
<li>Crowdsourcing must be augmented with consensus models like Dawid-Skene or CROWDLAB.</li>
</ul>
<h3 id="q6-how-does-data-centric-evaluation-of-ml-models-change-standard-practices">
  Q6: How does Data-Centric Evaluation of ML Models change standard practices?
  <a class="anchor" href="#q6-how-does-data-centric-evaluation-of-ml-models-change-standard-practices">#</a>
</h3>
<ul>
<li>Not just global metrics: need slice-based evaluation, error analysis, and influence functions.</li>
<li>Subpopulations and rare cases must be properly assessed.</li>
</ul>
<h3 id="q7-how-is-data-curation-for-llms-unique">
  Q7: How is Data Curation for LLMs unique?
  <a class="anchor" href="#q7-how-is-data-curation-for-llms-unique">#</a>
</h3>
<ul>
<li>LLMs memorize training data deeply.</li>
<li>Curating high-quality fine-tuning datasets, synthetic data filtering, and evaluation by uncertainty quantification is critical.</li>
</ul>
<h3 id="q8-what-role-does-growing-or-compressing-datasets-play">
  Q8: What role does Growing or Compressing Datasets play?
  <a class="anchor" href="#q8-what-role-does-growing-or-compressing-datasets-play">#</a>
</h3>
<ul>
<li><strong>Active learning</strong> grows datasets smartly by labeling only informative samples.</li>
<li><strong>Core-set selection</strong> compresses datasets while preserving model performance, making training efficient.</li>
</ul>
<h3 id="q9-how-does-interpretability-relate-to-data-centric-ai">
  Q9: How does Interpretability relate to Data-Centric AI?
  <a class="anchor" href="#q9-how-does-interpretability-relate-to-data-centric-ai">#</a>
</h3>
<ul>
<li>Models are only as interpretable as their features.</li>
<li>Human-in-the-loop feature engineering ensures features are understandable, relevant, and actionable.</li>
</ul>
<h3 id="q10-how-do-we-encode-human-priors-into-models">
  Q10: How do we Encode Human Priors into Models?
  <a class="anchor" href="#q10-how-do-we-encode-human-priors-into-models">#</a>
</h3>
<ul>
<li>Via <strong>Data Augmentation</strong>: enriching datasets to encode invariances (e.g., rotation, Mixup).</li>
<li>Via <strong>Prompt Engineering</strong>: guiding LLMs at inference time with careful input manipulation.</li>
</ul>
<h3 id="q11-how-do-we-secure-data-privacy-and-security">
  Q11: How do we secure Data Privacy and Security?
  <a class="anchor" href="#q11-how-do-we-secure-data-privacy-and-security">#</a>
</h3>
<ul>
<li>ML models risk leaking sensitive information.</li>
<li>Defenses include membership inference mitigation, differential privacy, model regularization, and careful threat modeling.</li>
</ul>
<h3 id="q12-how-does-the-full-picture-of-data-centric-ai-flow">
  Q12: How does the full picture of Data-Centric AI flow?
  <a class="anchor" href="#q12-how-does-the-full-picture-of-data-centric-ai-flow">#</a>
</h3>
<ol>
<li>Frame the problem with a Data-Centric mindset.</li>
<li>Curate a well-constructed, balanced, and interpretable dataset.</li>
<li>Detect and fix label errors, outliers, and bias early.</li>
<li>Train models, but always re-evaluate data quality after errors.</li>
<li>Focus evaluations on slices and high-loss examples.</li>
<li>Grow datasets when needed (active learning) or compress intelligently (core-sets).</li>
<li>Secure models against privacy attacks.</li>
<li>Continuously refine, because <strong>data evolves</strong> in deployment.</li>
</ol>
<h3 id="q13-final-takeaway">
  Q13: Final Takeaway
  <a class="anchor" href="#q13-final-takeaway">#</a>
</h3>
<ul>
<li>In Data-Centric AI, <strong>data is the model</strong>.</li>
<li>Every improvement — in accuracy, fairness, robustness, trust, and security — roots back to the data.</li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#q1-how-does-data-centric-ai-differ-from-model-centric-ai">Q1: How does Data-Centric AI differ from Model-Centric AI?</a></li>
            <li><a href="#q2-why-are-label-errors-and-confident-learning-crucial">Q2: Why are Label Errors and Confident Learning crucial?</a></li>
            <li><a href="#q3-what-advances-exist-in-confident-learning-and-llmgenai-applications">Q3: What advances exist in Confident Learning and LLM/GenAI applications?</a></li>
            <li><a href="#q4-how-are-class-imbalance-outliers-and-distribution-shift-handled">Q4: How are Class Imbalance, Outliers, and Distribution Shift handled?</a></li>
            <li><a href="#q5-what-is-essential-about-dataset-creation-and-curation">Q5: What is essential about Dataset Creation and Curation?</a></li>
            <li><a href="#q6-how-does-data-centric-evaluation-of-ml-models-change-standard-practices">Q6: How does Data-Centric Evaluation of ML Models change standard practices?</a></li>
            <li><a href="#q7-how-is-data-curation-for-llms-unique">Q7: How is Data Curation for LLMs unique?</a></li>
            <li><a href="#q8-what-role-does-growing-or-compressing-datasets-play">Q8: What role does Growing or Compressing Datasets play?</a></li>
            <li><a href="#q9-how-does-interpretability-relate-to-data-centric-ai">Q9: How does Interpretability relate to Data-Centric AI?</a></li>
            <li><a href="#q10-how-do-we-encode-human-priors-into-models">Q10: How do we Encode Human Priors into Models?</a></li>
            <li><a href="#q11-how-do-we-secure-data-privacy-and-security">Q11: How do we secure Data Privacy and Security?</a></li>
            <li><a href="#q12-how-does-the-full-picture-of-data-centric-ai-flow">Q12: How does the full picture of Data-Centric AI flow?</a></li>
            <li><a href="#q13-final-takeaway">Q13: Final Takeaway</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












