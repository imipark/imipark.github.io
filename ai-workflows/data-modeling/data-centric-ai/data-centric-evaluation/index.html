<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  Data-Centric Evaluation of ML Models
  #



  Q1: What is the typical ML workflow before deployment?
  #


Collect data and define the ML task.
Explore and preprocess the data.
Train a straightforward model.
Investigate shortcomings in the model and dataset.
Improve dataset and model iteratively.
Deploy the model and monitor for new issues.


  Q2: Why is model evaluation critical?
  #


Evaluation affects practical outcomes in real-world applications.
Poor evaluation choices can lead to misleading or harmful models.


  Q3: What are examples of evaluation metrics for classification?
  #


Accuracy, balanced accuracy, precision, recall, log loss, AUROC, calibration error.


  Q4: What are some pitfalls in model evaluation?
  #


Data leakage by using non-held-out data.
Misspecified metrics hiding failures in subpopulations.
Validation data not representing deployment settings.
Label errors.


  Q5: How is text generation model evaluation different?
  #


Human evaluations (👍👎 or Likert scales).
LLM evaluations with multiple criteria.
Automated metrics like ROUGE, BLEU, and Perplexity.


  Q6: What is a data slice?
  #


A subset of the dataset sharing a common characteristic, e.g., different sensor types, demographics.


  Q7: Why is it insufficient to delete sensitive features to address slice fairness?
  #


Slice membership information may be correlated with other features.


  Q8: How can we improve model performance for underperforming slices?
  #


Use a more flexible model.
Over-sample the minority subgroup.
Collect more data from the subgroup.
Engineer new features that better capture subgroup specifics.


  Q9: How to discover underperforming subpopulations?
  #


Sort validation examples by loss.
Cluster high-loss examples to find commonalities.


  Q10: What are typical causes of wrong predictions?
  #


Incorrect labels.
Examples that do not belong to any class.
Outlier examples.
Model type limitations.
Conflicting or noisy dataset labels.


  Q11: What actions can address wrong predictions?
  #


Correct labels.
Remove fundamentally unpredictable examples.
Augment or normalize outlier examples.
Fit better model architectures or do feature engineering.
Enrich the dataset to distinguish overlapping classes.


  Q12: What is the concept of leave-one-out influence?
  #


Measure the impact of omitting a datapoint on the model’s validation performance.


  Q13: What is Data Shapley?
  #


A method that averages the influence of a datapoint over all subsets containing it, providing a fairer measure of its importance.


  Q14: How can we approximate influence?
  #


Monte Carlo sampling methods.
Closed-form approximations for simple models like linear regression and k-NN.


  Q15: Why review influential samples?
  #


Correcting highly influential mislabeled examples can lead to significant accuracy improvements.



  References
  #


Cook’s Distance (Linear Regression Influence)
Similarity Search Scaling for Big Data (Johnson et al., 2019)
Trustworthy Data Influence Estimation
Confident Learning and Cleanlab Project
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://imipark.github.io/ai-workflows/data-modeling/data-centric-ai/data-centric-evaluation/">
  <meta property="og:site_name" content="AI Reasoning">
  <meta property="og:title" content="Data-Centric Evaluation of ML Models">
  <meta property="og:description" content="Data-Centric Evaluation of ML Models # Q1: What is the typical ML workflow before deployment? # Collect data and define the ML task. Explore and preprocess the data. Train a straightforward model. Investigate shortcomings in the model and dataset. Improve dataset and model iteratively. Deploy the model and monitor for new issues. Q2: Why is model evaluation critical? # Evaluation affects practical outcomes in real-world applications. Poor evaluation choices can lead to misleading or harmful models. Q3: What are examples of evaluation metrics for classification? # Accuracy, balanced accuracy, precision, recall, log loss, AUROC, calibration error. Q4: What are some pitfalls in model evaluation? # Data leakage by using non-held-out data. Misspecified metrics hiding failures in subpopulations. Validation data not representing deployment settings. Label errors. Q5: How is text generation model evaluation different? # Human evaluations (👍👎 or Likert scales). LLM evaluations with multiple criteria. Automated metrics like ROUGE, BLEU, and Perplexity. Q6: What is a data slice? # A subset of the dataset sharing a common characteristic, e.g., different sensor types, demographics. Q7: Why is it insufficient to delete sensitive features to address slice fairness? # Slice membership information may be correlated with other features. Q8: How can we improve model performance for underperforming slices? # Use a more flexible model. Over-sample the minority subgroup. Collect more data from the subgroup. Engineer new features that better capture subgroup specifics. Q9: How to discover underperforming subpopulations? # Sort validation examples by loss. Cluster high-loss examples to find commonalities. Q10: What are typical causes of wrong predictions? # Incorrect labels. Examples that do not belong to any class. Outlier examples. Model type limitations. Conflicting or noisy dataset labels. Q11: What actions can address wrong predictions? # Correct labels. Remove fundamentally unpredictable examples. Augment or normalize outlier examples. Fit better model architectures or do feature engineering. Enrich the dataset to distinguish overlapping classes. Q12: What is the concept of leave-one-out influence? # Measure the impact of omitting a datapoint on the model’s validation performance. Q13: What is Data Shapley? # A method that averages the influence of a datapoint over all subsets containing it, providing a fairer measure of its importance. Q14: How can we approximate influence? # Monte Carlo sampling methods. Closed-form approximations for simple models like linear regression and k-NN. Q15: Why review influential samples? # Correcting highly influential mislabeled examples can lead to significant accuracy improvements. References # Cook’s Distance (Linear Regression Influence) Similarity Search Scaling for Big Data (Johnson et al., 2019) Trustworthy Data Influence Estimation Confident Learning and Cleanlab Project">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="ai-workflows">
<title>Data-Centric Evaluation of ML Models | AI Reasoning</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="https://imipark.github.io/ai-workflows/data-modeling/data-centric-ai/data-centric-evaluation/">
<link rel="stylesheet" href="/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.25b11228394de1fba390fc849b5d3bb3c6c459f06baf74d8591943d647930d5a.js" integrity="sha256-JbESKDlN4fujkPyEm107s8bEWfBrr3TYWRlD1keTDVo=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>AI Reasoning</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>













  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ai-workflows/" class="">AI Reasoning Stack</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-11214ac3b076f362925d6c6673de12d0" class="toggle" checked />
    <label for="section-11214ac3b076f362925d6c6673de12d0" class="flex justify-between">
      <a href="/ai-workflows/data-modeling/" class="">Data Modeling</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-211a3339275321c1881a08804c2b28d9" class="toggle" checked />
    <label for="section-211a3339275321c1881a08804c2b28d9" class="flex justify-between">
      <a href="/ai-workflows/data-modeling/data-centric-ai/" class="">Data-Centric AI (DCAI)</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-0a5a201c09b19922ece313b6aa71ce8f" class="toggle"  />
    <label for="section-0a5a201c09b19922ece313b6aa71ce8f" class="flex justify-between">
      <a href="/ai-workflows/genai-systems/" class="">GenAI Systems</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-f4857c1847bb17cfb0035cc71a5366c1" class="toggle"  />
    <label for="section-f4857c1847bb17cfb0035cc71a5366c1" class="flex justify-between">
      <a href="/ai-workflows/genai-systems/5-day-genai-google/" class="">5-Day GenAI with Google</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google/day1_foundational_llm_text_generation/" class="">Day 1 - Foundational LLMs &amp; Text Generation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google/day1_prompt_engineering/" class="">Day 1 – Prompt Engineering</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google/day2_embeddings_vectordb/" class="">Day 2 – Embeddings &amp; Vector Databases</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google/day3_generative_agents/" class="">Day 3 – Generative Agents</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google/day4_domainspecific_llms/" class="">Day 4 – Domain-Specific LLMs</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google/day5_mlops/" class="">Day 5 – MLOps for Generative AI</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b4a719ff8289f19d4cb311dacee3340e" class="toggle"  />
    <label for="section-b4a719ff8289f19d4cb311dacee3340e" class="flex justify-between">
      <a href="/ai-workflows/genai-systems/ai_agents/" class="">AI Agents</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/prompt_engineering/" class="">Prompt Engineering</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-03684c6e891307ee8c9dcf20c1d978f6" class="toggle"  />
    <label for="section-03684c6e891307ee8c9dcf20c1d978f6" class="flex justify-between">
      <a href="/ai-workflows/alignment-reasoning/" class="">Alignment &amp; Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-bb5592811c186c31064caec5ee15a92d" class="toggle"  />
    <label for="section-bb5592811c186c31064caec5ee15a92d" class="flex justify-between">
      <a href="/ai-workflows/alignment-reasoning/causality/" class="">Causality</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/alignment-reasoning/causality/causal-ai/" class="">Causal AI</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/alignment-reasoning/causality/causal-inference/" class="">Causal Inference</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9c28f1d660c5ac029fadc3dc50d9e908" class="toggle"  />
    <label for="section-9c28f1d660c5ac029fadc3dc50d9e908" class="flex justify-between">
      <a href="/ai-workflows/alignment-reasoning/graph-reasoning/" class="">Graph Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/alignment-reasoning/graph-reasoning/graphrag/" class="">GraphRAG</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/alignment-reasoning/graph-reasoning/knowledge-graphs/" class="">Knowledge Graphs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-636a4e7efc4b2fba162f5cf2cc25004b" class="toggle"  />
    <label for="section-636a4e7efc4b2fba162f5cf2cc25004b" class="flex justify-between">
      <a href="/ai-workflows/alignment-reasoning/rlhf/" class="">RLHF</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ba9c4cdb2ff4e72821aba3b5dbda6ebf" class="toggle"  />
    <label for="section-ba9c4cdb2ff4e72821aba3b5dbda6ebf" class="flex justify-between">
      <a href="/ai-workflows/eval-methods/" class="">Eval Methods</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/mlops/" class="">MLOps</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/healthcare/" class="">Healthcare</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-49f8a15fba102060fbec99923a9f7e7f" class="toggle"  />
    <label for="section-49f8a15fba102060fbec99923a9f7e7f" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/" class="">Domain</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8fe994b0524505ef83c5591fe607d72e" class="toggle"  />
    <label for="section-8fe994b0524505ef83c5591fe607d72e" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/ai-in-healthcare/" class="">AI in Healthcare</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/" class="">C2 Clinical Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/" class="">C3 ML Healthcare</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/" class="">C4 AI Evaluations</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c5_capstone/" class="">C5 Capstone Projects</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-786aee9ce5c7a34804dfdaaae1c79408" class="toggle"  />
    <label for="section-786aee9ce5c7a34804dfdaaae1c79408" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/hands-on-healthcare-data/" class="">Hands-On Healthcare Data</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/data/" class="">Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/clinical_ai/" class="">AI</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ipark/" class="">Inhee Park, PhD - Resume</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>










  
<ul>
  
  <li>
    <a href="https://www.linkedin.com/in/inheepark/"  target="_blank" rel="noopener">
        ╰──LinkedIn
      </a>
  </li>
  
  <li>
    <a href="https://github.com/imipark/"  target="_blank" rel="noopener">
        ╰──GitHub
      </a>
  </li>
  
  <li>
    <a href="/posts/"  target="_blank" rel="noopener">
        ╰──Blog
      </a>
  </li>
  
  <li>
    <a href="https://iparkirk.github.io"  target="_blank" rel="noopener">
        ╰──Old Web
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Data-Centric Evaluation of ML Models</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#data-centric-evaluation-of-ml-models">Data-Centric Evaluation of ML Models</a>
          <ul>
            <li><a href="#q1-what-is-the-typical-ml-workflow-before-deployment">Q1: What is the typical ML workflow before deployment?</a></li>
            <li><a href="#q2-why-is-model-evaluation-critical">Q2: Why is model evaluation critical?</a></li>
            <li><a href="#q3-what-are-examples-of-evaluation-metrics-for-classification">Q3: What are examples of evaluation metrics for classification?</a></li>
            <li><a href="#q4-what-are-some-pitfalls-in-model-evaluation">Q4: What are some pitfalls in model evaluation?</a></li>
            <li><a href="#q5-how-is-text-generation-model-evaluation-different">Q5: How is text generation model evaluation different?</a></li>
            <li><a href="#q6-what-is-a-data-slice">Q6: What is a data slice?</a></li>
            <li><a href="#q7-why-is-it-insufficient-to-delete-sensitive-features-to-address-slice-fairness">Q7: Why is it insufficient to delete sensitive features to address slice fairness?</a></li>
            <li><a href="#q8-how-can-we-improve-model-performance-for-underperforming-slices">Q8: How can we improve model performance for underperforming slices?</a></li>
            <li><a href="#q9-how-to-discover-underperforming-subpopulations">Q9: How to discover underperforming subpopulations?</a></li>
            <li><a href="#q10-what-are-typical-causes-of-wrong-predictions">Q10: What are typical causes of wrong predictions?</a></li>
            <li><a href="#q11-what-actions-can-address-wrong-predictions">Q11: What actions can address wrong predictions?</a></li>
            <li><a href="#q12-what-is-the-concept-of-leave-one-out-influence">Q12: What is the concept of leave-one-out influence?</a></li>
            <li><a href="#q13-what-is-data-shapley">Q13: What is Data Shapley?</a></li>
            <li><a href="#q14-how-can-we-approximate-influence">Q14: How can we approximate influence?</a></li>
            <li><a href="#q15-why-review-influential-samples">Q15: Why review influential samples?</a></li>
            <li><a href="#references">References</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h2 id="data-centric-evaluation-of-ml-models">
  Data-Centric Evaluation of ML Models
  <a class="anchor" href="#data-centric-evaluation-of-ml-models">#</a>
</h2>
<hr>
<h3 id="q1-what-is-the-typical-ml-workflow-before-deployment">
  Q1: What is the typical ML workflow before deployment?
  <a class="anchor" href="#q1-what-is-the-typical-ml-workflow-before-deployment">#</a>
</h3>
<ul>
<li>Collect data and define the ML task.</li>
<li>Explore and preprocess the data.</li>
<li>Train a straightforward model.</li>
<li>Investigate shortcomings in the model and dataset.</li>
<li>Improve dataset and model iteratively.</li>
<li>Deploy the model and monitor for new issues.</li>
</ul>
<h3 id="q2-why-is-model-evaluation-critical">
  Q2: Why is model evaluation critical?
  <a class="anchor" href="#q2-why-is-model-evaluation-critical">#</a>
</h3>
<ul>
<li>Evaluation affects practical outcomes in real-world applications.</li>
<li>Poor evaluation choices can lead to misleading or harmful models.</li>
</ul>
<h3 id="q3-what-are-examples-of-evaluation-metrics-for-classification">
  Q3: What are examples of evaluation metrics for classification?
  <a class="anchor" href="#q3-what-are-examples-of-evaluation-metrics-for-classification">#</a>
</h3>
<ul>
<li>Accuracy, balanced accuracy, precision, recall, log loss, AUROC, calibration error.</li>
</ul>
<h3 id="q4-what-are-some-pitfalls-in-model-evaluation">
  Q4: What are some pitfalls in model evaluation?
  <a class="anchor" href="#q4-what-are-some-pitfalls-in-model-evaluation">#</a>
</h3>
<ul>
<li>Data leakage by using non-held-out data.</li>
<li>Misspecified metrics hiding failures in subpopulations.</li>
<li>Validation data not representing deployment settings.</li>
<li>Label errors.</li>
</ul>
<h3 id="q5-how-is-text-generation-model-evaluation-different">
  Q5: How is text generation model evaluation different?
  <a class="anchor" href="#q5-how-is-text-generation-model-evaluation-different">#</a>
</h3>
<ul>
<li>Human evaluations (👍👎 or Likert scales).</li>
<li>LLM evaluations with multiple criteria.</li>
<li>Automated metrics like ROUGE, BLEU, and Perplexity.</li>
</ul>
<h3 id="q6-what-is-a-data-slice">
  Q6: What is a data slice?
  <a class="anchor" href="#q6-what-is-a-data-slice">#</a>
</h3>
<ul>
<li>A subset of the dataset sharing a common characteristic, e.g., different sensor types, demographics.</li>
</ul>
<h3 id="q7-why-is-it-insufficient-to-delete-sensitive-features-to-address-slice-fairness">
  Q7: Why is it insufficient to delete sensitive features to address slice fairness?
  <a class="anchor" href="#q7-why-is-it-insufficient-to-delete-sensitive-features-to-address-slice-fairness">#</a>
</h3>
<ul>
<li>Slice membership information may be correlated with other features.</li>
</ul>
<h3 id="q8-how-can-we-improve-model-performance-for-underperforming-slices">
  Q8: How can we improve model performance for underperforming slices?
  <a class="anchor" href="#q8-how-can-we-improve-model-performance-for-underperforming-slices">#</a>
</h3>
<ul>
<li>Use a more flexible model.</li>
<li>Over-sample the minority subgroup.</li>
<li>Collect more data from the subgroup.</li>
<li>Engineer new features that better capture subgroup specifics.</li>
</ul>
<h3 id="q9-how-to-discover-underperforming-subpopulations">
  Q9: How to discover underperforming subpopulations?
  <a class="anchor" href="#q9-how-to-discover-underperforming-subpopulations">#</a>
</h3>
<ul>
<li>Sort validation examples by loss.</li>
<li>Cluster high-loss examples to find commonalities.</li>
</ul>
<h3 id="q10-what-are-typical-causes-of-wrong-predictions">
  Q10: What are typical causes of wrong predictions?
  <a class="anchor" href="#q10-what-are-typical-causes-of-wrong-predictions">#</a>
</h3>
<ul>
<li>Incorrect labels.</li>
<li>Examples that do not belong to any class.</li>
<li>Outlier examples.</li>
<li>Model type limitations.</li>
<li>Conflicting or noisy dataset labels.</li>
</ul>
<h3 id="q11-what-actions-can-address-wrong-predictions">
  Q11: What actions can address wrong predictions?
  <a class="anchor" href="#q11-what-actions-can-address-wrong-predictions">#</a>
</h3>
<ul>
<li>Correct labels.</li>
<li>Remove fundamentally unpredictable examples.</li>
<li>Augment or normalize outlier examples.</li>
<li>Fit better model architectures or do feature engineering.</li>
<li>Enrich the dataset to distinguish overlapping classes.</li>
</ul>
<h3 id="q12-what-is-the-concept-of-leave-one-out-influence">
  Q12: What is the concept of leave-one-out influence?
  <a class="anchor" href="#q12-what-is-the-concept-of-leave-one-out-influence">#</a>
</h3>
<ul>
<li>Measure the impact of omitting a datapoint on the model’s validation performance.</li>
</ul>
<h3 id="q13-what-is-data-shapley">
  Q13: What is Data Shapley?
  <a class="anchor" href="#q13-what-is-data-shapley">#</a>
</h3>
<ul>
<li>A method that averages the influence of a datapoint over all subsets containing it, providing a fairer measure of its importance.</li>
</ul>
<h3 id="q14-how-can-we-approximate-influence">
  Q14: How can we approximate influence?
  <a class="anchor" href="#q14-how-can-we-approximate-influence">#</a>
</h3>
<ul>
<li>Monte Carlo sampling methods.</li>
<li>Closed-form approximations for simple models like linear regression and k-NN.</li>
</ul>
<h3 id="q15-why-review-influential-samples">
  Q15: Why review influential samples?
  <a class="anchor" href="#q15-why-review-influential-samples">#</a>
</h3>
<ul>
<li>Correcting highly influential mislabeled examples can lead to significant accuracy improvements.</li>
</ul>
<hr>
<h3 id="references">
  References
  <a class="anchor" href="#references">#</a>
</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Cook%27s_distance">Cook’s Distance (Linear Regression Influence)</a></li>
<li><a href="https://arxiv.org/abs/1702.08734">Similarity Search Scaling for Big Data (Johnson et al., 2019)</a></li>
<li><a href="https://ojs.aaai.org/index.php/AAAI/article/view/20591">Trustworthy Data Influence Estimation</a></li>
<li><a href="https://github.com/cleanlab/cleanlab">Confident Learning and Cleanlab Project</a></li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#data-centric-evaluation-of-ml-models">Data-Centric Evaluation of ML Models</a>
          <ul>
            <li><a href="#q1-what-is-the-typical-ml-workflow-before-deployment">Q1: What is the typical ML workflow before deployment?</a></li>
            <li><a href="#q2-why-is-model-evaluation-critical">Q2: Why is model evaluation critical?</a></li>
            <li><a href="#q3-what-are-examples-of-evaluation-metrics-for-classification">Q3: What are examples of evaluation metrics for classification?</a></li>
            <li><a href="#q4-what-are-some-pitfalls-in-model-evaluation">Q4: What are some pitfalls in model evaluation?</a></li>
            <li><a href="#q5-how-is-text-generation-model-evaluation-different">Q5: How is text generation model evaluation different?</a></li>
            <li><a href="#q6-what-is-a-data-slice">Q6: What is a data slice?</a></li>
            <li><a href="#q7-why-is-it-insufficient-to-delete-sensitive-features-to-address-slice-fairness">Q7: Why is it insufficient to delete sensitive features to address slice fairness?</a></li>
            <li><a href="#q8-how-can-we-improve-model-performance-for-underperforming-slices">Q8: How can we improve model performance for underperforming slices?</a></li>
            <li><a href="#q9-how-to-discover-underperforming-subpopulations">Q9: How to discover underperforming subpopulations?</a></li>
            <li><a href="#q10-what-are-typical-causes-of-wrong-predictions">Q10: What are typical causes of wrong predictions?</a></li>
            <li><a href="#q11-what-actions-can-address-wrong-predictions">Q11: What actions can address wrong predictions?</a></li>
            <li><a href="#q12-what-is-the-concept-of-leave-one-out-influence">Q12: What is the concept of leave-one-out influence?</a></li>
            <li><a href="#q13-what-is-data-shapley">Q13: What is Data Shapley?</a></li>
            <li><a href="#q14-how-can-we-approximate-influence">Q14: How can we approximate influence?</a></li>
            <li><a href="#q15-why-review-influential-samples">Q15: Why review influential samples?</a></li>
            <li><a href="#references">References</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












