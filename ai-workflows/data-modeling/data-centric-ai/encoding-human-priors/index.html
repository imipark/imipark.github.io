<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="


Encoding Human Priors – Data Augmentation and Prompt Engineering 




  Q1: What is the main focus of this lecture?
  #


How to encode human priors into machine learning through:

Training data augmentation
Prompt engineering at test time (especially for LLMs).




  Q2: Why do ML models need human priors?
  #


ML models often fail in simple ways.
They lack common sense (e.g., failing to recognize a rotated dog image).
Human priors capture invariances and domain knowledge that models don&rsquo;t inherently learn.


  Q3: What is data augmentation and why is it important?
  #


Data augmentation creates new training examples by applying transformations (e.g., rotation, flipping).
Helps address:

Overfitting (memorization)
Underfitting (lack of data)
Class imbalance or biased datasets.


Saves time and cost, especially when labeled data is expensive (e.g., in healthcare).


  Q4: What are examples of data augmentation techniques?
  #


Simple methods: Rotation, flipping.
Advanced methods:

Mixup: Blending images and labels (e.g., 60% cat &#43; 40% dog).
Synthetic generation: Using DALL-E, Stable Diffusion to generate new data.
Simulation-to-real transfer: e.g., Google&rsquo;s RetinaGAN for robotics.


Text augmentation: Back-translation (English → French → English) to generate paraphrases.


  Q5: What is prompt engineering?
  #


Prompt engineering manipulates inputs to LLMs at test time.
Example: Instead of “Write a letter of recommendation,” prompt with “Write a letter for a student who got into MIT” to get higher-quality output.
Leverages the language interface humans naturally use.


  Q6: Why does prompt engineering work especially well for LLMs?
  #


LLMs are trained on massive language datasets.
Humans can easily adapt prompts to guide the model without retraining it.
Providing context and examples (&ldquo;few-shot prompting&rdquo;) improves results.


  Q7: How are GPT-3 and ChatGPT different in handling prompts?
  #


GPT-3: Predicts next token, assumes user might be creating forms/questions.
ChatGPT: Trained for dialogue and commands, better at instruction-following.


  Q8: What are best practices in prompt engineering?
  #


Add examples (&ldquo;few-shot&rdquo;) to define task behavior.
Build context templates for reusability.
Iteratively tweak prompts to observe effects on output.


  Q9: How does data augmentation vs. prompt engineering differ?
  #


  
      
          Aspect
          Data Augmentation
          Prompt Engineering
      
  
  
      
          When applied
          Before training
          At test time
      
      
          What is changed
          Training dataset
          Input prompt
      
      
          Goal
          Teach model invariances
          Guide model behavior dynamically
      
      
          Typical models
          Any ML models
          Mainly LLMs (e.g., GPT family)
      
  


  Q10: Final Takeaway
  #


Encoding human priors via data (training-time or test-time) dramatically improves model robustness.
Data is the bridge to insert human knowledge into ML systems effectively.



  References
  #


Lecture Slides PDF
Mixup Paper (Zhang et al., 2017)
Mobius Transformations (Zhou et al., 2020)
RetinaGAN (Ho et al., 2020)
GPT-3 Paper
DALL-E
Stable Diffusion
Lab assignment: Prompt Engineering
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://imipark.github.io/ai-workflows/data-modeling/data-centric-ai/encoding-human-priors/">
  <meta property="og:site_name" content="AI Reasoning">
  <meta property="og:title" content="Encoding Human Priors">
  <meta property="og:description" content="Encoding Human Priors – Data Augmentation and Prompt Engineering Q1: What is the main focus of this lecture? # How to encode human priors into machine learning through: Training data augmentation Prompt engineering at test time (especially for LLMs). Q2: Why do ML models need human priors? # ML models often fail in simple ways. They lack common sense (e.g., failing to recognize a rotated dog image). Human priors capture invariances and domain knowledge that models don’t inherently learn. Q3: What is data augmentation and why is it important? # Data augmentation creates new training examples by applying transformations (e.g., rotation, flipping). Helps address: Overfitting (memorization) Underfitting (lack of data) Class imbalance or biased datasets. Saves time and cost, especially when labeled data is expensive (e.g., in healthcare). Q4: What are examples of data augmentation techniques? # Simple methods: Rotation, flipping. Advanced methods: Mixup: Blending images and labels (e.g., 60% cat &#43; 40% dog). Synthetic generation: Using DALL-E, Stable Diffusion to generate new data. Simulation-to-real transfer: e.g., Google’s RetinaGAN for robotics. Text augmentation: Back-translation (English → French → English) to generate paraphrases. Q5: What is prompt engineering? # Prompt engineering manipulates inputs to LLMs at test time. Example: Instead of “Write a letter of recommendation,” prompt with “Write a letter for a student who got into MIT” to get higher-quality output. Leverages the language interface humans naturally use. Q6: Why does prompt engineering work especially well for LLMs? # LLMs are trained on massive language datasets. Humans can easily adapt prompts to guide the model without retraining it. Providing context and examples (“few-shot prompting”) improves results. Q7: How are GPT-3 and ChatGPT different in handling prompts? # GPT-3: Predicts next token, assumes user might be creating forms/questions. ChatGPT: Trained for dialogue and commands, better at instruction-following. Q8: What are best practices in prompt engineering? # Add examples (“few-shot”) to define task behavior. Build context templates for reusability. Iteratively tweak prompts to observe effects on output. Q9: How does data augmentation vs. prompt engineering differ? # Aspect Data Augmentation Prompt Engineering When applied Before training At test time What is changed Training dataset Input prompt Goal Teach model invariances Guide model behavior dynamically Typical models Any ML models Mainly LLMs (e.g., GPT family) Q10: Final Takeaway # Encoding human priors via data (training-time or test-time) dramatically improves model robustness. Data is the bridge to insert human knowledge into ML systems effectively. References # Lecture Slides PDF Mixup Paper (Zhang et al., 2017) Mobius Transformations (Zhou et al., 2020) RetinaGAN (Ho et al., 2020) GPT-3 Paper DALL-E Stable Diffusion Lab assignment: Prompt Engineering">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="ai-workflows">
<title>Encoding Human Priors | AI Reasoning</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="https://imipark.github.io/ai-workflows/data-modeling/data-centric-ai/encoding-human-priors/">
<link rel="stylesheet" href="/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.4014c58b4ff93b711a1e1d78f5ec4df7c78de5b479f64af51be6af1f4dace7eb.js" integrity="sha256-QBTFi0/5O3EaHh149exN98eN5bR59kr1G&#43;avH02s5&#43;s=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>AI Reasoning</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>













  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ai-workflows/" class="">AI Reasoning Stack</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-f8e502c34e18a04e1c3aecf192b0355a" class="toggle" checked />
    <label for="section-f8e502c34e18a04e1c3aecf192b0355a" class="flex justify-between">
      <a href="/ai-workflows/data-modeling/" class="">Data Modeling</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-906a2243f4790a09188fae70fbc32dbd" class="toggle" checked />
    <label for="section-906a2243f4790a09188fae70fbc32dbd" class="flex justify-between">
      <a href="/ai-workflows/data-modeling/data-centric-ai/" class="">Data-Centric AI (DCAI)</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-5bf1c216f4b747bd7c2f992550ff09a1" class="toggle"  />
    <label for="section-5bf1c216f4b747bd7c2f992550ff09a1" class="flex justify-between">
      <a href="/ai-workflows/genai-systems/" class="">GenAI Systems</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8cbfd420d91de13f61964bf971127312" class="toggle"  />
    <label for="section-8cbfd420d91de13f61964bf971127312" class="flex justify-between">
      <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/" class="">5-Day GenAI with Google 2005</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day1_foundational_llm_text_generation/" class="">Day 1 - Foundational LLMs &amp; Text Generation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day1_prompt_engineering/" class="">Day 1 – Prompt Engineering</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day2_embeddings_vectordb/" class="">Day 2 – Embeddings &amp; Vector Databases</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day3_generative_agents/" class="">Day 3 – Generative Agents</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day4_domainspecific_llms/" class="">Day 4 – Domain-Specific LLMs</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/5-day-genai-google-2025/day5_mlops/" class="">Day 5 – MLOps for Generative AI</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai-systems/multimodel_llms/" class="">Multimodal LLMs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-17ba62e37c896ad50105fedeb71549dd" class="toggle"  />
    <label for="section-17ba62e37c896ad50105fedeb71549dd" class="flex justify-between">
      <a href="/ai-workflows/reasoning/" class="">Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cd94e161670d28ecff992edf840d76e8" class="toggle"  />
    <label for="section-cd94e161670d28ecff992edf840d76e8" class="flex justify-between">
      <a href="/ai-workflows/reasoning/causality/" class="">Causality</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-ai/" class="">Causal AI</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-inference/" class="">Causal Inference</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7e468aa05ceb7c844f07a2e754606b76" class="toggle"  />
    <label for="section-7e468aa05ceb7c844f07a2e754606b76" class="flex justify-between">
      <a href="/ai-workflows/reasoning/graph-reasoning/" class="">Graph Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/graphrag/" class="">GraphRAG</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/knowledge-graphs/" class="">Knowledge Graphs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="toggle"  />
    <label for="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="flex justify-between">
      <a href="/ai-workflows/rlhf/" class="">RLHF</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b1afcafdefac57f3420f64e23d73f05d" class="toggle"  />
    <label for="section-b1afcafdefac57f3420f64e23d73f05d" class="flex justify-between">
      <a href="/ai-workflows/rlhf/rlhf2006/" class="">RLHF 2006</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/rlhf/rlhf2006/instruct_gpt_codes_params/" class="">Instruct Gpt Codes Params</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ca53d32fab0e1a54fdf5627349d86bfc" class="toggle"  />
    <label for="section-ca53d32fab0e1a54fdf5627349d86bfc" class="flex justify-between">
      <a href="/ai-workflows/eval/" class="">AI Evaluation</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/healthcare/" class="">Healthcare</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="toggle"  />
    <label for="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/" class="">Domain</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-45ba5974905f86df95925365835eadbb" class="toggle"  />
    <label for="section-45ba5974905f86df95925365835eadbb" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/ai-in-healthcare/" class="">AI in Healthcare</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/" class="">C2 Clinical Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/" class="">C3 ML Healthcare</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/" class="">C4 AI Evaluations</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c5_capstone/" class="">C5 Capstone Projects</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9722ba71bf098ab02c3220d6e8d9056f" class="toggle"  />
    <label for="section-9722ba71bf098ab02c3220d6e8d9056f" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/hands-on-healthcare-data/" class="">Hands-On Healthcare Data</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/data/" class="">Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/clinical_ai/" class="">AI Applications</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ipark/" class="">Inhee Park, PhD - Resume</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>










  
<ul>
  
  <li>
    <a href="https://www.linkedin.com/in/inheepark/"  target="_blank" rel="noopener">
        ╰──LinkedIn
      </a>
  </li>
  
  <li>
    <a href="https://github.com/imipark/"  target="_blank" rel="noopener">
        ╰──GitHub
      </a>
  </li>
  
  <li>
    <a href="/posts/"  target="_blank" rel="noopener">
        ╰──Blog
      </a>
  </li>
  
  <li>
    <a href="https://iparkirk.github.io"  target="_blank" rel="noopener">
        ╰──Old Web
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Encoding Human Priors</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#q1-what-is-the-main-focus-of-this-lecture">Q1: What is the main focus of this lecture?</a></li>
            <li><a href="#q2-why-do-ml-models-need-human-priors">Q2: Why do ML models need human priors?</a></li>
            <li><a href="#q3-what-is-data-augmentation-and-why-is-it-important">Q3: What is data augmentation and why is it important?</a></li>
            <li><a href="#q4-what-are-examples-of-data-augmentation-techniques">Q4: What are examples of data augmentation techniques?</a></li>
            <li><a href="#q5-what-is-prompt-engineering">Q5: What is prompt engineering?</a></li>
            <li><a href="#q6-why-does-prompt-engineering-work-especially-well-for-llms">Q6: Why does prompt engineering work especially well for LLMs?</a></li>
            <li><a href="#q7-how-are-gpt-3-and-chatgpt-different-in-handling-prompts">Q7: How are GPT-3 and ChatGPT different in handling prompts?</a></li>
            <li><a href="#q8-what-are-best-practices-in-prompt-engineering">Q8: What are best practices in prompt engineering?</a></li>
            <li><a href="#q9-how-does-data-augmentation-vs-prompt-engineering-differ">Q9: How does data augmentation vs. prompt engineering differ?</a></li>
            <li><a href="#q10-final-takeaway">Q10: Final Takeaway</a></li>
            <li><a href="#references">References</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><p align="center">
<img src="/images/AIR_logo.png" alt="AI Reasoning Logo" width="200"/>
<strong style="font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;">
Encoding Human Priors – Data Augmentation and Prompt Engineering 
</strong>
</p>
<hr>
<h3 id="q1-what-is-the-main-focus-of-this-lecture">
  Q1: What is the main focus of this lecture?
  <a class="anchor" href="#q1-what-is-the-main-focus-of-this-lecture">#</a>
</h3>
<ul>
<li>How to <strong>encode human priors</strong> into machine learning through:
<ul>
<li><strong>Training data augmentation</strong></li>
<li><strong>Prompt engineering at test time</strong> (especially for LLMs).</li>
</ul>
</li>
</ul>
<h3 id="q2-why-do-ml-models-need-human-priors">
  Q2: Why do ML models need human priors?
  <a class="anchor" href="#q2-why-do-ml-models-need-human-priors">#</a>
</h3>
<ul>
<li>ML models often <strong>fail in simple ways</strong>.</li>
<li>They lack <strong>common sense</strong> (e.g., failing to recognize a rotated dog image).</li>
<li>Human priors <strong>capture invariances</strong> and domain knowledge that models don&rsquo;t inherently learn.</li>
</ul>
<h3 id="q3-what-is-data-augmentation-and-why-is-it-important">
  Q3: What is data augmentation and why is it important?
  <a class="anchor" href="#q3-what-is-data-augmentation-and-why-is-it-important">#</a>
</h3>
<ul>
<li><strong>Data augmentation</strong> creates new training examples by applying transformations (e.g., rotation, flipping).</li>
<li>Helps address:
<ul>
<li><strong>Overfitting</strong> (memorization)</li>
<li><strong>Underfitting</strong> (lack of data)</li>
<li><strong>Class imbalance</strong> or <strong>biased datasets</strong>.</li>
</ul>
</li>
<li>Saves time and cost, especially when labeled data is expensive (e.g., in healthcare).</li>
</ul>
<h3 id="q4-what-are-examples-of-data-augmentation-techniques">
  Q4: What are examples of data augmentation techniques?
  <a class="anchor" href="#q4-what-are-examples-of-data-augmentation-techniques">#</a>
</h3>
<ul>
<li><strong>Simple methods</strong>: Rotation, flipping.</li>
<li><strong>Advanced methods</strong>:
<ul>
<li><strong>Mixup</strong>: Blending images and labels (e.g., 60% cat + 40% dog).</li>
<li><strong>Synthetic generation</strong>: Using DALL-E, Stable Diffusion to generate new data.</li>
<li><strong>Simulation-to-real transfer</strong>: e.g., Google&rsquo;s RetinaGAN for robotics.</li>
</ul>
</li>
<li><strong>Text augmentation</strong>: <strong>Back-translation</strong> (English → French → English) to generate paraphrases.</li>
</ul>
<h3 id="q5-what-is-prompt-engineering">
  Q5: What is prompt engineering?
  <a class="anchor" href="#q5-what-is-prompt-engineering">#</a>
</h3>
<ul>
<li><strong>Prompt engineering</strong> manipulates inputs to LLMs <strong>at test time</strong>.</li>
<li>Example: Instead of “Write a letter of recommendation,” prompt with “Write a letter for a student who got into MIT” to get higher-quality output.</li>
<li>Leverages the <strong>language interface</strong> humans naturally use.</li>
</ul>
<h3 id="q6-why-does-prompt-engineering-work-especially-well-for-llms">
  Q6: Why does prompt engineering work especially well for LLMs?
  <a class="anchor" href="#q6-why-does-prompt-engineering-work-especially-well-for-llms">#</a>
</h3>
<ul>
<li>LLMs are trained on massive <strong>language datasets</strong>.</li>
<li>Humans can easily <strong>adapt prompts</strong> to guide the model without retraining it.</li>
<li>Providing <strong>context and examples</strong> (&ldquo;few-shot prompting&rdquo;) improves results.</li>
</ul>
<h3 id="q7-how-are-gpt-3-and-chatgpt-different-in-handling-prompts">
  Q7: How are GPT-3 and ChatGPT different in handling prompts?
  <a class="anchor" href="#q7-how-are-gpt-3-and-chatgpt-different-in-handling-prompts">#</a>
</h3>
<ul>
<li><strong>GPT-3</strong>: Predicts next token, assumes user might be creating forms/questions.</li>
<li><strong>ChatGPT</strong>: Trained for <strong>dialogue and commands</strong>, better at <strong>instruction-following</strong>.</li>
</ul>
<h3 id="q8-what-are-best-practices-in-prompt-engineering">
  Q8: What are best practices in prompt engineering?
  <a class="anchor" href="#q8-what-are-best-practices-in-prompt-engineering">#</a>
</h3>
<ul>
<li>Add <strong>examples</strong> (&ldquo;few-shot&rdquo;) to define task behavior.</li>
<li>Build <strong>context templates</strong> for reusability.</li>
<li>Iteratively <strong>tweak prompts</strong> to observe effects on output.</li>
</ul>
<h3 id="q9-how-does-data-augmentation-vs-prompt-engineering-differ">
  Q9: How does data augmentation vs. prompt engineering differ?
  <a class="anchor" href="#q9-how-does-data-augmentation-vs-prompt-engineering-differ">#</a>
</h3>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Aspect</th>
          <th style="text-align: left">Data Augmentation</th>
          <th style="text-align: left">Prompt Engineering</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">When applied</td>
          <td style="text-align: left">Before training</td>
          <td style="text-align: left">At test time</td>
      </tr>
      <tr>
          <td style="text-align: left">What is changed</td>
          <td style="text-align: left">Training dataset</td>
          <td style="text-align: left">Input prompt</td>
      </tr>
      <tr>
          <td style="text-align: left">Goal</td>
          <td style="text-align: left">Teach model invariances</td>
          <td style="text-align: left">Guide model behavior dynamically</td>
      </tr>
      <tr>
          <td style="text-align: left">Typical models</td>
          <td style="text-align: left">Any ML models</td>
          <td style="text-align: left">Mainly LLMs (e.g., GPT family)</td>
      </tr>
  </tbody>
</table>
<h3 id="q10-final-takeaway">
  Q10: Final Takeaway
  <a class="anchor" href="#q10-final-takeaway">#</a>
</h3>
<ul>
<li><strong>Encoding human priors via data</strong> (training-time or test-time) dramatically improves model robustness.</li>
<li><strong>Data is the bridge</strong> to insert human knowledge into ML systems effectively.</li>
</ul>
<hr>
<h3 id="references">
  References
  <a class="anchor" href="#references">#</a>
</h3>
<ul>
<li><a href="https://dcai.csail.mit.edu/2023/human-priors/human-priors.pdf">Lecture Slides PDF</a></li>
<li><a href="https://arxiv.org/abs/1710.09412">Mixup Paper (Zhang et al., 2017)</a></li>
<li><a href="https://arxiv.org/abs/2002.02917">Mobius Transformations (Zhou et al., 2020)</a></li>
<li><a href="https://arxiv.org/abs/2011.03148">RetinaGAN (Ho et al., 2020)</a></li>
<li><a href="https://arxiv.org/abs/2005.14165">GPT-3 Paper</a></li>
<li><a href="https://openai.com/index/dall-e-2/">DALL-E</a></li>
<li><a href="https://stability.ai/blog/stable-diffusion-public-release">Stable Diffusion</a></li>
<li><a href="https://github.com/dcai-course/dcai-lab/blob/master/prompt_engineering/Lab_Prompt_Engineering.ipynb">Lab assignment: Prompt Engineering</a></li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#q1-what-is-the-main-focus-of-this-lecture">Q1: What is the main focus of this lecture?</a></li>
            <li><a href="#q2-why-do-ml-models-need-human-priors">Q2: Why do ML models need human priors?</a></li>
            <li><a href="#q3-what-is-data-augmentation-and-why-is-it-important">Q3: What is data augmentation and why is it important?</a></li>
            <li><a href="#q4-what-are-examples-of-data-augmentation-techniques">Q4: What are examples of data augmentation techniques?</a></li>
            <li><a href="#q5-what-is-prompt-engineering">Q5: What is prompt engineering?</a></li>
            <li><a href="#q6-why-does-prompt-engineering-work-especially-well-for-llms">Q6: Why does prompt engineering work especially well for LLMs?</a></li>
            <li><a href="#q7-how-are-gpt-3-and-chatgpt-different-in-handling-prompts">Q7: How are GPT-3 and ChatGPT different in handling prompts?</a></li>
            <li><a href="#q8-what-are-best-practices-in-prompt-engineering">Q8: What are best practices in prompt engineering?</a></li>
            <li><a href="#q9-how-does-data-augmentation-vs-prompt-engineering-differ">Q9: How does data augmentation vs. prompt engineering differ?</a></li>
            <li><a href="#q10-final-takeaway">Q10: Final Takeaway</a></li>
            <li><a href="#references">References</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












