<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="


Core Components of a Multimodal LLM





Visual Encoder
Converts input images into feature embeddings. Common choices include CLIP, ViT, and EVA.


Modality Adapter (Aligner)
Projects or transforms visual features to be compatible with the language model’s embedding space (e.g., via MLP or cross-attention).


Language Model (LLM)
A large pretrained language model (e.g., LLaMA, GPT) that consumes both text and aligned visual inputs to generate or classify responses.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://imipark.github.io/ai-workflows/genai/multimodel_llms/components_fusions/">
  <meta property="og:site_name" content="AI Reasoning">
  <meta property="og:title" content="Core Components and Fusion Strategies in Multimodal LLMs">
  <meta property="og:description" content="Core Components of a Multimodal LLM Visual Encoder
Converts input images into feature embeddings. Common choices include CLIP, ViT, and EVA.
Modality Adapter (Aligner)
Projects or transforms visual features to be compatible with the language model’s embedding space (e.g., via MLP or cross-attention).
Language Model (LLM)
A large pretrained language model (e.g., LLaMA, GPT) that consumes both text and aligned visual inputs to generate or classify responses.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="ai-workflows">
<title>Core Components and Fusion Strategies in Multimodal LLMs | AI Reasoning</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="https://imipark.github.io/ai-workflows/genai/multimodel_llms/components_fusions/">
<link rel="stylesheet" href="/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.0173bbefee938ca18415a40e44b93e080353b5ef582efcbf2ea5007cdddc86e0.js" integrity="sha256-AXO77&#43;6TjKGEFaQORLk&#43;CANTte9YLvy/LqUAfN3chuA=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>AI Reasoning</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>













  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ai-workflows/" class="">AI Reasoning Stack</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7f3f4cf59430750c2ad109248c8c879b" class="toggle"  />
    <label for="section-7f3f4cf59430750c2ad109248c8c879b" class="flex justify-between">
      <a href="/ai-workflows/data/" class="">Data</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fc566bddf8394fb4d0c5cff688d2febc" class="toggle"  />
    <label for="section-fc566bddf8394fb4d0c5cff688d2febc" class="flex justify-between">
      <a href="/ai-workflows/data/data-centric-ai/" class="">Data-Centric AI (DCAI)</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cff08f084db31c8732ef81d1fe1c4130" class="toggle" checked />
    <label for="section-cff08f084db31c8732ef81d1fe1c4130" class="flex justify-between">
      <a href="/ai-workflows/genai/" class="">GenAI</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-63b806a012c3062adb6281022ca8468f" class="toggle"  />
    <label for="section-63b806a012c3062adb6281022ca8468f" class="flex justify-between">
      <a href="/ai-workflows/genai/5-day-genai-google-2025/" class="">5-Day GenAI with Google 2005</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day1_foundational_llm_text_generation/" class="">Day 1 - Foundational LLMs &amp; Text Generation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day1_prompt_engineering/" class="">Day 1 – Prompt Engineering</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day2_embeddings_vectordb/" class="">Day 2 – Embeddings &amp; Vector Databases</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day3_generative_agents/" class="">Day 3 – Generative Agents</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day4_domainspecific_llms/" class="">Day 4 – Domain-Specific LLMs</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/5-day-genai-google-2025/day5_mlops/" class="">Day 5 – MLOps for Generative AI</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/genai/multimodel_llms/" class="">Multimodal LLMs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-17ba62e37c896ad50105fedeb71549dd" class="toggle"  />
    <label for="section-17ba62e37c896ad50105fedeb71549dd" class="flex justify-between">
      <a href="/ai-workflows/reasoning/" class="">Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cd94e161670d28ecff992edf840d76e8" class="toggle"  />
    <label for="section-cd94e161670d28ecff992edf840d76e8" class="flex justify-between">
      <a href="/ai-workflows/reasoning/causality/" class="">Causality</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-ai/" class="">Causal AI</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/causality/causal-inference/" class="">Causal Inference</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7e468aa05ceb7c844f07a2e754606b76" class="toggle"  />
    <label for="section-7e468aa05ceb7c844f07a2e754606b76" class="flex justify-between">
      <a href="/ai-workflows/reasoning/graph-reasoning/" class="">Graph Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/graphrag/" class="">GraphRAG</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/reasoning/graph-reasoning/knowledge-graphs/" class="">Knowledge Graphs</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="toggle"  />
    <label for="section-1b0623a0f68c821d1e7c5de8bd43d2fb" class="flex justify-between">
      <a href="/ai-workflows/rlhf/" class="">RLHF</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b1afcafdefac57f3420f64e23d73f05d" class="toggle"  />
    <label for="section-b1afcafdefac57f3420f64e23d73f05d" class="flex justify-between">
      <a href="/ai-workflows/rlhf/rlhf2006/" class="">RLHF 2006</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ai-workflows/rlhf/rlhf2006/instruct_gpt_codes_params/" class="">Instruct Gpt Codes Params</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ca53d32fab0e1a54fdf5627349d86bfc" class="toggle"  />
    <label for="section-ca53d32fab0e1a54fdf5627349d86bfc" class="flex justify-between">
      <a href="/ai-workflows/eval/" class="">Eval</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/healthcare/" class="">Healthcare</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="toggle"  />
    <label for="section-fd1d2eede2c2d7e81bbbc100c0b57829" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/" class="">Domain</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-45ba5974905f86df95925365835eadbb" class="toggle"  />
    <label for="section-45ba5974905f86df95925365835eadbb" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/ai-in-healthcare/" class="">AI in Healthcare</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/" class="">C2 Clinical Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/" class="">C3 ML Healthcare</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/" class="">C4 AI Evaluations</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/domain_knowledge/ai-in-healthcare/c5_capstone/" class="">C5 Capstone Projects</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9722ba71bf098ab02c3220d6e8d9056f" class="toggle"  />
    <label for="section-9722ba71bf098ab02c3220d6e8d9056f" class="flex justify-between">
      <a href="/healthcare/domain_knowledge/hands-on-healthcare-data/" class="">Hands-On Healthcare Data</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/data/" class="">Data</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/healthcare/clinical_ai/" class="">AI Applications</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/ipark/" class="">Inhee Park, PhD - Resume</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>










  
<ul>
  
  <li>
    <a href="https://www.linkedin.com/in/inheepark/"  target="_blank" rel="noopener">
        ╰──LinkedIn
      </a>
  </li>
  
  <li>
    <a href="https://github.com/imipark/"  target="_blank" rel="noopener">
        ╰──GitHub
      </a>
  </li>
  
  <li>
    <a href="/posts/"  target="_blank" rel="noopener">
        ╰──Blog
      </a>
  </li>
  
  <li>
    <a href="https://iparkirk.github.io"  target="_blank" rel="noopener">
        ╰──Old Web
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Core Components and Fusion Strategies in Multimodal LLMs</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#fusion-strategies-in-multimodal-llms">Fusion Strategies in Multimodal LLMs</a>
          <ul>
            <li><a href="#1-projection--token-injection">1. Projection + Token Injection</a></li>
            <li><a href="#2-cross-attention-adapters">2. Cross-Attention Adapters</a></li>
            <li><a href="#3-joint-pretraining-early-fusion">3. Joint Pretraining (Early Fusion)</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><p align="center">
<img src="/images/AIR_logo.png" alt="AI Reasoning Logo" width="200"/>
<strong style="font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;">
Core Components of a Multimodal LLM
</strong>
</p>
<hr>
<ol>
<li>
<p><strong>Visual Encoder</strong><br>
Converts input images into feature embeddings. Common choices include CLIP, ViT, and EVA.</p>
</li>
<li>
<p><strong>Modality Adapter (Aligner)</strong><br>
Projects or transforms visual features to be compatible with the language model’s embedding space (e.g., via MLP or cross-attention).</p>
</li>
<li>
<p><strong>Language Model (LLM)</strong><br>
A large pretrained language model (e.g., LLaMA, GPT) that consumes both text and aligned visual inputs to generate or classify responses.</p>
</li>
</ol>
<hr>
<h2 id="fusion-strategies-in-multimodal-llms">
  Fusion Strategies in Multimodal LLMs
  <a class="anchor" href="#fusion-strategies-in-multimodal-llms">#</a>
</h2>
<h3 id="1-projection--token-injection">
  1. Projection + Token Injection
  <a class="anchor" href="#1-projection--token-injection">#</a>
</h3>
<p><strong>Models</strong>: BLIP-2, LLaVA<br>
<strong>How it works</strong>:</p>
<ul>
<li>Visual features are extracted using a frozen image encoder (e.g., ViT or CLIP).</li>
<li>These features are projected via an MLP to match the LLM&rsquo;s token embedding size.</li>
<li>The projected visual tokens are <strong>prepended or interleaved</strong> with text tokens.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#9ca0b0;font-style:italic"># Hugging Face-style pseudocode</span>
</span></span><span style="display:flex;"><span>image_embeds <span style="color:#04a5e5;font-weight:bold">=</span> vision_encoder(image)         <span style="color:#9ca0b0;font-style:italic"># Shape: (batch, num_patches, hidden_dim)</span>
</span></span><span style="display:flex;"><span>projected_embeds <span style="color:#04a5e5;font-weight:bold">=</span> visual_proj(image_embeds) <span style="color:#9ca0b0;font-style:italic"># Match LLM hidden size</span>
</span></span><span style="display:flex;"><span>input_embeds <span style="color:#04a5e5;font-weight:bold">=</span> torch<span style="color:#04a5e5;font-weight:bold">.</span>cat([projected_embeds, text_token_embeds], dim<span style="color:#04a5e5;font-weight:bold">=</span><span style="color:#fe640b">1</span>)
</span></span><span style="display:flex;"><span>output <span style="color:#04a5e5;font-weight:bold">=</span> llm(inputs_embeds<span style="color:#04a5e5;font-weight:bold">=</span>input_embeds)
</span></span></code></pre></div><hr>
<h3 id="2-cross-attention-adapters">
  2. Cross-Attention Adapters
  <a class="anchor" href="#2-cross-attention-adapters">#</a>
</h3>
<p><strong>Models</strong>: Flamingo, MiniGPT-4<br>
<strong>How it works</strong>:</p>
<ul>
<li>Visual tokens are kept separate from text tokens.</li>
<li>The LLM has <strong>cross-attention layers</strong> where text tokens attend to visual context.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#9ca0b0;font-style:italic"># Pseudocode with cross-attn</span>
</span></span><span style="display:flex;"><span>text_embeds <span style="color:#04a5e5;font-weight:bold">=</span> llm<span style="color:#04a5e5;font-weight:bold">.</span>text_embeddings(text_input)
</span></span><span style="display:flex;"><span>visual_context <span style="color:#04a5e5;font-weight:bold">=</span> vision_encoder(image)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8839ef">for</span> block <span style="color:#04a5e5;font-weight:bold">in</span> llm<span style="color:#04a5e5;font-weight:bold">.</span>transformer_blocks:
</span></span><span style="display:flex;"><span>    text_embeds <span style="color:#04a5e5;font-weight:bold">=</span> block<span style="color:#04a5e5;font-weight:bold">.</span>self_attn(text_embeds)
</span></span><span style="display:flex;"><span>    text_embeds <span style="color:#04a5e5;font-weight:bold">=</span> block<span style="color:#04a5e5;font-weight:bold">.</span>cross_attn(text_embeds, context<span style="color:#04a5e5;font-weight:bold">=</span>visual_context)
</span></span></code></pre></div><hr>
<h3 id="3-joint-pretraining-early-fusion">
  3. Joint Pretraining (Early Fusion)
  <a class="anchor" href="#3-joint-pretraining-early-fusion">#</a>
</h3>
<p><strong>Models</strong>: Unified-IO, GIT, PaLI<br>
<strong>How it works</strong>:</p>
<ul>
<li>Images are tokenized (as patches or regions).</li>
<li>Both image and text tokens are passed together into a unified transformer.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#9ca0b0;font-style:italic"># Pseudocode for joint vision-text transformer</span>
</span></span><span style="display:flex;"><span>image_tokens <span style="color:#04a5e5;font-weight:bold">=</span> patch_embed(image)            <span style="color:#9ca0b0;font-style:italic"># ViT-style patch tokens</span>
</span></span><span style="display:flex;"><span>text_tokens <span style="color:#04a5e5;font-weight:bold">=</span> tokenizer(text)
</span></span><span style="display:flex;"><span>all_tokens <span style="color:#04a5e5;font-weight:bold">=</span> torch<span style="color:#04a5e5;font-weight:bold">.</span>cat([image_tokens, text_tokens], dim<span style="color:#04a5e5;font-weight:bold">=</span><span style="color:#fe640b">1</span>)
</span></span><span style="display:flex;"><span>output <span style="color:#04a5e5;font-weight:bold">=</span> joint_transformer(all_tokens)
</span></span></code></pre></div></article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#fusion-strategies-in-multimodal-llms">Fusion Strategies in Multimodal LLMs</a>
          <ul>
            <li><a href="#1-projection--token-injection">1. Projection + Token Injection</a></li>
            <li><a href="#2-cross-attention-adapters">2. Cross-Attention Adapters</a></li>
            <li><a href="#3-joint-pretraining-early-fusion">3. Joint Pretraining (Early Fusion)</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












