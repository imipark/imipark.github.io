<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI Reasoning</title>
    <link>https://imipark.github.io/</link>
    <description>Recent content on AI Reasoning</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Jan 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://imipark.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[ToC] Course 2</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/toc_course2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/toc_course2/</guid>
      <description>&lt;h2 id=&#34;toc-of-course-25-introduction-to-clinical-data&#34;&gt;&#xA;  ToC of Course 2/5: Introduction to Clinical Data&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#toc-of-course-25-introduction-to-clinical-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-1-asking-and-answering-questions-via-clinical-data-mining&#34;&gt;&#xA;  Module 1: Asking and Answering Questions via Clinical Data Mining&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-1-asking-and-answering-questions-via-clinical-data-mining&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to the data mining workflow&lt;/li&gt;&#xA;&lt;li&gt;Real Life Example&lt;/li&gt;&#xA;&lt;li&gt;Example: Finding similar patients&lt;/li&gt;&#xA;&lt;li&gt;Example: Estimating risk&lt;/li&gt;&#xA;&lt;li&gt;Putting patient data on timeline&lt;/li&gt;&#xA;&lt;li&gt;Revisit the data mining workflow steps&lt;/li&gt;&#xA;&lt;li&gt;Types of research questions&lt;/li&gt;&#xA;&lt;li&gt;Research questions suited for clinical data&lt;/li&gt;&#xA;&lt;li&gt;Example: making decision to treat&lt;/li&gt;&#xA;&lt;li&gt;Properties that make answering a research question useful&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-2-data-available-from-healthcare-systems&#34;&gt;&#xA;  Module 2: Data Available from Healthcare Systems&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-2-data-available-from-healthcare-systems&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Review of the healthcare system&lt;/li&gt;&#xA;&lt;li&gt;Review of key entities and the data they collect&lt;/li&gt;&#xA;&lt;li&gt;Actors with different interests&lt;/li&gt;&#xA;&lt;li&gt;Common data types in Healthcare&lt;/li&gt;&#xA;&lt;li&gt;Strengths and weaknesses of observational data&lt;/li&gt;&#xA;&lt;li&gt;Bias and error from the healthcare system perspective&lt;/li&gt;&#xA;&lt;li&gt;Bias and error of exposures and outcomes&lt;/li&gt;&#xA;&lt;li&gt;How a patient&amp;rsquo;s exposure might be misclassified&lt;/li&gt;&#xA;&lt;li&gt;How a patient&amp;rsquo;s outcome could be misclassified&lt;/li&gt;&#xA;&lt;li&gt;Electronic medical record data&lt;/li&gt;&#xA;&lt;li&gt;Claims data&lt;/li&gt;&#xA;&lt;li&gt;Pharmacy&lt;/li&gt;&#xA;&lt;li&gt;Surveillance datasets and Registries&lt;/li&gt;&#xA;&lt;li&gt;Population health data sets&lt;/li&gt;&#xA;&lt;li&gt;A framework to assess if a data source is useful&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-3-representing-time-and-timing-of-events-for-clinical-data-mining&#34;&gt;&#xA;  Module 3: Representing Time, and Timing of Events, for Clinical Data Mining&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-3-representing-time-and-timing-of-events-for-clinical-data-mining&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction&lt;/li&gt;&#xA;&lt;li&gt;Time, timelines, timescales and representations of time&lt;/li&gt;&#xA;&lt;li&gt;Timescale: Choosing the relevant units of time&lt;/li&gt;&#xA;&lt;li&gt;What affects the timescale&lt;/li&gt;&#xA;&lt;li&gt;Representation of time&lt;/li&gt;&#xA;&lt;li&gt;Time series and non-time series data&lt;/li&gt;&#xA;&lt;li&gt;Order of events&lt;/li&gt;&#xA;&lt;li&gt;Implicit representations of time&lt;/li&gt;&#xA;&lt;li&gt;Different ways to put data in bins&lt;/li&gt;&#xA;&lt;li&gt;Timing of exposures and outcomes&lt;/li&gt;&#xA;&lt;li&gt;Clinical processes are non-stationary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-4-creating-analysis-ready-datasets-from-patient-timelines&#34;&gt;&#xA;  Module 4: Creating Analysis Ready Datasets from Patient Timelines&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-4-creating-analysis-ready-datasets-from-patient-timelines&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Turning clinical data into something you can analyze&lt;/li&gt;&#xA;&lt;li&gt;Defining the unit of analysis&lt;/li&gt;&#xA;&lt;li&gt;Using features and the presence of features&lt;/li&gt;&#xA;&lt;li&gt;How to create features from structured sources&lt;/li&gt;&#xA;&lt;li&gt;Standardizing features&lt;/li&gt;&#xA;&lt;li&gt;Dealing with too many features&lt;/li&gt;&#xA;&lt;li&gt;The origins of missing values&lt;/li&gt;&#xA;&lt;li&gt;Dealing with missing values&lt;/li&gt;&#xA;&lt;li&gt;Summary recommendations for missing values&lt;/li&gt;&#xA;&lt;li&gt;Constructing new features&lt;/li&gt;&#xA;&lt;li&gt;Examples of engineered features&lt;/li&gt;&#xA;&lt;li&gt;When to consider engineered features&lt;/li&gt;&#xA;&lt;li&gt;Main points about creating analysis ready datasets&lt;/li&gt;&#xA;&lt;li&gt;Structured knowledge graphs&lt;/li&gt;&#xA;&lt;li&gt;So what exactly is in a knowledge graph&lt;/li&gt;&#xA;&lt;li&gt;What are important knowledge graphs&lt;/li&gt;&#xA;&lt;li&gt;How to choose which knowledge graph to use&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-5-handling-unstructured-healthcare-data-text-images-signals&#34;&gt;&#xA;  Module 5: Handling Unstructured Healthcare Data: Text, Images, Signals&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-5-handling-unstructured-healthcare-data-text-images-signals&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to unstructured data&lt;/li&gt;&#xA;&lt;li&gt;What is clinical text&lt;/li&gt;&#xA;&lt;li&gt;The value of clinical text&lt;/li&gt;&#xA;&lt;li&gt;What makes clinical text difficult to handle&lt;/li&gt;&#xA;&lt;li&gt;Privacy and de-identification&lt;/li&gt;&#xA;&lt;li&gt;A primer on Natural Language Processing&lt;/li&gt;&#xA;&lt;li&gt;Practical approach to processing clinical text&lt;/li&gt;&#xA;&lt;li&gt;Summary - Clinical text&lt;/li&gt;&#xA;&lt;li&gt;Overview and goals of medical imaging&lt;/li&gt;&#xA;&lt;li&gt;Why are images important?&lt;/li&gt;&#xA;&lt;li&gt;What are images?&lt;/li&gt;&#xA;&lt;li&gt;A typical image management process&lt;/li&gt;&#xA;&lt;li&gt;Summary - Images&lt;/li&gt;&#xA;&lt;li&gt;Overview of biomedical signals&lt;/li&gt;&#xA;&lt;li&gt;Why are signals important?&lt;/li&gt;&#xA;&lt;li&gt;What are signals?&lt;/li&gt;&#xA;&lt;li&gt;What are the major issues with using signals?&lt;/li&gt;&#xA;&lt;li&gt;Summary - Signals&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-6-putting-the-pieces-together-electronic-phenotyping&#34;&gt;&#xA;  Module 6: Putting the Pieces Together: Electronic Phenotyping&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-6-putting-the-pieces-together-electronic-phenotyping&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to electronic phenotyping&lt;/li&gt;&#xA;&lt;li&gt;Challenges in electronic phenotyping&lt;/li&gt;&#xA;&lt;li&gt;Specifying an electronic phenotype&lt;/li&gt;&#xA;&lt;li&gt;Two approaches to phenotyping&lt;/li&gt;&#xA;&lt;li&gt;Rule-based electronic phenotyping&lt;/li&gt;&#xA;&lt;li&gt;Examples of rule based electronic phenotype definitions&lt;/li&gt;&#xA;&lt;li&gt;Constructing a rule based phenotype definition&lt;/li&gt;&#xA;&lt;li&gt;Probabilistic phenotyping&lt;/li&gt;&#xA;&lt;li&gt;Approaches for creating a probabilistic phenotype definition&lt;/li&gt;&#xA;&lt;li&gt;Software for probabilistic phenotype definitions&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-7-ethics&#34;&gt;&#xA;  Module 7: Ethics&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-7-ethics&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to Research Ethics and AI&lt;/li&gt;&#xA;&lt;li&gt;The Belmont Report: A Framework for Research Ethics&lt;/li&gt;&#xA;&lt;li&gt;Ethical Issues in Data sources for AI&lt;/li&gt;&#xA;&lt;li&gt;Secondary Uses of Data&lt;/li&gt;&#xA;&lt;li&gt;Return of Results&lt;/li&gt;&#xA;&lt;li&gt;AI and The Learning Health System&lt;/li&gt;&#xA;&lt;li&gt;Ethics Summary&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>[ToC] Course 3</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/toc_course3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/toc_course3/</guid>
      <description>&lt;h2 id=&#34;toc-of-course-35-fundamentals-of-machine-learning-for-healthcare&#34;&gt;&#xA;  ToC of Course 3/5: Fundamentals of Machine Learning for Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#toc-of-course-35-fundamentals-of-machine-learning-for-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;module-3-concepts-and-principles-of-machine-learning-in-healthcare&#34;&gt;&#xA;  Module 3: Concepts and Principles of Machine Learning in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-3-concepts-and-principles-of-machine-learning-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to Deep Learning and Neural Networks&lt;/li&gt;&#xA;&lt;li&gt;Deep Learning and Neural Networks&lt;/li&gt;&#xA;&lt;li&gt;Cross Entropy Loss&lt;/li&gt;&#xA;&lt;li&gt;Gradient Descent&lt;/li&gt;&#xA;&lt;li&gt;Representing Unstructured Image and Text Data&lt;/li&gt;&#xA;&lt;li&gt;Convolutional Neural Networks&lt;/li&gt;&#xA;&lt;li&gt;Natural Language Processing and Recurrent Neural Networks&lt;/li&gt;&#xA;&lt;li&gt;The Transformer Architecture for Sequences&lt;/li&gt;&#xA;&lt;li&gt;Commonly Used and Advanced Neural Network Architectures&lt;/li&gt;&#xA;&lt;li&gt;Advanced Computer Vision Tasks and Wrap-Up&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-4-evaluation-and-metrics-for-machine-learning-in-healthcare&#34;&gt;&#xA;  Module 4: Evaluation and Metrics for Machine Learning in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-4-evaluation-and-metrics-for-machine-learning-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to Model Performance Evaluation&lt;/li&gt;&#xA;&lt;li&gt;Overfitting and Underfitting&lt;/li&gt;&#xA;&lt;li&gt;Strategies to Address Overfitting, Underfitting and Introduction to Regularization&lt;/li&gt;&#xA;&lt;li&gt;Statistical Approaches to Model Evaluation&lt;/li&gt;&#xA;&lt;li&gt;Receiver Operator and Precision Recall Curves as Evaluation Metrics&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-5-strategies-and-challenges-in-machine-learning-in-healthcare&#34;&gt;&#xA;  Module 5: Strategies and Challenges in Machine Learning in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-5-strategies-and-challenges-in-machine-learning-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to Common Clinical Machine Learning Challenges&lt;/li&gt;&#xA;&lt;li&gt;Utility of Causative Model Predictions&lt;/li&gt;&#xA;&lt;li&gt;Context in Clinical Machine Learning&lt;/li&gt;&#xA;&lt;li&gt;Intrinsic Interpretability&lt;/li&gt;&#xA;&lt;li&gt;Medical Data Challenges in Machine Learning Part 1&lt;/li&gt;&#xA;&lt;li&gt;Medical Data Challenges in Machine Learning Part 2&lt;/li&gt;&#xA;&lt;li&gt;How Much Data Do We Need?&lt;/li&gt;&#xA;&lt;li&gt;Retrospective Data in Medicine and &amp;ldquo;Shelf Life&amp;rdquo; for Data&lt;/li&gt;&#xA;&lt;li&gt;Medical Data: Quality vs Quantity&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-6-best-practices-teams-and-launching-your-machine-learning-journey&#34;&gt;&#xA;  Module 6: Best Practices, Teams, and Launching Your Machine Learning Journey&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-6-best-practices-teams-and-launching-your-machine-learning-journey&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Clinical Utility and Output Action Pairing&lt;/li&gt;&#xA;&lt;li&gt;Taking Action - Utilizing the OAP Framework&lt;/li&gt;&#xA;&lt;li&gt;Building Multidisciplinary Teams for Clinical Machine Learning&lt;/li&gt;&#xA;&lt;li&gt;Governance, Ethics, and Best Practices&lt;/li&gt;&#xA;&lt;li&gt;On Being Human in the Era of Clinical Machine Learning&lt;/li&gt;&#xA;&lt;li&gt;Death by GPS and Other Lessons of Automation Bias&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-7-foundation-models&#34;&gt;&#xA;  Module 7: Foundation Models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-7-foundation-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to Foundation Models&lt;/li&gt;&#xA;&lt;li&gt;Adapting to Technology&lt;/li&gt;&#xA;&lt;li&gt;General AI and Emergent Behavior&lt;/li&gt;&#xA;&lt;li&gt;How Foundation Models Work&lt;/li&gt;&#xA;&lt;li&gt;Healthcare Use Cases for Text Data&lt;/li&gt;&#xA;&lt;li&gt;Healthcare Use Cases for Non-textual Unstructured Data&lt;/li&gt;&#xA;&lt;li&gt;Challenges and Pitfalls&lt;/li&gt;&#xA;&lt;li&gt;Conclusion&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>[ToC] Course 4</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/toc_course4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/toc_course4/</guid>
      <description>&lt;h2 id=&#34;toc-of-course-45-evaluations-of-ai-applications-in-healthcare&#34;&gt;&#xA;  ToC of Course 4/5: Evaluations of AI Applications in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#toc-of-course-45-evaluations-of-ai-applications-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-1-ai-in-healthcare&#34;&gt;&#xA;  Module 1: AI in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-1-ai-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Learning Objectives&lt;/li&gt;&#xA;&lt;li&gt;Common Definitions&lt;/li&gt;&#xA;&lt;li&gt;Overview&lt;/li&gt;&#xA;&lt;li&gt;Why AI is needed in Healthcare&lt;/li&gt;&#xA;&lt;li&gt;Examples of AI in Healthcare&lt;/li&gt;&#xA;&lt;li&gt;Growth of AI in Healthcare&lt;/li&gt;&#xA;&lt;li&gt;Questions Answered by AI&lt;/li&gt;&#xA;&lt;li&gt;AI Output&lt;/li&gt;&#xA;&lt;li&gt;Think beyond area under the curve&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-2-evaluations-of-ai-in-healthcare&#34;&gt;&#xA;  Module 2: Evaluations of AI in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-2-evaluations-of-ai-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Learning Objectives&lt;/li&gt;&#xA;&lt;li&gt;Recap: Framework&lt;/li&gt;&#xA;&lt;li&gt;Stakeholders&lt;/li&gt;&#xA;&lt;li&gt;Clinical Utility&lt;/li&gt;&#xA;&lt;li&gt;Outcome: Action Pairing, An Overview&lt;/li&gt;&#xA;&lt;li&gt;Lead Time&lt;/li&gt;&#xA;&lt;li&gt;Type of Action&lt;/li&gt;&#xA;&lt;li&gt;OAP Examples&lt;/li&gt;&#xA;&lt;li&gt;Number Needed to Treat&lt;/li&gt;&#xA;&lt;li&gt;Net Benefits&lt;/li&gt;&#xA;&lt;li&gt;Decision Curves&lt;/li&gt;&#xA;&lt;li&gt;Feasibility overview&lt;/li&gt;&#xA;&lt;li&gt;Implementation Costs&lt;/li&gt;&#xA;&lt;li&gt;Clinical Evaluation and Uptake&lt;/li&gt;&#xA;&lt;li&gt;Summary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-3-ai-deployment&#34;&gt;&#xA;  Module 3: AI Deployment&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-3-ai-deployment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Learning Objectives&lt;/li&gt;&#xA;&lt;li&gt;The Problem&lt;/li&gt;&#xA;&lt;li&gt;Practical Questions Prior to Deployment&lt;/li&gt;&#xA;&lt;li&gt;Deployment Pathway&lt;/li&gt;&#xA;&lt;li&gt;Design and Development&lt;/li&gt;&#xA;&lt;li&gt;Stakeholder Involvement&lt;/li&gt;&#xA;&lt;li&gt;Data Type and Sources&lt;/li&gt;&#xA;&lt;li&gt;Settings&lt;/li&gt;&#xA;&lt;li&gt;In Silico Evaluation&lt;/li&gt;&#xA;&lt;li&gt;Net Utility &amp;amp; Work Capacity&lt;/li&gt;&#xA;&lt;li&gt;Statistical Validity&lt;/li&gt;&#xA;&lt;li&gt;Care Integration, Silent Mode&lt;/li&gt;&#xA;&lt;li&gt;Clinical Integration, Considerations&lt;/li&gt;&#xA;&lt;li&gt;Technical Integration&lt;/li&gt;&#xA;&lt;li&gt;Deployment Modalities&lt;/li&gt;&#xA;&lt;li&gt;Continuous Monitoring and Maintenance&lt;/li&gt;&#xA;&lt;li&gt;Challenges of Deployment&lt;/li&gt;&#xA;&lt;li&gt;Sepsis Example&lt;/li&gt;&#xA;&lt;li&gt;Summary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-4-downstream-evaluations-of-ai-in-healthcare-bias-and-fairness&#34;&gt;&#xA;  Module 4: Downstream Evaluations of AI in Healthcare: Bias and Fairness&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-4-downstream-evaluations-of-ai-in-healthcare-bias-and-fairness&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Learning Objectives&lt;/li&gt;&#xA;&lt;li&gt;Real World Examples of AI Bias&lt;/li&gt;&#xA;&lt;li&gt;Introduction - Types of Bias&lt;/li&gt;&#xA;&lt;li&gt;Historical Bias&lt;/li&gt;&#xA;&lt;li&gt;Representation Bias&lt;/li&gt;&#xA;&lt;li&gt;Measurement Bias&lt;/li&gt;&#xA;&lt;li&gt;Aggregation Bias&lt;/li&gt;&#xA;&lt;li&gt;Evaluation Bias&lt;/li&gt;&#xA;&lt;li&gt;Deployment Bias&lt;/li&gt;&#xA;&lt;li&gt;What is algorithmic Fairness&lt;/li&gt;&#xA;&lt;li&gt;Anti-classification&lt;/li&gt;&#xA;&lt;li&gt;Parity Classification&lt;/li&gt;&#xA;&lt;li&gt;Calibration&lt;/li&gt;&#xA;&lt;li&gt;Applying Fairness Measures&lt;/li&gt;&#xA;&lt;li&gt;Lack of Transparency&lt;/li&gt;&#xA;&lt;li&gt;Minimal Reporting Standards&lt;/li&gt;&#xA;&lt;li&gt;Opportunities and Challenges&lt;/li&gt;&#xA;&lt;li&gt;Summary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-5-the-regulatory-environment-for-ai-in-healthcare&#34;&gt;&#xA;  Module 5: The Regulatory Environment for AI in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-5-the-regulatory-environment-for-ai-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Learning Objectives&lt;/li&gt;&#xA;&lt;li&gt;The Problem&lt;/li&gt;&#xA;&lt;li&gt;International Definitions Used for Regulatory Purposes&lt;/li&gt;&#xA;&lt;li&gt;Definition Statement &amp;amp; Risk Framework&lt;/li&gt;&#xA;&lt;li&gt;Valid Clinical Association&lt;/li&gt;&#xA;&lt;li&gt;Analytical Evaluation&lt;/li&gt;&#xA;&lt;li&gt;Clinical Evaluation&lt;/li&gt;&#xA;&lt;li&gt;General Control&lt;/li&gt;&#xA;&lt;li&gt;de novo Notifications&lt;/li&gt;&#xA;&lt;li&gt;Software Modification&lt;/li&gt;&#xA;&lt;li&gt;TPLC&lt;/li&gt;&#xA;&lt;li&gt;Locked vs Adapted AI solutions&lt;/li&gt;&#xA;&lt;li&gt;Examples&lt;/li&gt;&#xA;&lt;li&gt;Non-Regulated Products&lt;/li&gt;&#xA;&lt;li&gt;EU Regulations&lt;/li&gt;&#xA;&lt;li&gt;Chinese Guidelines&lt;/li&gt;&#xA;&lt;li&gt;OMB Guidelines&lt;/li&gt;&#xA;&lt;li&gt;Summary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-7-ai-and-medicine-optional-content&#34;&gt;&#xA;  Module 7: AI and Medicine (Optional Content)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-7-ai-and-medicine-optional-content&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction: Navigating the Intersections of AI and Medicine&lt;/li&gt;&#xA;&lt;li&gt;Life Cycle of AI&lt;/li&gt;&#xA;&lt;li&gt;A Deep Dive into Historical and Societal Dimensions&lt;/li&gt;&#xA;&lt;li&gt;Race-Based Medicine and Race-Aware Approach&lt;/li&gt;&#xA;&lt;li&gt;Bias Mitigation Strategies&lt;/li&gt;&#xA;&lt;li&gt;Exploring Potentials and Ethical Quandaries&lt;/li&gt;&#xA;&lt;li&gt;Dismantling Race-Based Medicine&lt;/li&gt;&#xA;&lt;li&gt;Deploying AI into Healthcare Settings&lt;/li&gt;&#xA;&lt;li&gt;Conclusion&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Data-Centric AI vs Model-Centric AI</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/data-centric-vs-model-centric/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/data-centric-vs-model-centric/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Data-Centric AI vs Model-Centric AI &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;MIT Lecture : &lt;a href=&#34;https://dcai.csail.mit.edu/&#34;&gt;https://dcai.csail.mit.edu/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;GitHub for Labs: &lt;a href=&#34;https://github.com/dcai-course/dcai-lab&#34;&gt;https://github.com/dcai-course/dcai-lab&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-is-the-traditional-model-centric-approach-to-machine-learning&#34;&gt;&#xA;  Q1: What is the traditional model-centric approach to machine learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-the-traditional-model-centric-approach-to-machine-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Traditionally, machine learning has focused on &lt;em&gt;model-centric AI&lt;/em&gt;, where the dataset is fixed and the goal is to tune the model:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Learn different model architectures&lt;/li&gt;&#xA;&lt;li&gt;Modify hyperparameters and training losses&lt;/li&gt;&#xA;&lt;li&gt;Focus on improving model performance given clean data&lt;/li&gt;&#xA;&lt;li&gt;This is how ML is often taught in courses (e.g., MIT 6.036)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q2-what-challenges-arise-in-real-world-ml-settings&#34;&gt;&#xA;  Q2: What challenges arise in real-world ML settings?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-challenges-arise-in-real-world-ml-settings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Real-world data is:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 1 - Foundational LLMs &amp; Text Generation</title>
      <link>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day1_foundational_llm_text_generation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day1_foundational_llm_text_generation/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Day 1 - Foundational LLMs &amp; Text Generation&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;foundations-of-llms&#34;&gt;&#xA;  &lt;strong&gt;Foundations of LLMs&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#foundations-of-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-why-llms-matter&#34;&gt;&#xA;  1. Why LLMs Matter&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-llms-matter&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Traditional NLP systems were narrow, but Large Language Models (LLMs) offer general-purpose capabilities like translation, Q&amp;amp;A, and summarization—all without explicit task-specific programming.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ How do LLMs work under the hood?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-what-powers-llms-the-transformer&#34;&gt;&#xA;  2. What Powers LLMs: The Transformer&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-powers-llms-the-transformer&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;The Transformer is the core architecture enabling LLMs. Unlike RNNs that process data sequentially, Transformers handle inputs in parallel using &lt;strong&gt;self-attention&lt;/strong&gt;, allowing them to model long-range dependencies more efficiently and scale training.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module 1: Asking Answering Questions via Clinical DataMining</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m1/</guid>
      <description>&lt;h2 id=&#34;module-1-asking-answering-questions-via-clinical-datamining&#34;&gt;&#xA;  &lt;strong&gt;Module 1: Asking Answering Questions via Clinical DataMining&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-1-asking-answering-questions-via-clinical-datamining&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-the-data-mining-workflow&#34;&gt;&#xA;  1 Introduction to the data mining workflow&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction-to-the-data-mining-workflow&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q-what-is-the-main-goal-of-this-course&#34;&gt;&#xA;  Q: What is the main goal of this course?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-is-the-main-goal-of-this-course&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: To explain how clinical data can be used to answer research questions that improve patient and population health.&lt;/p&gt;&#xA;&lt;h3 id=&#34;q-what-is-the-structure-of-the-course&#34;&gt;&#xA;  Q: What is the structure of the course?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-is-the-structure-of-the-course&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: It begins with choosing meaningful research questions, followed by understanding the healthcare system, exploring data types, reviewing processing and analysis methods, and addressing bias and error.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 1 – Prompt Engineering</title>
      <link>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day1_prompt_engineering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day1_prompt_engineering/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Day 1 – Prompt Engineering&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-why-prompt-engineering-matters&#34;&gt;&#xA;  1. Why Prompt Engineering Matters&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-prompt-engineering-matters&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;need for controlling LLM behavior&lt;/em&gt;. Although everyone can write prompts, crafting high-quality prompts is complex. The model, structure, tone, and context all affect the outcome. Prompt engineering is an iterative process requiring optimization and experimentation.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ how do we guide LLMs effectively without retraining them?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-how-llms-predict-text&#34;&gt;&#xA;  2. How LLMs Predict Text&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-how-llms-predict-text&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;LLMs are &lt;em&gt;token prediction machines&lt;/em&gt;. They predict the next likely token based on previous tokens and training data. Prompt engineering means designing inputs that lead the model toward the desired outputs using this prediction mechanism.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Label Errors</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/label-errors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/label-errors/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Label Errors &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-are-label-errors-and-why-do-they-matter&#34;&gt;&#xA;  Q1: What are label errors and why do they matter?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-are-label-errors-and-why-do-they-matter&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Label errors&lt;/strong&gt;: Incorrect labels in training/testing datasets.&lt;/li&gt;&#xA;&lt;li&gt;They cause &lt;strong&gt;worse model performance&lt;/strong&gt;, &lt;strong&gt;benchmark misinterpretation&lt;/strong&gt;, and &lt;strong&gt;deployment risks&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q2-what-are-the-types-of-label-noise&#34;&gt;&#xA;  Q2: What are the types of label noise?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-are-the-types-of-label-noise&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Uniform/Symmetric noise&lt;/strong&gt;: Random label flipping.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Systematic/Asymmetric noise&lt;/strong&gt;: Certain labels more likely flipped.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Instance-dependent noise&lt;/strong&gt;: Noise depends on input features (out of scope here).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q3-what-is-confident-learning-cl&#34;&gt;&#xA;  Q3: What is Confident Learning (CL)?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-what-is-confident-learning-cl&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A framework to:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Find label errors&lt;/li&gt;&#xA;&lt;li&gt;Rank examples by label issue likelihood&lt;/li&gt;&#xA;&lt;li&gt;Learn with noisy labels&lt;/li&gt;&#xA;&lt;li&gt;Characterize noise structure&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Model-agnostic&lt;/strong&gt;: uses model-predicted probabilities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q4-how-does-cl-detect-label-errors&#34;&gt;&#xA;  Q4: How does CL detect label errors?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q4-how-does-cl-detect-label-errors&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Use predicted probabilities + noisy labels.&lt;/li&gt;&#xA;&lt;li&gt;Estimate joint distribution of noisy vs. true labels.&lt;/li&gt;&#xA;&lt;li&gt;Detect off-diagonal entries = label errors.&lt;/li&gt;&#xA;&lt;li&gt;Key techniques: &lt;strong&gt;Prune&lt;/strong&gt;, &lt;strong&gt;Count&lt;/strong&gt;, &lt;strong&gt;Rank&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;q5-why-is-a-noise-process-assumption-needed&#34;&gt;&#xA;  Q5: Why is a noise process assumption needed?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q5-why-is-a-noise-process-assumption-needed&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;To &lt;strong&gt;separate&lt;/strong&gt; model uncertainty (epistemic) and label noise (aleatoric).&lt;/li&gt;&#xA;&lt;li&gt;CL assumes &lt;strong&gt;class-conditional noise&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q6-why-not-just-sort-by-loss&#34;&gt;&#xA;  Q6: Why not just sort by loss?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q6-why-not-just-sort-by-loss&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sorting by loss doesn&amp;rsquo;t tell you:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Where to cut off&lt;/li&gt;&#xA;&lt;li&gt;How many label errors exist&lt;/li&gt;&#xA;&lt;li&gt;How to automate error finding without human review&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q7-how-does-cl-achieve-robustness-to-imperfect-predictions&#34;&gt;&#xA;  Q7: How does CL achieve robustness to imperfect predictions?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q7-how-does-cl-achieve-robustness-to-imperfect-predictions&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Prune&lt;/strong&gt; low-confidence examples&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Count&lt;/strong&gt; robustly across examples&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rank&lt;/strong&gt; by predicted probabilities&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q8-how-does-label-noise-affect-real-world-ml&#34;&gt;&#xA;  Q8: How does label noise affect real-world ML?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q8-how-does-label-noise-affect-real-world-ml&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Real-world datasets are &lt;strong&gt;not random noise&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Deep learning claims about noise robustness often assume unrealistic random noise.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q9-what-happens-when-test-sets-have-label-errors&#34;&gt;&#xA;  Q9: What happens when test sets have label errors?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q9-what-happens-when-test-sets-have-label-errors&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Benchmark &lt;strong&gt;model rankings change&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;A &amp;ldquo;better&amp;rdquo; model might actually underperform in deployment.&lt;/li&gt;&#xA;&lt;li&gt;Quantifying label errors in &lt;strong&gt;test sets is critical&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q10-how-can-practitioners-fix-this&#34;&gt;&#xA;  Q10: How can practitioners fix this?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q10-how-can-practitioners-fix-this&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use &lt;strong&gt;corrected test sets&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Benchmark using cleaned labels.&lt;/li&gt;&#xA;&lt;li&gt;Tools like &lt;strong&gt;cleanlab&lt;/strong&gt; can automate finding label issues.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q11-key-takeaways&#34;&gt;&#xA;  Q11: Key Takeaways&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q11-key-takeaways&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Confident learning enables data-centric model improvements.&lt;/li&gt;&#xA;&lt;li&gt;Even small label error rates (~3-6%) can &lt;strong&gt;destabilize ML benchmarks&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;ML needs to &lt;strong&gt;quantify label noise&lt;/strong&gt; to ensure real-world reliability.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;references&#34;&gt;&#xA;  References&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#references&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1911.00068&#34;&gt;Confident Learning Paper (JAIR 2021)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.14749&#34;&gt;Pervasive Label Errors Paper (NeurIPS 2021)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://labelerrors.com/&#34;&gt;Label Errors Website&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cleanlab/cleanlab&#34;&gt;Cleanlab GitHub&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>[Summary] Module2: Data Available From Healthcare Systems</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m2/</guid>
      <description>&lt;h2 id=&#34;module2-data-available-from-healthcare-systems&#34;&gt;&#xA;  Module2: Data Available From Healthcare Systems&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module2-data-available-from-healthcare-systems&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-review-of-the-healthcare-system&#34;&gt;&#xA;  1 Review of the healthcare system&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-review-of-the-healthcare-system&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q-what-is-the-focus-of-this-modules-introduction&#34;&gt;&#xA;  Q: What is the focus of this module&amp;rsquo;s introduction?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-is-the-focus-of-this-modules-introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: To demonstrate how clinical data from the healthcare system can be used to ask and answer meaningful research questions.&lt;/p&gt;&#xA;&lt;h3 id=&#34;q-what-key-topics-are-introduced-in-this-session&#34;&gt;&#xA;  Q: What key topics are introduced in this session?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-key-topics-are-introduced-in-this-session&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Common data sources in healthcare&lt;/li&gt;&#xA;&lt;li&gt;Types of data generated&lt;/li&gt;&#xA;&lt;li&gt;Systematic inaccuracies in the data&lt;/li&gt;&#xA;&lt;li&gt;Strategies for working with imperfect data&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q-how-does-this-connect-to-the-earlier-module&#34;&gt;&#xA;  Q: How does this connect to the earlier module?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-how-does-this-connect-to-the-earlier-module&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: It builds on the discussion of research question formulation and data mining workflows by diving into real-world data availability and limitations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Advanced Confident Learning and Applications for GenAI</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/advanced-confident-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/advanced-confident-learning/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Advanced Confident Learning and Applications for GenAI&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-is-the-main-focus-of-this-lecture&#34;&gt;&#xA;  Q1: What is the main focus of this lecture?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-the-main-focus-of-this-lecture&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Advanced Confident Learning (CL)&lt;/strong&gt;: Theory, methods, and applications, especially for &lt;strong&gt;Generative AI&lt;/strong&gt; (images, text).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q2-how-does-confident-learning-cl-work-at-its-core&#34;&gt;&#xA;  Q2: How does Confident Learning (CL) work at its core?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-how-does-confident-learning-cl-work-at-its-core&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Inputs: &lt;strong&gt;Noisy labels&lt;/strong&gt; and &lt;strong&gt;predicted probabilities&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Core idea: Find &lt;strong&gt;self-confidence thresholds&lt;/strong&gt; per class to detect label errors.&lt;/li&gt;&#xA;&lt;li&gt;Estimate if an example is an error, correct label, or outlier.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q3-what-is-the-quick-intuition-behind-cl&#34;&gt;&#xA;  Q3: What is the quick intuition behind CL?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-what-is-the-quick-intuition-behind-cl&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Off-diagonal entries in the predicted-vs-true label matrix reveal &lt;strong&gt;label errors&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q4-what-makes-cl-robust-to-noise&#34;&gt;&#xA;  Q4: What makes CL robust to noise?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q4-what-makes-cl-robust-to-noise&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Prune principle&lt;/strong&gt;: Remove low-confidence errors before training.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Count principle&lt;/strong&gt;: Use counts rather than raw outputs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rank principle&lt;/strong&gt;: Rank by model confidence, not rely on probabilities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q5-how-is-cl-better-than-just-loss-adjustment-techniques&#34;&gt;&#xA;  Q5: How is CL better than just loss adjustment techniques?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q5-how-is-cl-better-than-just-loss-adjustment-techniques&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;CL &lt;strong&gt;avoids error propagation&lt;/strong&gt; common in reweighting methods.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Robust&lt;/strong&gt; to stochastic/noisy outputs from real-world models.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q6-what-is-the-theoretical-guarantee-of-cl&#34;&gt;&#xA;  Q6: What is the theoretical guarantee of CL?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q6-what-is-the-theoretical-guarantee-of-cl&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;As long as correct labels dominate wrong ones in a class, CL can exactly find errors — even if model probabilities are imperfect (up to ~33% wrong).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q7-why-does-label-noise-in-test-sets-matter&#34;&gt;&#xA;  Q7: Why does label noise in test sets matter?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q7-why-does-label-noise-in-test-sets-matter&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;3.4% of labels&lt;/strong&gt; in popular ML test sets are wrong.&lt;/li&gt;&#xA;&lt;li&gt;Small label error rates (~6%) can &lt;strong&gt;change model rankings&lt;/strong&gt; drastically.&lt;/li&gt;&#xA;&lt;li&gt;Benchmark results can be misleading without corrected test sets.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q8-how-to-fix-label-errors-in-test-sets&#34;&gt;&#xA;  Q8: How to fix label errors in test sets?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q8-how-to-fix-label-errors-in-test-sets&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use &lt;strong&gt;majority consensus&lt;/strong&gt; among reviewers to correct labels.&lt;/li&gt;&#xA;&lt;li&gt;Prune uncertain/multi-label examples.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q9-how-is-cl-applied-to-generative-ai-models&#34;&gt;&#xA;  Q9: How is CL applied to Generative AI models?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q9-how-is-cl-applied-to-generative-ai-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Before training&lt;/strong&gt;: Clean training data to avoid issues in model generation.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;After generation&lt;/strong&gt;: Run CL on generated data (e.g., images/text) to remove/fix errors.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q10-example-use-cases-for-cl-in-generative-ai&#34;&gt;&#xA;  Q10: Example use cases for CL in Generative AI?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q10-example-use-cases-for-cl-in-generative-ai&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Scenario&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Application&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Image generation (e.g., DALL-E)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Improve datasets pre/post generation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;LLM outputs (e.g., GPT-4)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Post-process outputs for better quality&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;RAG (Retrieval-Augmented Generation)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Clean retrieved answers&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Trustworthy Language Models (TLM)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Attach confidence scores to outputs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;q11-final-takeaways&#34;&gt;&#xA;  Q11: Final Takeaways&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q11-final-takeaways&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;CL is &lt;strong&gt;model-agnostic&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Improves reliability&lt;/strong&gt; of both traditional ML models and Generative AI.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;One line of code&lt;/strong&gt; to apply using &lt;a href=&#34;https://github.com/cleanlab/cleanlab&#34;&gt;cleanlab&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;references&#34;&gt;&#xA;  References&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#references&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cleanlab/cleanlab&#34;&gt;Confident Learning: GitHub Repository&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://labelerrors.com/&#34;&gt;Label Errors Website&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://help.cleanlab.ai/tutorials/tlm/&#34;&gt;Trustworthy Language Models (TLM) Tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.14165&#34;&gt;Related Papers:&lt;/a&gt; (GPT-3), (Northcutt et al., Pervasive Label Errors, 2021)&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Day 2 – Embeddings &amp; Vector Databases</title>
      <link>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day2_embeddings_vectordb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day2_embeddings_vectordb/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Day 2 – Embeddings &amp; Vector Databases&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-why-embeddings&#34;&gt;&#xA;  1. Why Embeddings?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We begin with the &lt;em&gt;core problem of representing diverse data types&lt;/em&gt;. Images, text, audio, and structured data all need to be compared, retrieved, and clustered. Embeddings map these into a shared vector space where similarity can be computed numerically.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ how can we measure and preserve semantic meaning across different data types?&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module 3: Concepts and Principles of ML in Healthcare</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m3/</guid>
      <description>&lt;h2 id=&#34;module-3-concepts-and-principles-of-ml-in-healthcare&#34;&gt;&#xA;  &lt;strong&gt;Module 3: Concepts and Principles of ML in Healthcare&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-3-concepts-and-principles-of-ml-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-deep-learning-and-neural-networks&#34;&gt;&#xA;  1 Introduction to Deep Learning and Neural Networks&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction-to-deep-learning-and-neural-networks&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-why-are-neural-networks-considered-a-turning-point-in-machine-learning&#34;&gt;&#xA;  Q1: Why are neural networks considered a turning point in machine learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-why-are-neural-networks-considered-a-turning-point-in-machine-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Neural networks mark a major departure from traditional ML models because they enable much &lt;strong&gt;deeper interactions&lt;/strong&gt; between features and parameters. Unlike models like logistic regression or decision trees, neural networks—especially deep ones—organize parameters in &lt;strong&gt;layers&lt;/strong&gt;, allowing complex feature transformations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module3: Representing Time Timing Events For Clinical Data Mining</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m3/</guid>
      <description>&lt;h2 id=&#34;module3-representing-time-timing-events-for-clinical-data-mining&#34;&gt;&#xA;  Module3: Representing Time Timing Events For Clinical Data Mining&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module3-representing-time-timing-events-for-clinical-data-mining&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-time-timelines-timescales-and-representations-of-time&#34;&gt;&#xA;  1 Time, timelines, timescales and representations of time&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-time-timelines-timescales-and-representations-of-time&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q-why-is-it-useful-to-place-patient-events-on-a-timeline&#34;&gt;&#xA;  Q: Why is it useful to place patient events on a timeline?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-why-is-it-useful-to-place-patient-events-on-a-timeline&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: Timelines integrate diverse patient data sources, helping visualize when each event occurred, enabling analysis of sequence and duration.&lt;/p&gt;&#xA;&lt;h3 id=&#34;q-what-are-two-key-reasons-time-matters-in-healthcare-data&#34;&gt;&#xA;  Q: What are two key reasons time matters in healthcare data?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-are-two-key-reasons-time-matters-in-healthcare-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Patient age&lt;/strong&gt;: Impacts diagnosis, treatment decisions, metabolism, and insurance access.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Event order&lt;/strong&gt;: Helps infer causality — exposures should precede outcomes.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;q-how-do-timescales-vary-in-medical-questions&#34;&gt;&#xA;  Q: How do timescales vary in medical questions?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-how-do-timescales-vary-in-medical-questions&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: Medical events can span milliseconds (e.g., EKG signals), days (e.g., symptom onset), or decades (e.g., chronic disease progression), requiring careful scale selection.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module4 : Creating Analysis Ready Dataset from Patient Timelines</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m4/</guid>
      <description>&lt;h2 id=&#34;module4--creating-analysis-ready-dataset-from-patient-timelines&#34;&gt;&#xA;  &lt;strong&gt;Module4 : Creating Analysis Ready Dataset from Patient Timelines&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module4--creating-analysis-ready-dataset-from-patient-timelines&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-turning-clinical-data-into-something-you-can-analyze&#34;&gt;&#xA;  1 Turning clinical data into something you can analyze&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-turning-clinical-data-into-something-you-can-analyze&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q-what-is-the-main-objective-of-this-module&#34;&gt;&#xA;  Q: What is the main objective of this module?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-is-the-main-objective-of-this-module&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: To explain how to convert raw clinical data into a patient-feature matrix suitable for analysis and answering research questions.&lt;/p&gt;&#xA;&lt;h3 id=&#34;q-what-is-a-patient-feature-matrix&#34;&gt;&#xA;  Q: What is a patient-feature matrix?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-is-a-patient-feature-matrix&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: A structured table where each row represents a patient and each column represents a clinical feature or measurement.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ch4 EHR</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/hands-on-healthcare-data/ch4_ehr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/hands-on-healthcare-data/ch4_ehr/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Ch4 Deep Dive – Electronic Health Records (EHR) &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-is-the-central-focus-of-chapter-4&#34;&gt;&#xA;  Q1: What is the central focus of Chapter 4?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-the-central-focus-of-chapter-4&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Chapter 4 focuses on working with electronic health record (EHR) data using the &lt;strong&gt;MIMIC-III&lt;/strong&gt; dataset, and explores &lt;strong&gt;medication harmonization&lt;/strong&gt; using SQL, Neo4j (property graph), and TypeDB (typed hypergraph).&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q2-what-makes-working-with-ehr-data-complex&#34;&gt;&#xA;  Q2: What makes working with EHR data complex?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-makes-working-with-ehr-data-complex&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;EHRs are &lt;strong&gt;highly structured&lt;/strong&gt; but vary between implementations.&lt;/li&gt;&#xA;&lt;li&gt;Data is often &lt;strong&gt;redundant, inconsistent, or missing&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Clinical context and domain knowledge are crucial for correct interpretation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q3-why-was-medication-harmonization-chosen-as-the-use-case&#34;&gt;&#xA;  Q3: Why was &lt;strong&gt;medication harmonization&lt;/strong&gt; chosen as the use case?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-why-was-medication-harmonization-chosen-as-the-use-case&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Because medications are objective and widely used in EHRs, but the &lt;strong&gt;same drug&lt;/strong&gt; can appear under multiple names or codes (e.g. NDCs). Harmonization is necessary to:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Class Imbalance, Outliers, and Distribution Shift</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/class-imbalance-outliers-distribution-shift/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/class-imbalance-outliers-distribution-shift/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Class Imbalance, Outliers, and Distribution Shift &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-are-the-main-problems-discussed-in-this-lecture&#34;&gt;&#xA;  Q1: What are the main problems discussed in this lecture?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-are-the-main-problems-discussed-in-this-lecture&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Class imbalance&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Outliers&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Distribution shift&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q2-what-is-class-imbalance-and-why-is-it-a-problem&#34;&gt;&#xA;  Q2: What is class imbalance and why is it a problem?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-is-class-imbalance-and-why-is-it-a-problem&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Some classes occur much less frequently than others.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Examples&lt;/strong&gt;: COVID detection, fraud detection, manufacturing defects, self-driving cars.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Impact&lt;/strong&gt;: Naive models can have misleadingly high accuracy while failing on rare classes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q3-how-do-we-address-class-imbalance&#34;&gt;&#xA;  Q3: How do we address class imbalance?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-how-do-we-address-class-imbalance&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sampling Techniques&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sample weights&lt;/strong&gt; (less stable for mini-batch training)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Over-sampling&lt;/strong&gt; (replicating minority class examples)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Under-sampling&lt;/strong&gt; (dropping majority class examples)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SMOTE&lt;/strong&gt; (synthetic minority over-sampling)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Balanced mini-batch training&lt;/strong&gt; (better distribution in each batch)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Choose appropriate evaluation metrics&lt;/strong&gt;: precision, recall, F-beta score.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q4-what-are-outliers-and-why-are-they-problematic&#34;&gt;&#xA;  Q4: What are outliers and why are they problematic?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q4-what-are-outliers-and-why-are-they-problematic&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Datapoints that differ significantly from the norm.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Causes&lt;/strong&gt;: Measurement error, bad data collection, adversarial inputs, rare events.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Impact&lt;/strong&gt;: Outliers can harm training and inference stability.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q5-how-do-we-detect-outliers&#34;&gt;&#xA;  Q5: How do we detect outliers?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q5-how-do-we-detect-outliers&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Simple methods&lt;/strong&gt;: Tukey&amp;rsquo;s fences, Z-score analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;More advanced&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Isolation forest&lt;/strong&gt; (tree-based)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;KNN distance&lt;/strong&gt; (neighbor proximity)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Autoencoders&lt;/strong&gt; (reconstruction loss)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;: ROC curve and AUROC score.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q6-what-is-distribution-shift&#34;&gt;&#xA;  Q6: What is distribution shift?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q6-what-is-distribution-shift&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Training and test distributions differ.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Almost all real-world ML deployments experience it.&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q7-what-are-the-types-of-distribution-shift&#34;&gt;&#xA;  Q7: What are the types of distribution shift?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q7-what-are-the-types-of-distribution-shift&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Type&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Meaning&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Example&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Covariate shift&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;(p(x)) changes, (p(y&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;x)) stays the same&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Concept shift&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;(p(y&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;x)) changes, (p(x)) stays the same&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Prior probability shift&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;(p(y)) changes, (p(x&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;y)) stays the same&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;q8-how-do-we-detect-and-handle-distribution-shift&#34;&gt;&#xA;  Q8: How do we detect and handle distribution shift?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q8-how-do-we-detect-and-handle-distribution-shift&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Detection&lt;/strong&gt;: Monitor metrics and statistical properties of data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Handling&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Retrain with better data.&lt;/li&gt;&#xA;&lt;li&gt;Use sample reweighting if unlabeled test data is available.&lt;/li&gt;&#xA;&lt;li&gt;Concept shift remains hardest to fix without labeled test data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q9-final-takeaways&#34;&gt;&#xA;  Q9: Final Takeaways&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q9-final-takeaways&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Handling &lt;strong&gt;class imbalance, outliers, and distribution shift&lt;/strong&gt; is critical for building robust, real-world ML systems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Evaluation metric choice&lt;/strong&gt;, &lt;strong&gt;proper data preprocessing&lt;/strong&gt;, and &lt;strong&gt;continuous monitoring&lt;/strong&gt; are key strategies.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;references&#34;&gt;&#xA;  References&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#references&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://imbalanced-learn.org&#34;&gt;imbalanced-learn package&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1106.1813&#34;&gt;SMOTE Paper&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pyod.readthedocs.io/&#34;&gt;PyOD library for outlier detection&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://direct.mit.edu/books/book/3841/Dataset-Shift-in-Machine-Learning&#34;&gt;Dataset Shift Book&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/outlier_detection.html&#34;&gt;Outlier detection in scikit-learn&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/dcai-course/dcai-lab/blob/master/outliers/Lab%20-%20Outliers.ipynb&#34;&gt;Lab assignment for Outliers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Day 3 – Generative Agents</title>
      <link>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day3_generative_agents/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day3_generative_agents/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Day 3 – Generative Agents&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-what-are-generative-agents&#34;&gt;&#xA;  1. What Are Generative Agents?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-what-are-generative-agents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;definition of agents&lt;/em&gt;—AI systems designed to achieve goals by perceiving their environment and taking actions using tools. Unlike static LLMs, generative agents combine models, tools, and orchestration to interact with the world dynamically.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ what components make these agents truly autonomous and intelligent?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-agent-architecture-breakdown&#34;&gt;&#xA;  2. Agent Architecture Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-agent-architecture-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;An agent’s architecture includes:&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module 4: Evaluation and Metrics for ML in Healthcare</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m4/</guid>
      <description>&lt;h2 id=&#34;module-4-evaluation-and-metrics-for-ml-in-healthcare&#34;&gt;&#xA;  &lt;strong&gt;Module 4: Evaluation and Metrics for ML in Healthcare&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-4-evaluation-and-metrics-for-ml-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-model-performance-evaluation&#34;&gt;&#xA;  1 Introduction to Model Performance Evaluation&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction-to-model-performance-evaluation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-why-is-model-evaluation-critical-in-healthcare-machine-learning&#34;&gt;&#xA;  Q1: Why is model evaluation critical in healthcare machine learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-why-is-model-evaluation-critical-in-healthcare-machine-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;In healthcare, decisions informed by ML models can have life-altering consequences:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It’s not enough for a model to perform well on training data.&lt;/li&gt;&#xA;&lt;li&gt;We need to ensure that the model performs well on &lt;strong&gt;unseen patients&lt;/strong&gt; and &lt;strong&gt;real-world conditions&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Rigorous evaluation is essential to &lt;strong&gt;trust and validate clinical usefulness&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;➡️  What does it mean for a model to generalize?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dataset Creation and Curation</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/dataset-creation-curation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/dataset-creation-curation/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Dataset Creation and Curation &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-are-the-main-themes-of-dataset-creation-and-curation&#34;&gt;&#xA;  Q1: What are the main themes of dataset creation and curation?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-are-the-main-themes-of-dataset-creation-and-curation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Framing the ML task correctly.&lt;/li&gt;&#xA;&lt;li&gt;Addressing data sourcing concerns like selection bias.&lt;/li&gt;&#xA;&lt;li&gt;Handling label sourcing and quality control.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q2-why-is-careful-sourcing-of-data-important&#34;&gt;&#xA;  Q2: Why is careful sourcing of data important?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-why-is-careful-sourcing-of-data-important&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ML models exploit spurious correlations.&lt;/li&gt;&#xA;&lt;li&gt;If training data does not match real-world deployment conditions, models can fail badly.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q3-what-is-selection-bias-and-what-are-its-common-causes&#34;&gt;&#xA;  Q3: What is selection bias and what are its common causes?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-what-is-selection-bias-and-what-are-its-common-causes&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Selection bias&lt;/strong&gt;: Systematic mismatch between training data and deployment data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Causes&lt;/strong&gt;: Time/location bias, demographic bias, response bias, availability bias, long tail bias.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q4-how-can-we-deal-with-selection-bias-during-data-collection&#34;&gt;&#xA;  Q4: How can we deal with selection bias during data collection?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q4-how-can-we-deal-with-selection-bias-during-data-collection&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Hold out validation sets that mimic deployment conditions, such as latest data, new locations, or oversampled rare events.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q5-how-can-we-estimate-how-much-data-we-need&#34;&gt;&#xA;  Q5: How can we estimate how much data we need?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q5-how-can-we-estimate-how-much-data-we-need&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use a method to measure learning curves by sub-sampling data and fitting a simple log-log model to predict performance scaling.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q6-what-is-the-formula-used-to-predict-model-error-with-more-data&#34;&gt;&#xA;  Q6: What is the formula used to predict model error with more data?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q6-what-is-the-formula-used-to-predict-model-error-with-more-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;( \log(&#x9;ext{error}) = -a \cdot \log(n) + b )&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q7-what-are-concerns-when-labeling-data-with-crowdsourced-workers&#34;&gt;&#xA;  Q7: What are concerns when labeling data with crowdsourced workers?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q7-what-are-concerns-when-labeling-data-with-crowdsourced-workers&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Variability in annotator accuracy.&lt;/li&gt;&#xA;&lt;li&gt;Possibility of annotator collusion.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q8-how-can-we-maintain-label-quality-during-crowdsourcing&#34;&gt;&#xA;  Q8: How can we maintain label quality during crowdsourcing?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q8-how-can-we-maintain-label-quality-during-crowdsourcing&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Insert &amp;ldquo;quality control&amp;rdquo; examples with known ground-truth to monitor annotator performance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q9-what-methods-are-used-to-curate-labels-from-multiple-annotators&#34;&gt;&#xA;  Q9: What methods are used to curate labels from multiple annotators?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q9-what-methods-are-used-to-curate-labels-from-multiple-annotators&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Majority Vote and Inter-Annotator Agreement&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Dawid-Skene model&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;CROWDLAB&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q10-how-does-majority-vote-work&#34;&gt;&#xA;  Q10: How does Majority Vote work?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q10-how-does-majority-vote-work&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Assigns the label chosen by the majority of annotators.&lt;/li&gt;&#xA;&lt;li&gt;Confidence is based on inter-annotator agreement.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q11-what-are-downsides-of-majority-vote&#34;&gt;&#xA;  Q11: What are downsides of Majority Vote?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q11-what-are-downsides-of-majority-vote&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ties are ambiguous.&lt;/li&gt;&#xA;&lt;li&gt;Bad annotators have equal influence as good ones.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q12-what-is-the-dawid-skene-model&#34;&gt;&#xA;  Q12: What is the Dawid-Skene model?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q12-what-is-the-dawid-skene-model&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Models each annotator with a confusion matrix.&lt;/li&gt;&#xA;&lt;li&gt;Uses Bayesian inference (often approximated with EM) to estimate consensus labels and annotator quality.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q13-what-are-limitations-of-dawid-skene&#34;&gt;&#xA;  Q13: What are limitations of Dawid-Skene?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q13-what-are-limitations-of-dawid-skene&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Requires strong assumptions.&lt;/li&gt;&#xA;&lt;li&gt;Performs poorly if examples are labeled by few annotators.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q14-what-is-crowdlab&#34;&gt;&#xA;  Q14: What is CROWDLAB?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q14-what-is-crowdlab&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Combines classifier predictions and annotator labels for better consensus.&lt;/li&gt;&#xA;&lt;li&gt;Weights depend on model confidence and inter-annotator agreement.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q15-how-does-crowdlab-work&#34;&gt;&#xA;  Q15: How does CROWDLAB work?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q15-how-does-crowdlab-work&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For examples labeled by few annotators, rely more on the classifier.&lt;/li&gt;&#xA;&lt;li&gt;For examples labeled by many annotators, rely more on label agreement.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q16-how-are-weights-estimated-in-crowdlab&#34;&gt;&#xA;  Q16: How are weights estimated in CROWDLAB?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q16-how-are-weights-estimated-in-crowdlab&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Based on annotator agreement rates and classifier accuracy normalized against a majority-class baseline.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q17-what-is-the-hands-on-lab-assignment-for-this-lecture&#34;&gt;&#xA;  Q17: What is the hands-on lab assignment for this lecture?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q17-what-is-the-hands-on-lab-assignment-for-this-lecture&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Analyze a multi-annotator dataset and implement methods for estimating consensus labels and annotator quality.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;references&#34;&gt;&#xA;  References&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#references&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://books.google.com/books/about/Human_in_the_Loop_Machine_Learning.html?id=LCh0zQEACAAJ&#34;&gt;Human-in-the-Loop ML textbook&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1807.04975&#34;&gt;Recognition in terra incognita (Beery et al., 2018)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1909.12673&#34;&gt;Constructive prediction of generalization error (Rosenfeld et al., 2020)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.06812&#34;&gt;CROWDLAB paper (Goh et al., 2022)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://catalogofbias.org/biases/selection-bias/&#34;&gt;Catalogue of Bias (Selection Bias)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/dcai-course/dcai-lab/blob/master/dataset_curation/Lab%20-%20Dataset%20Curation.ipynb&#34;&gt;Dataset curation lab notebook&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Day 4 – Domain-Specific LLMs</title>
      <link>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day4_domainspecific_llms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day4_domainspecific_llms/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Day 4 – Domain-Specific LLMs&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-the-rise-of-specialized-llms&#34;&gt;&#xA;  1. The Rise of Specialized LLMs&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-the-rise-of-specialized-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;evolution of LLMs&lt;/em&gt; from general-purpose to domain-specific tools. This shift was driven by challenges in fields like cybersecurity and medicine, where technical language and sensitive use cases demand more than general knowledge.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ why do general-purpose LLMs struggle in specialized domains?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-the-challenges-in-cybersecurity&#34;&gt;&#xA;  2. The Challenges in Cybersecurity&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-the-challenges-in-cybersecurity&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Cybersecurity experts face three main issues: rapidly evolving threats, repetitive manual work (toil), and a shortage of skilled talent. These bottlenecks make it hard to keep up with modern security needs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module 5: Strategies and Challenges in ML for Healthcare</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m5/</guid>
      <description>&lt;h2 id=&#34;module-5-strategies-and-challenges-in-ml-for-healthcare&#34;&gt;&#xA;  &lt;strong&gt;Module 5: Strategies and Challenges in ML for Healthcare&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-5-strategies-and-challenges-in-ml-for-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-common-clinical-machine-learning-challenges&#34;&gt;&#xA;  1 Introduction to Common Clinical Machine Learning Challenges&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction-to-common-clinical-machine-learning-challenges&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-why-is-deploying-machine-learning-in-healthcare-uniquely-challenging&#34;&gt;&#xA;  Q1: Why is deploying machine learning in healthcare uniquely challenging?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-why-is-deploying-machine-learning-in-healthcare-uniquely-challenging&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Healthcare presents &lt;strong&gt;complex, high-stakes environments&lt;/strong&gt; with unique constraints:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data is &lt;strong&gt;heterogeneous&lt;/strong&gt;, often unstructured and incomplete.&lt;/li&gt;&#xA;&lt;li&gt;Clinical settings are &lt;strong&gt;dynamic and contextual&lt;/strong&gt;, with human-in-the-loop decisions.&lt;/li&gt;&#xA;&lt;li&gt;Errors have &lt;strong&gt;real consequences&lt;/strong&gt;, requiring robustness and explainability.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;➡️  What specific areas of ML model development are affected by these clinical challenges?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ch6 ML and Graph Analytics</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/hands-on-healthcare-data/ch6_graph_ml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/hands-on-healthcare-data/ch6_graph_ml/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Ch6 Machine Learning &amp; Graph-Based Analytics&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;part-1-qa-summary&#34;&gt;&#xA;  Part 1: Q&amp;amp;A Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#part-1-qa-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-what-is-the-difference-between-cleaning-harmonization-and-feature-engineering&#34;&gt;&#xA;  1. What is the difference between cleaning, harmonization, and feature engineering?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-what-is-the-difference-between-cleaning-harmonization-and-feature-engineering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cleaning&lt;/strong&gt;: Removing errors or inconsistencies in the raw data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Harmonization&lt;/strong&gt;: Mapping and aligning data semantically across datasets (e.g., converting NDC to RxNorm).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Feature Engineering&lt;/strong&gt;: Transforming data to fit the needs of specific algorithms or analysis (e.g., PCA, one-hot encoding).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-why-are-graphs-more-useful-for-harmonization-than-feature-engineering&#34;&gt;&#xA;  2. Why are graphs more useful for harmonization than feature engineering?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-why-are-graphs-more-useful-for-harmonization-than-feature-engineering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Graphs help link concepts across vocabularies, terminologies, or systems.&lt;/li&gt;&#xA;&lt;li&gt;Feature engineering tends to be model-specific and harder to generalize.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-what-are-the-downsides-of-repeating-cleaningharmonization-for-each-project&#34;&gt;&#xA;  3. What are the downsides of repeating cleaning/harmonization for each project?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-what-are-the-downsides-of-repeating-cleaningharmonization-for-each-project&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Redundancy: Same steps are repeated across projects.&lt;/li&gt;&#xA;&lt;li&gt;Inefficiency: Each team member duplicates similar work.&lt;/li&gt;&#xA;&lt;li&gt;Inconsistency: No central source of truth for processed data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;4-what-is-a-feature-store-and-how-does-it-help&#34;&gt;&#xA;  4. What is a feature store and how does it help?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#4-what-is-a-feature-store-and-how-does-it-help&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A &lt;strong&gt;feature store&lt;/strong&gt; centralizes reusable, preprocessed features.&lt;/li&gt;&#xA;&lt;li&gt;Helps reduce redundancy and promotes consistency.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;5-how-do-knowledge-graphs-improve-the-pipeline&#34;&gt;&#xA;  5. How do knowledge graphs improve the pipeline?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#5-how-do-knowledge-graphs-improve-the-pipeline&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data is cleaned and harmonized once at the graph level.&lt;/li&gt;&#xA;&lt;li&gt;All downstream users can reuse the harmonized view via queries or APIs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;6-what-assumptions-are-made-when-using-a-knowledge-graph&#34;&gt;&#xA;  6. What assumptions are made when using a knowledge graph?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#6-what-assumptions-are-made-when-using-a-knowledge-graph&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Patient-level data and terminology concepts are stored in the same graph.&lt;/li&gt;&#xA;&lt;li&gt;Nodes/edges are tagged with metadata (e.g., timestamps, source).&lt;/li&gt;&#xA;&lt;li&gt;The graph is a supergraph enabling subgraph extraction.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;7-what-are-graph-embeddings-and-why-are-they-useful&#34;&gt;&#xA;  7. What are graph embeddings and why are they useful?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#7-what-are-graph-embeddings-and-why-are-they-useful&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They convert graph structures into vectors usable in ML models.&lt;/li&gt;&#xA;&lt;li&gt;Enable pattern detection, similarity analysis, and deep learning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;8-what-is-node2vec&#34;&gt;&#xA;  8. What is &lt;code&gt;node2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#8-what-is-node2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Random walk-based graph embedding technique.&lt;/li&gt;&#xA;&lt;li&gt;Uses return (p) and in-out (q) parameters to tune graph walk.&lt;/li&gt;&#xA;&lt;li&gt;Captures homophily and structural equivalence.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;9-what-is-cui2vec&#34;&gt;&#xA;  9. What is &lt;code&gt;cui2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#9-what-is-cui2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Embeds UMLS CUIs based on co-occurrence in various RWD sources.&lt;/li&gt;&#xA;&lt;li&gt;Context-aware (claims, notes, publications).&lt;/li&gt;&#xA;&lt;li&gt;Useful for understanding concept similarity.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;10-what-is-med2vec&#34;&gt;&#xA;  10. What is &lt;code&gt;med2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#10-what-is-med2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Uses temporal sequence of medical events to create visit-based embeddings.&lt;/li&gt;&#xA;&lt;li&gt;Retains longitudinal context.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;11-what-is-snomed2vec&#34;&gt;&#xA;  11. What is &lt;code&gt;snomed2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#11-what-is-snomed2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Embeds SNOMED CT concepts using hierarchical and network-based methods.&lt;/li&gt;&#xA;&lt;li&gt;Includes alternatives like metapath2vec and Poincaré embeddings.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;12-what-are-some-challenges-with-pretrained-embeddings&#34;&gt;&#xA;  12. What are some challenges with pretrained embeddings?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#12-what-are-some-challenges-with-pretrained-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Risk of overfitting to training data domain (e.g., CMS claims).&lt;/li&gt;&#xA;&lt;li&gt;May not generalize well to other populations or use cases.&lt;/li&gt;&#xA;&lt;li&gt;Introduces extra model layer to maintain and tune.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;part-2-curriculum-style-breakdown-with-why&#34;&gt;&#xA;  Part 2: Curriculum-Style Breakdown with &amp;ldquo;Why&amp;rdquo;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#part-2-curriculum-style-breakdown-with-why&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-phase-1-understand-the-motivation&#34;&gt;&#xA;  🧭 Phase 1: Understand the Motivation&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-1-understand-the-motivation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Read and distinguish between cleaning, harmonization, and feature engineering.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Clarifies each pipeline component and prevents misuse of graphs for tasks like feature engineering.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-2-explore-pipeline-challenges&#34;&gt;&#xA;  🧱 Phase 2: Explore Pipeline Challenges&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-2-explore-pipeline-challenges&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Analyze Figures 6-6 to 6-9 on pipeline repetition and inefficiency.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Understand how lack of standardization leads to duplicated efforts.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-3-learn-about-feature-stores&#34;&gt;&#xA;  🧠 Phase 3: Learn about Feature Stores&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-3-learn-about-feature-stores&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Study how feature stores centralize and reuse engineered features.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Saves time, increases reproducibility, and reduces tech debt.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-4-integrate-knowledge-graphs&#34;&gt;&#xA;  🌐 Phase 4: Integrate Knowledge Graphs&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-4-integrate-knowledge-graphs&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Understand what goes into a knowledge graph (patient data + ontologies).&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Enables one-time harmonization per data source, allowing scalable reuse.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-5-explore-graph-embedding-techniques&#34;&gt;&#xA;  🧩 Phase 5: Explore Graph Embedding Techniques&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-5-explore-graph-embedding-techniques&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Implement &lt;code&gt;node2vec&lt;/code&gt; on a small graph.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Learn homophily vs structural equivalence, key for biomedical graph reasoning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-6-biomedical-concept-embeddings&#34;&gt;&#xA;  🧬 Phase 6: Biomedical Concept Embeddings&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-6-biomedical-concept-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Compare and contrast &lt;code&gt;cui2vec&lt;/code&gt;, &lt;code&gt;med2vec&lt;/code&gt;, and &lt;code&gt;snomed2vec&lt;/code&gt;.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Appreciate how embeddings differ by data type (temporal, co-occurrence, hierarchical).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-7-real-world-concerns-with-embeddings&#34;&gt;&#xA;  ⚠️ Phase 7: Real-World Concerns with Embeddings&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-7-real-world-concerns-with-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Evaluate pretrained embeddings and consider limitations (overfitting, generalizability).&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Embeddings may look good on paper but can fail in new domains.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-8-apply-to-your-use-case&#34;&gt;&#xA;  🔁 Phase 8: Apply to Your Use Case&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-8-apply-to-your-use-case&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Pick a small real-world use case and simulate a pipeline using a knowledge graph and embedding.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Reinforces learning and identifies operational gaps in pipeline design.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Data-Centric Evaluation of ML Models</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/data-centric-evaluation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/data-centric-evaluation/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Data-Centric Evaluation of ML Models &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Instead of only asking &lt;strong&gt;how accurate&lt;/strong&gt;, we ask &lt;strong&gt;why and where does the model fail&lt;/strong&gt; — and whether the data itself causes it.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Aspect&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Model-Centric Evaluation&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Data-Centric Evaluation&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Focus&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Overall model score&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Specific weaknesses tied to data&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Metrics&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Accuracy, ROC, etc.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Slice-specific accuracy, Error analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Blind spots&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Hide rare data failures&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Detect hidden failures in data&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Error tracing&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Hard&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Directly trace errors to dirty/outlier/bias data&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Example&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&amp;ldquo;95% accurate model!&amp;rdquo;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&amp;ldquo;Fails badly on young users with rare diseases&amp;rdquo;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Mindset&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Improve model tuning&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Fix the dataset (quality, balance, coverage)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;q1-what-is-the-typical-ml-workflow-before-deployment&#34;&gt;&#xA;  Q1: What is the typical ML workflow before deployment?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-the-typical-ml-workflow-before-deployment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Collect data and define the ML task.&lt;/li&gt;&#xA;&lt;li&gt;Explore and preprocess the data.&lt;/li&gt;&#xA;&lt;li&gt;Train a straightforward model.&lt;/li&gt;&#xA;&lt;li&gt;Investigate shortcomings in the model and dataset.&lt;/li&gt;&#xA;&lt;li&gt;Improve dataset and model iteratively.&lt;/li&gt;&#xA;&lt;li&gt;Deploy the model and monitor for new issues.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q2-why-is-model-evaluation-critical&#34;&gt;&#xA;  Q2: Why is model evaluation critical?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-why-is-model-evaluation-critical&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Evaluation affects practical outcomes in real-world applications.&lt;/li&gt;&#xA;&lt;li&gt;Poor evaluation choices can lead to misleading or harmful models.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q3-what-are-examples-of-evaluation-metrics-for-classification&#34;&gt;&#xA;  Q3: What are examples of evaluation metrics for classification?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-what-are-examples-of-evaluation-metrics-for-classification&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Accuracy, balanced accuracy, precision, recall, log loss, AUROC, calibration error.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q4-what-are-some-pitfalls-in-model-evaluation&#34;&gt;&#xA;  Q4: What are some pitfalls in model evaluation?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q4-what-are-some-pitfalls-in-model-evaluation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data leakage by using non-held-out data.&lt;/li&gt;&#xA;&lt;li&gt;Misspecified metrics hiding failures in subpopulations.&lt;/li&gt;&#xA;&lt;li&gt;Validation data not representing deployment settings.&lt;/li&gt;&#xA;&lt;li&gt;Label errors.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q5-how-is-text-generation-model-evaluation-different&#34;&gt;&#xA;  Q5: How is text generation model evaluation different?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q5-how-is-text-generation-model-evaluation-different&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Human evaluations (👍👎 or Likert scales).&lt;/li&gt;&#xA;&lt;li&gt;LLM evaluations with multiple criteria.&lt;/li&gt;&#xA;&lt;li&gt;Automated metrics like ROUGE, BLEU, and Perplexity.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q6-what-is-a-data-slice&#34;&gt;&#xA;  Q6: What is a data slice?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q6-what-is-a-data-slice&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A subset of the dataset sharing a common characteristic, e.g., different sensor types, demographics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q7-why-is-it-insufficient-to-delete-sensitive-features-to-address-slice-fairness&#34;&gt;&#xA;  Q7: Why is it insufficient to delete sensitive features to address slice fairness?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q7-why-is-it-insufficient-to-delete-sensitive-features-to-address-slice-fairness&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Slice membership information may be correlated with other features.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q8-how-can-we-improve-model-performance-for-underperforming-slices&#34;&gt;&#xA;  Q8: How can we improve model performance for underperforming slices?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q8-how-can-we-improve-model-performance-for-underperforming-slices&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use a more flexible model.&lt;/li&gt;&#xA;&lt;li&gt;Over-sample the minority subgroup.&lt;/li&gt;&#xA;&lt;li&gt;Collect more data from the subgroup.&lt;/li&gt;&#xA;&lt;li&gt;Engineer new features that better capture subgroup specifics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q9-how-to-discover-underperforming-subpopulations&#34;&gt;&#xA;  Q9: How to discover underperforming subpopulations?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q9-how-to-discover-underperforming-subpopulations&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sort validation examples by loss.&lt;/li&gt;&#xA;&lt;li&gt;Cluster high-loss examples to find commonalities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q10-what-are-typical-causes-of-wrong-predictions&#34;&gt;&#xA;  Q10: What are typical causes of wrong predictions?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q10-what-are-typical-causes-of-wrong-predictions&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Incorrect labels.&lt;/li&gt;&#xA;&lt;li&gt;Examples that do not belong to any class.&lt;/li&gt;&#xA;&lt;li&gt;Outlier examples.&lt;/li&gt;&#xA;&lt;li&gt;Model type limitations.&lt;/li&gt;&#xA;&lt;li&gt;Conflicting or noisy dataset labels.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q11-what-actions-can-address-wrong-predictions&#34;&gt;&#xA;  Q11: What actions can address wrong predictions?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q11-what-actions-can-address-wrong-predictions&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Correct labels.&lt;/li&gt;&#xA;&lt;li&gt;Remove fundamentally unpredictable examples.&lt;/li&gt;&#xA;&lt;li&gt;Augment or normalize outlier examples.&lt;/li&gt;&#xA;&lt;li&gt;Fit better model architectures or do feature engineering.&lt;/li&gt;&#xA;&lt;li&gt;Enrich the dataset to distinguish overlapping classes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q12-what-is-the-concept-of-leave-one-out-influence&#34;&gt;&#xA;  Q12: What is the concept of leave-one-out influence?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q12-what-is-the-concept-of-leave-one-out-influence&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Measure the impact of omitting a datapoint on the model’s validation performance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q13-what-is-data-shapley&#34;&gt;&#xA;  Q13: What is Data Shapley?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q13-what-is-data-shapley&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A method that averages the influence of a datapoint over all subsets containing it, providing a fairer measure of its importance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q14-how-can-we-approximate-influence&#34;&gt;&#xA;  Q14: How can we approximate influence?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q14-how-can-we-approximate-influence&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Monte Carlo sampling methods.&lt;/li&gt;&#xA;&lt;li&gt;Closed-form approximations for simple models like linear regression and k-NN.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q15-why-review-influential-samples&#34;&gt;&#xA;  Q15: Why review influential samples?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q15-why-review-influential-samples&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Correcting highly influential mislabeled examples can lead to significant accuracy improvements.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;references&#34;&gt;&#xA;  References&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#references&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cook%27s_distance&#34;&gt;Cook’s Distance (Linear Regression Influence)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1702.08734&#34;&gt;Similarity Search Scaling for Big Data (Johnson et al., 2019)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ojs.aaai.org/index.php/AAAI/article/view/20591&#34;&gt;Trustworthy Data Influence Estimation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cleanlab/cleanlab&#34;&gt;Confident Learning and Cleanlab Project&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Day 5 – MLOps for Generative AI</title>
      <link>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day5_mlops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/5-day-genai-google-2025/day5_mlops/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Day 5 – MLOps for Generative AI&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-introduction&#34;&gt;&#xA;  1. Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;The rise of &lt;strong&gt;foundation models&lt;/strong&gt; and &lt;strong&gt;generative AI (gen AI)&lt;/strong&gt; has brought a paradigm shift in how we build and deploy AI systems. From selecting architectures to managing prompts and grounding outputs in real data, traditional MLOps needs adaptation.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;So how do we evolve MLOps for this new generative world?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-what-are-devops-and-mlops&#34;&gt;&#xA;  2. What Are DevOps and MLOps?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-are-devops-and-mlops&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DevOps&lt;/strong&gt;: Automation + collaboration for software delivery (CI/CD, testing, reliability)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MLOps&lt;/strong&gt;: Adds ML-specific needs:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data validation&lt;/li&gt;&#xA;&lt;li&gt;Model evaluation&lt;/li&gt;&#xA;&lt;li&gt;Monitoring&lt;/li&gt;&#xA;&lt;li&gt;Experiment tracking&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;These core principles set the stage, but gen AI has unique needs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary]  Module 6: Best Practices, Terms, and Launching Your ML Journey</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m6/</guid>
      <description>&lt;h2 id=&#34;module-6-best-practices-terms-and-launching-your-ml-journey&#34;&gt;&#xA;  &lt;strong&gt;Module 6: Best Practices, Terms, and Launching Your ML Journey&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-6-best-practices-terms-and-launching-your-ml-journey&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-clinical-utility-and-output-action-pairing&#34;&gt;&#xA;  1 Clinical Utility and Output Action Pairing&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-clinical-utility-and-output-action-pairing&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-is-clinical-utility-and-why-is-it-important-in-ml&#34;&gt;&#xA;  Q1: What is clinical utility and why is it important in ML?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-clinical-utility-and-why-is-it-important-in-ml&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Clinical utility refers to the &lt;strong&gt;real-world usefulness&lt;/strong&gt; of a model’s predictions:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A model must &lt;strong&gt;enable action&lt;/strong&gt; that improves outcomes.&lt;/li&gt;&#xA;&lt;li&gt;Predictions that can&amp;rsquo;t lead to interventions or decisions have limited utility.&lt;/li&gt;&#xA;&lt;li&gt;This bridges the gap between technical performance and clinical relevance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;➡️  How can we ensure predictions are actually actionable?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Curation and LLMs</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/data-curation-llms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/data-curation-llms/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Data Curation and LLMs &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-is-the-background-of-llms-discussed&#34;&gt;&#xA;  Q1: What is the background of LLMs discussed?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-the-background-of-llms-discussed&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMs like ChatGPT, GPT-4, and Llama are sequence models trained to predict the next token.&lt;/li&gt;&#xA;&lt;li&gt;They use unsupervised pre-training on massive internet-scale corpora and can solve various NLP tasks.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q2-what-are-the-applications-of-llms-discussed&#34;&gt;&#xA;  Q2: What are the applications of LLMs discussed?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-are-the-applications-of-llms-discussed&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Zero-shot prompting&lt;/li&gt;&#xA;&lt;li&gt;Few-shot prompting&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q3-what-is-the-focus-of-this-lecture&#34;&gt;&#xA;  Q3: What is the focus of this lecture?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-what-is-the-focus-of-this-lecture&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Using LLMs for data curation&lt;/li&gt;&#xA;&lt;li&gt;Evaluating LLM output data&lt;/li&gt;&#xA;&lt;li&gt;Curation for LLM pre-training and application fine-tuning&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q4-how-are-llms-used-for-data-curation&#34;&gt;&#xA;  Q4: How are LLMs used for data curation?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q4-how-are-llms-used-for-data-curation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They act as powerful, flexible, and computationally inexpensive reasoning engines for text data curation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q5-how-was-pii-detection-handled-traditionally-vs-with-llms&#34;&gt;&#xA;  Q5: How was PII detection handled traditionally vs with LLMs?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q5-how-was-pii-detection-handled-traditionally-vs-with-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Traditional: Custom regex rules.&lt;/li&gt;&#xA;&lt;li&gt;With LLMs: Zero-shot prompting to detect a wider range of PII without needing extensive rule-writing.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q6-how-can-grammar-checking-be-improved-with-llms&#34;&gt;&#xA;  Q6: How can grammar checking be improved with LLMs?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q6-how-can-grammar-checking-be-improved-with-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Traditional: Rule-based systems like LanguageTool.&lt;/li&gt;&#xA;&lt;li&gt;LLM-based: Fine-tuning LLMs on curated grammatical acceptability datasets like CoLA.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q7-what-is-a-major-challenge-in-working-with-llm-outputs&#34;&gt;&#xA;  Q7: What is a major challenge in working with LLM outputs?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q7-what-is-a-major-challenge-in-working-with-llm-outputs&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Hallucinations, where LLMs produce confidently incorrect information.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q8-how-can-we-evaluate-llm-outputs-more-reliably&#34;&gt;&#xA;  Q8: How can we evaluate LLM outputs more reliably?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q8-how-can-we-evaluate-llm-outputs-more-reliably&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use a stronger LLM (e.g., GPT-4) to judge the outputs of weaker LLMs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q9-what-evidence-supports-llm-based-evaluation&#34;&gt;&#xA;  Q9: What evidence supports LLM-based evaluation?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q9-what-evidence-supports-llm-based-evaluation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AlpaGasus fine-tuning project showed better results by curating higher-quality data points evaluated by GPT-3.5 and GPT-4.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q10-what-is-the-challenge-of-using-llms-to-evaluate-other-llms&#34;&gt;&#xA;  Q10: What is the challenge of using LLMs to evaluate other LLMs?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q10-what-is-the-challenge-of-using-llms-to-evaluate-other-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It risks circular evaluation (turtles all the way down) if the same LLMs are involved in both generation and evaluation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q11-what-method-helps-with-llm-uncertainty-quantification&#34;&gt;&#xA;  Q11: What method helps with LLM uncertainty quantification?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q11-what-method-helps-with-llm-uncertainty-quantification&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Natural Language Inference (NLI)-based techniques that check for answer contradictions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q12-what-are-the-key-stages-of-data-curation-for-llm-pre-training&#34;&gt;&#xA;  Q12: What are the key stages of data curation for LLM pre-training?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q12-what-are-the-key-stages-of-data-curation-for-llm-pre-training&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Focus on corpus quality because errors are difficult to &amp;ldquo;un-learn.&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;Use supervised fine-tuning and reinforcement learning from human feedback.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q13-how-does-data-curation-differ-for-llm-applications&#34;&gt;&#xA;  Q13: How does data curation differ for LLM applications?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q13-how-does-data-curation-differ-for-llm-applications&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Zero-shot prompting&lt;/li&gt;&#xA;&lt;li&gt;Few-shot prompting&lt;/li&gt;&#xA;&lt;li&gt;Retrieval-augmented generation&lt;/li&gt;&#xA;&lt;li&gt;Supervised fine-tuning&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q14-why-is-fine-tuning-important-for-llm-applications&#34;&gt;&#xA;  Q14: Why is fine-tuning important for LLM applications?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q14-why-is-fine-tuning-important-for-llm-applications&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fine-tuning provides the best task-specific performance.&lt;/li&gt;&#xA;&lt;li&gt;It enables training smaller models to match large model performance through synthetic data generation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q15-how-is-synthetic-data-curated-for-llm-fine-tuning&#34;&gt;&#xA;  Q15: How is synthetic data curated for LLM fine-tuning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q15-how-is-synthetic-data-curated-for-llm-fine-tuning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Generate synthetic data using a powerful LLM.&lt;/li&gt;&#xA;&lt;li&gt;Use uncertainty quantification to retain only high-confidence examples.&lt;/li&gt;&#xA;&lt;li&gt;Train classifiers to filter out unrealistic synthetic data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q16-what-is-the-future-trend-in-data-curation-for-llms&#34;&gt;&#xA;  Q16: What is the future trend in data curation for LLMs?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q16-what-is-the-future-trend-in-data-curation-for-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Growth of powerful multi-modal LLMs and new tools like CleanVision and GPT-4 to automate and improve data quality.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;references&#34;&gt;&#xA;  References&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#references&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://twitter.com/karpathy/status/1654892810590650376&#34;&gt;Karpathy on LLM prompting&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/LeapBeyond/scrubadub&#34;&gt;Scrubadub for regex-based PII detection&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/languagetool-org/languagetool&#34;&gt;LanguageTool grammar checker&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nyu-mll.github.io/CoLA/&#34;&gt;CoLA dataset&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2307.08701.pdf&#34;&gt;AlpaGasus paper&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2308.16175.pdf&#34;&gt;Trustworthy Language Models (TLM)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.05463&#34;&gt;Textbooks Are All You Need (Li et al., 2023)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca project&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cleanlab/cleanvision&#34;&gt;CleanVision project&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>[Summary] Module 7: Foundation Models</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m7/</guid>
      <description>&lt;h2 id=&#34;module-7-foundation-models&#34;&gt;&#xA;  &lt;strong&gt;Module 7: Foundation Models&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-7-foundation-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-foundation-models&#34;&gt;&#xA;  1 Introduction to Foundation Models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction-to-foundation-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-are-foundation-models-and-why-are-they-significant&#34;&gt;&#xA;  Q1: What are foundation models and why are they significant?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-are-foundation-models-and-why-are-they-significant&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Foundation models are &lt;strong&gt;large-scale models&lt;/strong&gt; trained on massive datasets:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They can be adapted for many downstream tasks with minimal fine-tuning.&lt;/li&gt;&#xA;&lt;li&gt;Examples include models like &lt;strong&gt;BERT, GPT, and CLIP&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Represent a shift from building task-specific models to training one model for many uses.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;➡️  Why have foundation models become so prominent recently?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Growing or Compressing Datasets</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/growing-or-compressing-datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/growing-or-compressing-datasets/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Growing or Compressing Datasets &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-is-the-main-focus-of-this-lecture&#34;&gt;&#xA;  Q1: What is the main focus of this lecture?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-the-main-focus-of-this-lecture&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Techniques to carefully select examples for labeling to reduce the burden in ML systems.&lt;/li&gt;&#xA;&lt;li&gt;Growing datasets via active learning and compressing datasets via core-set selection.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q2-what-is-active-learning&#34;&gt;&#xA;  Q2: What is active learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-is-active-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A method to intelligently select the most informative examples to label next, maximizing model improvement with fewer labeled samples.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q3-how-does-pool-based-active-learning-work&#34;&gt;&#xA;  Q3: How does pool-based active learning work?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-how-does-pool-based-active-learning-work&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Start with a pool of unlabeled examples.&lt;/li&gt;&#xA;&lt;li&gt;At each round, score examples using an acquisition function (e.g., entropy of predicted probabilities).&lt;/li&gt;&#xA;&lt;li&gt;Select and label top examples.&lt;/li&gt;&#xA;&lt;li&gt;Retrain the model with newly labeled data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q4-what-is-a-common-acquisition-function-used-in-active-learning&#34;&gt;&#xA;  Q4: What is a common acquisition function used in active learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q4-what-is-a-common-acquisition-function-used-in-active-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Entropy of the predicted class probabilities, encouraging labeling of uncertain examples.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q5-how-does-active-learning-compare-to-passive-learning&#34;&gt;&#xA;  Q5: How does active learning compare to passive learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q5-how-does-active-learning-compare-to-passive-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Active learning exponentially improves data efficiency compared to random/passive sampling.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q6-what-practical-challenges-does-active-learning-face&#34;&gt;&#xA;  Q6: What practical challenges does active learning face?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q6-what-practical-challenges-does-active-learning-face&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;High computational costs with large models and datasets.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q7-how-can-active-learning-be-made-more-practical&#34;&gt;&#xA;  Q7: How can active learning be made more practical?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q7-how-can-active-learning-be-made-more-practical&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Batch active learning with diversity selection.&lt;/li&gt;&#xA;&lt;li&gt;Efficient candidate selection using methods like SEALS to reduce search space.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q8-what-is-seals&#34;&gt;&#xA;  Q8: What is SEALS?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q8-what-is-seals&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Similarity Search for Efficient Active Learning and Search of Rare Concepts.&lt;/li&gt;&#xA;&lt;li&gt;Uses nearest neighbor search in embedding space to limit active learning candidate pool.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q9-what-is-core-set-selection&#34;&gt;&#xA;  Q9: What is core-set selection?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q9-what-is-core-set-selection&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Choosing a small representative subset of a large labeled dataset that preserves model performance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q10-why-is-core-set-selection-important&#34;&gt;&#xA;  Q10: Why is core-set selection important?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q10-why-is-core-set-selection-important&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When we have massive datasets, it reduces computational, time, and energy costs without sacrificing accuracy.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q11-what-methods-help-with-core-set-selection&#34;&gt;&#xA;  Q11: What methods help with core-set selection?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q11-what-methods-help-with-core-set-selection&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Greedy k-centers approach.&lt;/li&gt;&#xA;&lt;li&gt;Selection via Proxy: using smaller proxy models to guide subset selection.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q12-how-does-selection-via-proxy-work&#34;&gt;&#xA;  Q12: How does Selection via Proxy work?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q12-how-does-selection-via-proxy-work&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Train a lightweight model (proxy) on the full data.&lt;/li&gt;&#xA;&lt;li&gt;Use it to select a subset for training a larger model, speeding up training significantly.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q13-what-are-key-takeaways-about-dataset-growth-and-compression&#34;&gt;&#xA;  Q13: What are key takeaways about dataset growth and compression?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q13-what-are-key-takeaways-about-dataset-growth-and-compression&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Active learning enables data-efficient labeling for growing datasets.&lt;/li&gt;&#xA;&lt;li&gt;Core-set selection enables training efficiency for already large datasets.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;active-learning-vs-confident-learning&#34;&gt;&#xA;  Active Learning vs. Confident Learning&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#active-learning-vs-confident-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Category&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Active Learning&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Confident Learning&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Main Goal&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Select the most informative examples to label next&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Find mislabeled examples in existing labeled data&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;When Used&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;During dataset growth (annotation phase)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;After labels exist (cleaning phase)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Data State&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Partially labeled data pool&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Fully labeled (but noisy) dataset&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Model Uncertainty Usage&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Samples highest-uncertainty examples for human labeling&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Detects label inconsistency via confidence estimation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Human Role&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Label new examples&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Review and correct suspicious labels&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Output&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;New labels added to dataset&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;List of potential label errors to fix&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Typical Workflow&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Train model → Select uncertain points → Human annotates → Expand dataset&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Train model → Identify inconsistent labels → Human verifies/corrects → Clean dataset&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Common Technique&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Uncertainty sampling&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Confidence-based error detection&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Libraries/Tools&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;a href=&#34;https://modal-python.readthedocs.io/en/latest/&#34;&gt;modAL&lt;/a&gt;, &lt;a href=&#34;https://alipy.readthedocs.io/en/latest/&#34;&gt;ALiPy&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;a href=&#34;https://github.com/cleanlab/cleanlab&#34;&gt;cleanlab&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Philosophy&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Proactively grow data wisely&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Reactively audit and clean existing data&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Typical Question&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;em&gt;&amp;ldquo;What should I label next?&amp;rdquo;&lt;/em&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;em&gt;&amp;ldquo;Which labels are probably wrong?&amp;rdquo;&lt;/em&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;End Goal&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Smarter, faster data acquisition&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Higher quality existing labels&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Example Scenario&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Medical image AI needing efficient expert labeling&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Noisy crowd-sourced labeled text needing cleaning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Key Distillation&lt;/p&gt;</description>
    </item>
    <item>
      <title>Interpretability in Data-Centric ML</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/interpretability-data-centric-ml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/interpretability-data-centric-ml/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Interpretability in Data-Centric ML &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-why-do-we-need-interpretable-machine-learning&#34;&gt;&#xA;  Q1: Why do we need interpretable machine learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-why-do-we-need-interpretable-machine-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For debugging and validation of models.&lt;/li&gt;&#xA;&lt;li&gt;To allow human review and oversight of decisions.&lt;/li&gt;&#xA;&lt;li&gt;To improve usability by aligning models with human intuition, past experience, and values.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q2-when-is-interpretability-particularly-important&#34;&gt;&#xA;  Q2: When is interpretability particularly important?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-when-is-interpretability-particularly-important&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When the problem formulation is incomplete.&lt;/li&gt;&#xA;&lt;li&gt;When the model&amp;rsquo;s predictions have associated risks.&lt;/li&gt;&#xA;&lt;li&gt;When humans are involved in the decision-making loop.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q3-what-are-interpretable-features&#34;&gt;&#xA;  Q3: What are interpretable features?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-what-are-interpretable-features&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Features that are most useful, understandable, and meaningful to the user.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q4-how-can-interpretable-features-help-performance&#34;&gt;&#xA;  Q4: How can interpretable features help performance?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q4-how-can-interpretable-features-help-performance&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Lead to more efficient training.&lt;/li&gt;&#xA;&lt;li&gt;Improve model generalization.&lt;/li&gt;&#xA;&lt;li&gt;Reduce vulnerability to adversarial examples.&lt;/li&gt;&#xA;&lt;li&gt;The perceived interpretability-performance tradeoff is mostly a myth.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q5-what-qualities-make-features-interpretable&#34;&gt;&#xA;  Q5: What qualities make features interpretable?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q5-what-qualities-make-features-interpretable&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Readability&lt;/li&gt;&#xA;&lt;li&gt;Understandability&lt;/li&gt;&#xA;&lt;li&gt;Relevance&lt;/li&gt;&#xA;&lt;li&gt;Abstraction when necessary&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q6-how-do-we-get-interpretable-features&#34;&gt;&#xA;  Q6: How do we get interpretable features?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q6-how-do-we-get-interpretable-features&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Involving users directly in the feature design process.&lt;/li&gt;&#xA;&lt;li&gt;Using interpretable feature transformations.&lt;/li&gt;&#xA;&lt;li&gt;Generating new interpretable features through crowd-sourcing and algorithms.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q7-what-are-examples-of-methods-for-interpretable-feature-creation&#34;&gt;&#xA;  Q7: What are examples of methods for interpretable feature creation?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q7-what-are-examples-of-methods-for-interpretable-feature-creation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Collaborative feature engineering with domain experts.&lt;/li&gt;&#xA;&lt;li&gt;Flock: clustering crowd-generated feature descriptions.&lt;/li&gt;&#xA;&lt;li&gt;Ballet: allowing feature engineering with simple feedback loops.&lt;/li&gt;&#xA;&lt;li&gt;Pyreal: structured feature transformations for explanations.&lt;/li&gt;&#xA;&lt;li&gt;Mind the Gap Model (MGM): groups features using AND/OR logical structures.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q8-what-was-observed-in-the-child-welfare-case-study&#34;&gt;&#xA;  Q8: What was observed in the Child Welfare case study?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q8-what-was-observed-in-the-child-welfare-case-study&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Confusing or irrelevant features can hinder usability and trust.&lt;/li&gt;&#xA;&lt;li&gt;Clear, meaningful features helped screeners better interpret model recommendations.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q9-what-is-the-role-of-explanation-algorithms-in-interpretability&#34;&gt;&#xA;  Q9: What is the role of explanation algorithms in interpretability?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q9-what-is-the-role-of-explanation-algorithms-in-interpretability&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They help diagnose flawed features or data by revealing what the model actually uses.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q10-what-are-the-final-conclusions-about-interpretable-features&#34;&gt;&#xA;  Q10: What are the final conclusions about interpretable features?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q10-what-are-the-final-conclusions-about-interpretable-features&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ML models are only as interpretable as their features.&lt;/li&gt;&#xA;&lt;li&gt;Interpretable features are central for transparent, human-centered ML.&lt;/li&gt;&#xA;&lt;li&gt;Effective feature engineering must involve human collaboration, thoughtful transformations, and systematic generation methods.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;references&#34;&gt;&#xA;  References&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#references&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://doi.org/10.1109/TVCG.2021.3114864&#34;&gt;Sibyl: Challenges of ML in Child Welfare (Zytek et al., 2021)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.nature.com/articles/s42256-019-0048-x&#34;&gt;Stop Explaining Black-Box Models (Rudin, 2019)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1905.02175&#34;&gt;Adversarial Examples Are Not Bugs (Ilyas et al., 2019)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/2675133.2675242&#34;&gt;Flock: Crowd-Machine Learning Classifiers (Cheng &amp;amp; Bernstein, 2015)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/3479503&#34;&gt;Ballet: Collaborative Feature Engineering (Smith et al., 2021)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dtail.gitbook.io/pyreal/&#34;&gt;Pyreal Project&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://papers.nips.cc/paper_files/paper/2015/hash/89d217d180f6b3b732459e4fe6b63c99-Abstract.html&#34;&gt;Mind the Gap Model (Kim et al., 2015)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Encoding Human Priors</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/encoding-human-priors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/encoding-human-priors/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Encoding Human Priors – Data Augmentation and Prompt Engineering &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-is-the-main-focus-of-this-lecture&#34;&gt;&#xA;  Q1: What is the main focus of this lecture?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-the-main-focus-of-this-lecture&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How to &lt;strong&gt;encode human priors&lt;/strong&gt; into machine learning through:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Training data augmentation&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Prompt engineering at test time&lt;/strong&gt; (especially for LLMs).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q2-why-do-ml-models-need-human-priors&#34;&gt;&#xA;  Q2: Why do ML models need human priors?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-why-do-ml-models-need-human-priors&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ML models often &lt;strong&gt;fail in simple ways&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;They lack &lt;strong&gt;common sense&lt;/strong&gt; (e.g., failing to recognize a rotated dog image).&lt;/li&gt;&#xA;&lt;li&gt;Human priors &lt;strong&gt;capture invariances&lt;/strong&gt; and domain knowledge that models don&amp;rsquo;t inherently learn.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q3-what-is-data-augmentation-and-why-is-it-important&#34;&gt;&#xA;  Q3: What is data augmentation and why is it important?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-what-is-data-augmentation-and-why-is-it-important&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data augmentation&lt;/strong&gt; creates new training examples by applying transformations (e.g., rotation, flipping).&lt;/li&gt;&#xA;&lt;li&gt;Helps address:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Overfitting&lt;/strong&gt; (memorization)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Underfitting&lt;/strong&gt; (lack of data)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Class imbalance&lt;/strong&gt; or &lt;strong&gt;biased datasets&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Saves time and cost, especially when labeled data is expensive (e.g., in healthcare).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q4-what-are-examples-of-data-augmentation-techniques&#34;&gt;&#xA;  Q4: What are examples of data augmentation techniques?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q4-what-are-examples-of-data-augmentation-techniques&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Simple methods&lt;/strong&gt;: Rotation, flipping.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Advanced methods&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Mixup&lt;/strong&gt;: Blending images and labels (e.g., 60% cat + 40% dog).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Synthetic generation&lt;/strong&gt;: Using DALL-E, Stable Diffusion to generate new data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Simulation-to-real transfer&lt;/strong&gt;: e.g., Google&amp;rsquo;s RetinaGAN for robotics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Text augmentation&lt;/strong&gt;: &lt;strong&gt;Back-translation&lt;/strong&gt; (English → French → English) to generate paraphrases.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q5-what-is-prompt-engineering&#34;&gt;&#xA;  Q5: What is prompt engineering?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q5-what-is-prompt-engineering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Prompt engineering&lt;/strong&gt; manipulates inputs to LLMs &lt;strong&gt;at test time&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Example: Instead of “Write a letter of recommendation,” prompt with “Write a letter for a student who got into MIT” to get higher-quality output.&lt;/li&gt;&#xA;&lt;li&gt;Leverages the &lt;strong&gt;language interface&lt;/strong&gt; humans naturally use.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q6-why-does-prompt-engineering-work-especially-well-for-llms&#34;&gt;&#xA;  Q6: Why does prompt engineering work especially well for LLMs?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q6-why-does-prompt-engineering-work-especially-well-for-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMs are trained on massive &lt;strong&gt;language datasets&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Humans can easily &lt;strong&gt;adapt prompts&lt;/strong&gt; to guide the model without retraining it.&lt;/li&gt;&#xA;&lt;li&gt;Providing &lt;strong&gt;context and examples&lt;/strong&gt; (&amp;ldquo;few-shot prompting&amp;rdquo;) improves results.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q7-how-are-gpt-3-and-chatgpt-different-in-handling-prompts&#34;&gt;&#xA;  Q7: How are GPT-3 and ChatGPT different in handling prompts?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q7-how-are-gpt-3-and-chatgpt-different-in-handling-prompts&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;GPT-3&lt;/strong&gt;: Predicts next token, assumes user might be creating forms/questions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;ChatGPT&lt;/strong&gt;: Trained for &lt;strong&gt;dialogue and commands&lt;/strong&gt;, better at &lt;strong&gt;instruction-following&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q8-what-are-best-practices-in-prompt-engineering&#34;&gt;&#xA;  Q8: What are best practices in prompt engineering?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q8-what-are-best-practices-in-prompt-engineering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Add &lt;strong&gt;examples&lt;/strong&gt; (&amp;ldquo;few-shot&amp;rdquo;) to define task behavior.&lt;/li&gt;&#xA;&lt;li&gt;Build &lt;strong&gt;context templates&lt;/strong&gt; for reusability.&lt;/li&gt;&#xA;&lt;li&gt;Iteratively &lt;strong&gt;tweak prompts&lt;/strong&gt; to observe effects on output.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q9-how-does-data-augmentation-vs-prompt-engineering-differ&#34;&gt;&#xA;  Q9: How does data augmentation vs. prompt engineering differ?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q9-how-does-data-augmentation-vs-prompt-engineering-differ&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Aspect&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Data Augmentation&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Prompt Engineering&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;When applied&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Before training&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;At test time&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;What is changed&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Training dataset&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Input prompt&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Goal&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Teach model invariances&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Guide model behavior dynamically&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Typical models&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Any ML models&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Mainly LLMs (e.g., GPT family)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;q10-final-takeaway&#34;&gt;&#xA;  Q10: Final Takeaway&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q10-final-takeaway&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Encoding human priors via data&lt;/strong&gt; (training-time or test-time) dramatically improves model robustness.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data is the bridge&lt;/strong&gt; to insert human knowledge into ML systems effectively.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;references&#34;&gt;&#xA;  References&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#references&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dcai.csail.mit.edu/2023/human-priors/human-priors.pdf&#34;&gt;Lecture Slides PDF&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.09412&#34;&gt;Mixup Paper (Zhang et al., 2017)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2002.02917&#34;&gt;Mobius Transformations (Zhou et al., 2020)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.03148&#34;&gt;RetinaGAN (Ho et al., 2020)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.14165&#34;&gt;GPT-3 Paper&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://openai.com/index/dall-e-2/&#34;&gt;DALL-E&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stability.ai/blog/stable-diffusion-public-release&#34;&gt;Stable Diffusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/dcai-course/dcai-lab/blob/master/prompt_engineering/Lab_Prompt_Engineering.ipynb&#34;&gt;Lab assignment: Prompt Engineering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Data Privacy and Security in ML</title>
      <link>https://imipark.github.io/ai-workflows/data/data-centric-ai/data-privacy-security/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/data/data-centric-ai/data-privacy-security/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Data Privacy and Security in ML &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-why-is-data-privacy-and-security-important-in-ml-models&#34;&gt;&#xA;  Q1: Why is data privacy and security important in ML models?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-why-is-data-privacy-and-security-important-in-ml-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ML models often leak information about their training data.&lt;/li&gt;&#xA;&lt;li&gt;Public models can reveal sensitive data either directly or through inference attacks.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q2-what-types-of-attacks-can-compromise-ml-models&#34;&gt;&#xA;  Q2: What types of attacks can compromise ML models?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-types-of-attacks-can-compromise-ml-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Membership inference attacks: Determine if a datapoint was part of the training set.&lt;/li&gt;&#xA;&lt;li&gt;Data extraction attacks: Extract parts of the training data from the model.&lt;/li&gt;&#xA;&lt;li&gt;Other attacks include adversarial examples, data poisoning, model inversion, model extraction, and prompt injection.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q3-what-are-security-goals-and-threat-models&#34;&gt;&#xA;  Q3: What are security goals and threat models?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-what-are-security-goals-and-threat-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A security goal defines what must or must not happen.&lt;/li&gt;&#xA;&lt;li&gt;A threat model defines the adversary’s capabilities and limitations.&lt;/li&gt;&#xA;&lt;li&gt;Both are necessary to properly reason about a system’s security.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q4-how-does-threat-modeling-apply-to-ml-apis&#34;&gt;&#xA;  Q4: How does threat modeling apply to ML APIs?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q4-how-does-threat-modeling-apply-to-ml-apis&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Example: Google Vision API must prevent model extraction even when adversaries can query with arbitrary images.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q5-what-is-a-membership-inference-attack&#34;&gt;&#xA;  Q5: What is a membership inference attack?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q5-what-is-a-membership-inference-attack&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;An attack that identifies whether a specific data point was in the model’s training set.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q6-how-does-shadow-training-help-in-membership-inference&#34;&gt;&#xA;  Q6: How does shadow training help in membership inference?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q6-how-does-shadow-training-help-in-membership-inference&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Shadow models simulate the target model’s behavior on known datasets.&lt;/li&gt;&#xA;&lt;li&gt;An attack model is trained to classify whether a data point was part of the training set based on model outputs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q7-what-are-simple-metric-based-membership-inference-attacks&#34;&gt;&#xA;  Q7: What are simple metric-based membership inference attacks?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q7-what-are-simple-metric-based-membership-inference-attacks&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Prediction correctness: whether model predicts correctly.&lt;/li&gt;&#xA;&lt;li&gt;Prediction loss: whether the model loss is low.&lt;/li&gt;&#xA;&lt;li&gt;Prediction confidence: model’s maximum output probability.&lt;/li&gt;&#xA;&lt;li&gt;Prediction entropy: uncertainty of model’s output distribution.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q8-what-is-a-data-extraction-attack&#34;&gt;&#xA;  Q8: What is a data extraction attack?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q8-what-is-a-data-extraction-attack&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Directly extracting memorized sequences or examples from a model, especially from large LLMs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q9-how-is-perplexity-used-in-data-extraction&#34;&gt;&#xA;  Q9: How is perplexity used in data extraction?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q9-how-is-perplexity-used-in-data-extraction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Lower perplexity on sequences indicates that they were likely memorized during training.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q10-what-are-empirical-defenses-against-privacy-attacks&#34;&gt;&#xA;  Q10: What are empirical defenses against privacy attacks?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q10-what-are-empirical-defenses-against-privacy-attacks&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Limiting outputs (top-k predictions, quantization).&lt;/li&gt;&#xA;&lt;li&gt;Adding noise to predictions.&lt;/li&gt;&#xA;&lt;li&gt;Changing training methods (e.g., regularization).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q11-why-is-empirical-defense-evaluation-hard&#34;&gt;&#xA;  Q11: Why is empirical defense evaluation hard?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q11-why-is-empirical-defense-evaluation-hard&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Following Kerckhoffs’s principle, defenses must work even when attackers know the defense.&lt;/li&gt;&#xA;&lt;li&gt;Security is a cat-and-mouse game between defenders and attackers.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q12-what-is-differential-privacy-dp&#34;&gt;&#xA;  Q12: What is differential privacy (DP)?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q12-what-is-differential-privacy-dp&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A formal, mathematical definition of privacy that limits how much an algorithm’s output depends on any single input.&lt;/li&gt;&#xA;&lt;li&gt;Algorithms like DP-SGD make models less dependent on individual datapoints.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q13-what-challenges-exist-with-using-differential-privacy&#34;&gt;&#xA;  Q13: What challenges exist with using differential privacy?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q13-what-challenges-exist-with-using-differential-privacy&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It introduces parameters (ε, δ) that are difficult to set.&lt;/li&gt;&#xA;&lt;li&gt;Strong privacy may come at the cost of degraded model performance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q14-what-resources-were-recommended&#34;&gt;&#xA;  Q14: What resources were recommended?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q14-what-resources-were-recommended&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Surveys on membership inference attacks and privacy attacks.&lt;/li&gt;&#xA;&lt;li&gt;Awesome ML privacy attacks collection.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q15-what-was-the-lab-assignment&#34;&gt;&#xA;  Q15: What was the lab assignment?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q15-what-was-the-lab-assignment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Implement a membership inference attack against a black-box model.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;heading&#34;&gt;&#xA;  &#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2107.03374&#34;&gt;OpenAI Codex paper&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2022/Sep/12/prompt-injection/&#34;&gt;Prompt Injection&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.07853&#34;&gt;Membership Inference Survey&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.07646&#34;&gt;Privacy Attacks in ML Survey&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/stratosphereips/awesome-ml-privacy-attacks&#34;&gt;Awesome ML Privacy Attacks Repository&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://iacr.org/archive/tcc2006/38760266/38760266.pdf&#34;&gt;Differential Privacy (Dwork et al., 2006)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1607.00133&#34;&gt;DP-SGD (Abadi et al., 2016)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/dcai-course/dcai-lab/blob/master/membership_inference/Lab%20-%20Membership%20Inference.ipynb&#34;&gt;Membership Inference Lab Notebook&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>ChatGPT Images 2026 - Art School, InkWork</title>
      <link>https://imipark.github.io/posts/chatgpt_image_2026/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/posts/chatgpt_image_2026/</guid>
      <description>&lt;img src=&#34;https://imipark.github.io/images/ipark-art.png&#34; width=&#34;200&#34; /&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/ipark-inkwork.png&#34; width=&#34;200&#34; /&gt;</description>
    </item>
    <item>
      <title>Ghibli Art Style Snapshots (ChatGPT 2025)</title>
      <link>https://imipark.github.io/posts/ghibli_style_snapshots/</link>
      <pubDate>Tue, 08 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/posts/ghibli_style_snapshots/</guid>
      <description>&lt;img src=&#34;https://imipark.github.io/images/ghibli-ipark0.png&#34; width=&#34;200&#34; /&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/ghibli-ipark1.png&#34; width=&#34;200&#34; /&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/ghibli-ipark2.png&#34; width=&#34;200&#34; /&gt;</description>
    </item>
    <item>
      <title>The AI Engineer Path – Scrimba</title>
      <link>https://imipark.github.io/posts/ai_engineer_path_toc/</link>
      <pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/posts/ai_engineer_path_toc/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.coursera.org/specializations/ai-engineering#courses&#34;&gt;https://www.coursera.org/specializations/ai-engineering#courses&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;intro-to-ai-engineering-104-min&#34;&gt;&#xA;  Intro to AI Engineering (104 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#intro-to-ai-engineering-104-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Welcome to The AI Engineer Path!&lt;/li&gt;&#xA;&lt;li&gt;AI Engineering basics&lt;/li&gt;&#xA;&lt;li&gt;The code so far&lt;/li&gt;&#xA;&lt;li&gt;Polygon API sign-up &amp;amp; key&lt;/li&gt;&#xA;&lt;li&gt;Get an OpenAI API Key&lt;/li&gt;&#xA;&lt;li&gt;Overview of how the API works&lt;/li&gt;&#xA;&lt;li&gt;An API call: OpenAI dependency&lt;/li&gt;&#xA;&lt;li&gt;An API call: Instance and model&lt;/li&gt;&#xA;&lt;li&gt;An API call: The messages array&lt;/li&gt;&#xA;&lt;li&gt;A quick word about models&lt;/li&gt;&#xA;&lt;li&gt;Prompt Engineering and a challenge&lt;/li&gt;&#xA;&lt;li&gt;Adding AI to the App&lt;/li&gt;&#xA;&lt;li&gt;Tokens&lt;/li&gt;&#xA;&lt;li&gt;The OpenAI Playground&lt;/li&gt;&#xA;&lt;li&gt;Temperature&lt;/li&gt;&#xA;&lt;li&gt;The &amp;ldquo;Few Shot&amp;rdquo; Approach&lt;/li&gt;&#xA;&lt;li&gt;Adding Examples&lt;/li&gt;&#xA;&lt;li&gt;Stop Sequence&lt;/li&gt;&#xA;&lt;li&gt;Frequency and Presence Penalties&lt;/li&gt;&#xA;&lt;li&gt;Fine-tuning&lt;/li&gt;&#xA;&lt;li&gt;Creating Images with the DALL·E 3 API&lt;/li&gt;&#xA;&lt;li&gt;Intro to AI Safety&lt;/li&gt;&#xA;&lt;li&gt;Safety Best Practices&lt;/li&gt;&#xA;&lt;li&gt;Solo Project - PollyGlot&lt;/li&gt;&#xA;&lt;li&gt;You made it!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;deployment-50-min&#34;&gt;&#xA;  Deployment (50 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#deployment-50-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Learn secure &amp;amp; robust deployment strategies&lt;/li&gt;&#xA;&lt;li&gt;Create a Cloudflare worker&lt;/li&gt;&#xA;&lt;li&gt;Connect your worker to OpenAI&lt;/li&gt;&#xA;&lt;li&gt;Update client side data fetching&lt;/li&gt;&#xA;&lt;li&gt;Handle CORS and preflight requests&lt;/li&gt;&#xA;&lt;li&gt;OpenAI API requests &amp;amp; responses&lt;/li&gt;&#xA;&lt;li&gt;Create an AI Gateway&lt;/li&gt;&#xA;&lt;li&gt;Error handling&lt;/li&gt;&#xA;&lt;li&gt;Create &amp;amp; deploy the Polygon API worker&lt;/li&gt;&#xA;&lt;li&gt;Fetch the stock data&lt;/li&gt;&#xA;&lt;li&gt;Download files and push to GitHub&lt;/li&gt;&#xA;&lt;li&gt;Deploy your site with Cloudflare Pages&lt;/li&gt;&#xA;&lt;li&gt;Custom domains with Cloudflare&lt;/li&gt;&#xA;&lt;li&gt;Recap &amp;amp; next steps&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;open-source-models-33-min&#34;&gt;&#xA;  Open-source Models (33 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#open-source-models-33-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Open source vs closed source&lt;/li&gt;&#xA;&lt;li&gt;Intro To HuggingFace.js Inference&lt;/li&gt;&#xA;&lt;li&gt;Text To Speech With HuggingFace.js Inference&lt;/li&gt;&#xA;&lt;li&gt;Transforming Images with HuggingFace.js Inference&lt;/li&gt;&#xA;&lt;li&gt;AI Models In The Browser With Transformers.js&lt;/li&gt;&#xA;&lt;li&gt;Download and Run AI Models on Your Computer with Ollama&lt;/li&gt;&#xA;&lt;li&gt;Section Recap&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;embeddings-and-vector-databases-94-min&#34;&gt;&#xA;  Embeddings and Vector Databases (94 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#embeddings-and-vector-databases-94-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Your next big step in AI engineering&lt;/li&gt;&#xA;&lt;li&gt;What are embeddings?&lt;/li&gt;&#xA;&lt;li&gt;Set up environment variables&lt;/li&gt;&#xA;&lt;li&gt;Create an embedding&lt;/li&gt;&#xA;&lt;li&gt;Challenge: Pair text with embedding&lt;/li&gt;&#xA;&lt;li&gt;Vector databases&lt;/li&gt;&#xA;&lt;li&gt;Set up your vector database&lt;/li&gt;&#xA;&lt;li&gt;Store vector embeddings&lt;/li&gt;&#xA;&lt;li&gt;Semantic search&lt;/li&gt;&#xA;&lt;li&gt;Query embeddings using similarity search&lt;/li&gt;&#xA;&lt;li&gt;Create a conversational response using OpenAI&lt;/li&gt;&#xA;&lt;li&gt;Chunking text from documents&lt;/li&gt;&#xA;&lt;li&gt;Challenge: Split text, get vectors, insert into Supabase&lt;/li&gt;&#xA;&lt;li&gt;Error handling&lt;/li&gt;&#xA;&lt;li&gt;Query database and manage multiple matches&lt;/li&gt;&#xA;&lt;li&gt;AI chatbot proof of concept&lt;/li&gt;&#xA;&lt;li&gt;Retrieval-augmented generation (RAG)&lt;/li&gt;&#xA;&lt;li&gt;Solo Project: PopChoice&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;agents-117-min&#34;&gt;&#xA;  Agents (117 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#agents-117-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI Agent Intro&lt;/li&gt;&#xA;&lt;li&gt;Prompt Engineering 101&lt;/li&gt;&#xA;&lt;li&gt;Control Response Formats&lt;/li&gt;&#xA;&lt;li&gt;Zooming Out&lt;/li&gt;&#xA;&lt;li&gt;Agent Setup&lt;/li&gt;&#xA;&lt;li&gt;Introduction to ReAct prompting&lt;/li&gt;&#xA;&lt;li&gt;Build action functions&lt;/li&gt;&#xA;&lt;li&gt;Write ReAct prompt - part 1 - planning&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 2 - ReAct prompt&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 3 - how does the &amp;ldquo;loop&amp;rdquo; work?&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 4 - code setup&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 5 - Plan for parsing the response&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 6 - Parsing the Action&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 7 - Calling the function&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 8 - Housekeeping&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 9 - Finally! The loop!&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - part 1 - Intro&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - part 2 - Demo day&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - part 3 - Tools&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 4 - Loop Logic&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 5 - Setup Challenge&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 6 - Tool Calls&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 7 - Pushing to messages&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 8 - Adding arguments&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 9 - Automatic function calls&lt;/li&gt;&#xA;&lt;li&gt;Adding UI to agent - proof of concept&lt;/li&gt;&#xA;&lt;li&gt;Solo Project - AI Travel Agent&lt;/li&gt;&#xA;&lt;li&gt;Nice work!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;multimodality-62-min&#34;&gt;&#xA;  Multimodality (62 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#multimodality-62-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Introduction&lt;/li&gt;&#xA;&lt;li&gt;Generate original images from a text prompt&lt;/li&gt;&#xA;&lt;li&gt;Response formats&lt;/li&gt;&#xA;&lt;li&gt;Prompting for image generation&lt;/li&gt;&#xA;&lt;li&gt;Size, quality and style&lt;/li&gt;&#xA;&lt;li&gt;Editing images&lt;/li&gt;&#xA;&lt;li&gt;Image generation challenge&lt;/li&gt;&#xA;&lt;li&gt;Image generation challenge solution&lt;/li&gt;&#xA;&lt;li&gt;GPT-4 with Vision - Part 1&lt;/li&gt;&#xA;&lt;li&gt;GPT-4 with Vision - Part 2&lt;/li&gt;&#xA;&lt;li&gt;Image generation &amp;amp; Vision recap&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;openais-assistants-api-30-min&#34;&gt;&#xA;  OpenAI&amp;rsquo;s Assistants API (30 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#openais-assistants-api-30-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Introducing the Assistants API&lt;/li&gt;&#xA;&lt;li&gt;How OpenAI Assistants work&lt;/li&gt;&#xA;&lt;li&gt;Create an Assistant&lt;/li&gt;&#xA;&lt;li&gt;Create a thread and messages&lt;/li&gt;&#xA;&lt;li&gt;Running an Assistant&lt;/li&gt;&#xA;&lt;li&gt;Bring it all together&lt;/li&gt;&#xA;&lt;li&gt;More to explore&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>5 Steps Learning Template</title>
      <link>https://imipark.github.io/posts/5_steps_learning_template/</link>
      <pubDate>Tue, 25 Mar 2025 13:19:10 -0700</pubDate>
      <guid>https://imipark.github.io/posts/5_steps_learning_template/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;What&amp;rsquo;s the Problem?&#xA;&lt;em&gt;What is the issue, gap, or challenge this module/concept is trying to address?&lt;/em&gt;&#xA;→ &lt;strong&gt;Transition&lt;/strong&gt;: “So what if this problem exists?”&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Why Does It Matter?&#xA;&lt;em&gt;What are the real-world stakes or consequences of not solving this problem? Who or what is affected?&lt;/em&gt;&#xA;→ &lt;strong&gt;Transition&lt;/strong&gt;: “Given this urgency, what’s the smart way to tackle it?”&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;What’s the Core Idea?&#xA;&lt;em&gt;What is the central concept, structure, or strategy introduced to solve the problem?&lt;/em&gt;&#xA;→ &lt;strong&gt;Transition&lt;/strong&gt;: “Okay, so how would I actually &lt;em&gt;apply&lt;/em&gt; or &lt;em&gt;build&lt;/em&gt; this?”&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hugo Setup and Deploy</title>
      <link>https://imipark.github.io/posts/hugo-setup/</link>
      <pubDate>Thu, 20 Mar 2025 21:23:49 -0700</pubDate>
      <guid>https://imipark.github.io/posts/hugo-setup/</guid>
      <description>&lt;p&gt;Minimal setup using &lt;code&gt;hugo-book&lt;/code&gt; theme inside a Conda environment, with GitHub Pages deployment.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-create-and-activate-conda-environment&#34;&gt;&#xA;  1. Create and Activate Conda Environment&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-create-and-activate-conda-environment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create -n hugo-env&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate hugo-env&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-install-hugo--create-hugo-site-with-hugo-book-theme&#34;&gt;&#xA;  2. Install Hugo &amp;amp; Create Hugo Site with &lt;code&gt;hugo-book&lt;/code&gt; Theme&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-install-hugo--create-hugo-site-with-hugo-book-theme&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Install Hugo&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install hugo         &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Or: brew install hugo&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Create Hugo site&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hugo new site hugo-site&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#04a5e5&#34;&gt;cd&lt;/span&gt; hugo-site&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Initialize git and add theme&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git init&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;3-configure-configtoml&#34;&gt;&#xA;  3. Configure &lt;code&gt;config.toml&lt;/code&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-configure-configtoml&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-toml&#34; data-lang=&#34;toml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;baseURL = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;https://your-username.github.io/&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;languageCode = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;en-us&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;title = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;My Hugo Site&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;theme = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;hugo-book&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[params]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookTheme = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;light&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookToC = &lt;span style=&#34;color:#fe640b&#34;&gt;true&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookCollapseSection = &lt;span style=&#34;color:#fe640b&#34;&gt;true&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookFlatSection = &lt;span style=&#34;color:#fe640b&#34;&gt;false&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[[menu.sidebar]]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Knowledge Graph&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  url = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;/kg/&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  weight = &lt;span style=&#34;color:#fe640b&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;4-create-content-and-_indexmd-files&#34;&gt;&#xA;  4. Create Content and &lt;code&gt;_index.md&lt;/code&gt; Files&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#4-create-content-and-_indexmd-files&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Create directories and content&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p content/kg/topic1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;touch content/_index.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;touch content/kg/_index.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;touch content/kg/topic1/_index.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hugo new kg/topic1/intro.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;directory-structure&#34;&gt;&#xA;  Directory Structure&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#directory-structure&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;content/&#xA;├── _index.md&#xA;├── kg/&#xA;│   ├── _index.md&#xA;│   └── topic1/&#xA;│       ├── _index.md&#xA;│       └── intro.md&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;_indexmd-contents&#34;&gt;&#xA;  &lt;code&gt;_index.md&lt;/code&gt; contents&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#_indexmd-contents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;content/_index.md&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hugo Source Backup</title>
      <link>https://imipark.github.io/posts/hugo-source-backup/</link>
      <pubDate>Thu, 20 Mar 2025 21:23:49 -0700</pubDate>
      <guid>https://imipark.github.io/posts/hugo-source-backup/</guid>
      <description>&lt;p&gt;This guide outlines how to back up your &lt;strong&gt;Hugo source files&lt;/strong&gt; (excluding the &lt;code&gt;public/&lt;/code&gt; folder) to a &lt;strong&gt;private GitHub repository&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-folder-structure&#34;&gt;&#xA;  📁 Folder Structure&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-folder-structure&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Typical Hugo project structure:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hugo-site/&#xA;├── archetypes/&#xA;├── content/&#xA;├── layouts/&#xA;├── static/&#xA;├── themes/&#xA;├── config.toml&#xA;├── public/           # &amp;lt;- This is ignored for source backup&#xA;└── backup.sh         # Backup script&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-1-create-a-private-github-repo&#34;&gt;&#xA;  ✅ 1. Create a Private GitHub Repo&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-1-create-a-private-github-repo&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Go to &lt;a href=&#34;https://github.com/new&#34;&gt;https://github.com/new&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Name it something like &lt;code&gt;hugo-source&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Set visibility to &lt;strong&gt;Private&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Don’t initialize with README or license&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-2-initialize-git-in-your-hugo-site-if-not-already&#34;&gt;&#xA;  ✅ 2. Initialize Git in Your Hugo Site (if not already)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-2-initialize-git-in-your-hugo-site-if-not-already&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git init&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git remote add origin https://github.com/&amp;lt;your-username&amp;gt;/hugo-source.git&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#04a5e5&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;public/&amp;#34;&lt;/span&gt; &amp;gt;&amp;gt; .gitignore&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-3-create-the-backup-script&#34;&gt;&#xA;  ✅ 3. Create the Backup Script&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-3-create-the-backup-script&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Create a file named &lt;code&gt;backup.sh&lt;/code&gt; in the root of your Hugo project:&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/instruct_gpt_codes_params/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/instruct_gpt_codes_params/</guid>
      <description>&lt;h1 id=&#34;rlhf-pipeline-key-non-default-settings&#34;&gt;&#xA;  RLHF Pipeline: Key Non-Default Settings&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#rlhf-pipeline-key-non-default-settings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;critical-configuration-non-defaults-only&#34;&gt;&#xA;  Critical Configuration (Non-Defaults Only)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#critical-configuration-non-defaults-only&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-models--architecture&#34;&gt;&#xA;  🎯 Models &amp;amp; Architecture&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-models--architecture&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Setting&lt;/th&gt;&#xA;          &lt;th&gt;Value&lt;/th&gt;&#xA;          &lt;th&gt;Why Not Default?&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Model Class&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Step 1/3: &lt;code&gt;CausalLM&lt;/code&gt;&lt;br&gt;Step 2: &lt;code&gt;SequenceClassification&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Step 2 needs scalar reward output, not text generation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Quantization&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;4-bit QLoRA&lt;/td&gt;&#xA;          &lt;td&gt;Fits 7B model in 24GB VRAM (vs 28GB for fp16)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;num_labels&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Step 2: &lt;code&gt;1&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Reward model outputs single scalar score&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;-dataset-configuration&#34;&gt;&#xA;  📊 Dataset Configuration&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-dataset-configuration&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Setting&lt;/th&gt;&#xA;          &lt;th&gt;Value&lt;/th&gt;&#xA;          &lt;th&gt;Why Not Default?&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Dataset Size&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;SFT: 20K, RM: 50K, PPO: 20K&lt;/td&gt;&#xA;          &lt;td&gt;RM needs more data for robust preference learning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Data Format&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;SFT: chosen only&lt;br&gt;RM: chosen+rejected pairs&lt;br&gt;PPO: prompts only&lt;/td&gt;&#xA;          &lt;td&gt;Each step requires different supervision signal&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Train/Eval Split&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Step 2: 5% eval&lt;/td&gt;&#xA;          &lt;td&gt;Only RM needs validation to prevent reward hacking&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;-training-hyperparameters&#34;&gt;&#xA;  ⚙️ Training Hyperparameters&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-training-hyperparameters&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Setting&lt;/th&gt;&#xA;          &lt;th&gt;Value&lt;/th&gt;&#xA;          &lt;th&gt;Why Not Default?&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Learning Rate&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;SFT: &lt;code&gt;2e-4&lt;/code&gt;&lt;br&gt;RM: &lt;code&gt;5e-5&lt;/code&gt;&lt;br&gt;PPO: &lt;code&gt;1e-6&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Decreasing LR prevents destabilizing previous training&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Batch Size&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;1&lt;/code&gt; (SFT/RM)&lt;br&gt;&lt;code&gt;8&lt;/code&gt; (PPO)&lt;/td&gt;&#xA;          &lt;td&gt;Memory constraint; PPO needs multiple rollouts per update&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Gradient Accumulation&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;SFT: 16&lt;br&gt;RM: 32&lt;/td&gt;&#xA;          &lt;td&gt;Simulates larger batch sizes within memory limit&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Effective Batch Size&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;SFT: 16&lt;br&gt;RM: 32&lt;br&gt;PPO: 8&lt;/td&gt;&#xA;          &lt;td&gt;RM needs larger batches for stable ranking gradients&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;-lora-configuration&#34;&gt;&#xA;  🔧 LoRA Configuration&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-lora-configuration&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Setting&lt;/th&gt;&#xA;          &lt;th&gt;Value&lt;/th&gt;&#xA;          &lt;th&gt;Why Not Default?&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;r&lt;/strong&gt; (rank)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;16&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Balance between parameter efficiency and model capacity&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;alpha&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;32&lt;/code&gt; (2×r)&lt;/td&gt;&#xA;          &lt;td&gt;Standard scaling for LoRA updates&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;dropout&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;0.05&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Mild regularization to prevent adapter overfitting&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;task_type&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;SFT/PPO: &lt;code&gt;CAUSAL_LM&lt;/code&gt;&lt;br&gt;RM: &lt;code&gt;SEQ_CLS&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Matches the model head type for each step&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;-quantization-details&#34;&gt;&#xA;  🎛️ Quantization Details&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-quantization-details&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Setting&lt;/th&gt;&#xA;          &lt;th&gt;Value&lt;/th&gt;&#xA;          &lt;th&gt;Why Not Default?&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;load_in_4bit&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Reduces memory by 75% vs fp16&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;bnb_4bit_use_double_quant&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Quantizes quantization constants (extra memory savings)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;bnb_4bit_quant_type&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;&amp;quot;nf4&amp;quot;&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Normal Float 4-bit optimal for weights (vs uniform)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;bnb_4bit_compute_dtype&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;bfloat16&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Better numerical stability than fp16 for training&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;-optimization-settings&#34;&gt;&#xA;  📈 Optimization Settings&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-optimization-settings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Setting&lt;/th&gt;&#xA;          &lt;th&gt;Value&lt;/th&gt;&#xA;          &lt;th&gt;Why Not Default?&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;optim&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;paged_adamw_8bit&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Memory-efficient optimizer for 4-bit training&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;bf16&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Better gradient stability than fp16&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;gradient_checkpointing&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Trades compute for memory (enables longer sequences)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;lr_scheduler_type&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;&amp;quot;cosine&amp;quot;&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Smooth LR decay prevents abrupt training disruption&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;warmup_ratio&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;0.03&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Stabilizes initial training with 4-bit quantization&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;max_grad_norm&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;0.3&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Prevents gradient explosion in LoRA training&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;-ppo-specific-step-3-only&#34;&gt;&#xA;  🔄 PPO-Specific (Step 3 Only)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-ppo-specific-step-3-only&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Setting&lt;/th&gt;&#xA;          &lt;th&gt;Value&lt;/th&gt;&#xA;          &lt;th&gt;Why Not Default?&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;mini_batch_size&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Memory constraint during on-policy generation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;ppo_epochs&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;4&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Multiple passes over collected experience&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;init_kl_coef&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;0.1&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Prevents policy from diverging too far from SFT&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;adap_kl_ctrl&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Dynamically adjusts KL penalty based on divergence&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;gamma&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;1.0&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;No discounting (language has no clear episode structure)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;lam&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;0.95&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;GAE parameter balancing bias-variance in advantage&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;cliprange&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;0.2&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Limits policy update size (PPO core mechanism)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;vf_coef&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;0.1&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Weight of value function loss vs policy loss&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;training-flow-summary&#34;&gt;&#xA;  Training Flow Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#training-flow-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Llama-2-7b-hf (4-bit quantized)&#xA;       ↓&#xA;   [Step 1: SFT]  ← 20K chosen examples, LR=2e-4, LoRA r=16&#xA;       ↓&#xA;       ├─→ [Step 2: RM]  ← 50K preference pairs, LR=5e-5, outputs scalar&#xA;       │        ↓&#xA;       └─→ [Step 3: PPO]  ← 20K prompts, LR=1e-6, KL=0.1&#xA;            ↓&#xA;     Final RLHF Model&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;key-metrics-to-monitor&#34;&gt;&#xA;  Key Metrics to Monitor&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#key-metrics-to-monitor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Step&lt;/th&gt;&#xA;          &lt;th&gt;Primary Metric&lt;/th&gt;&#xA;          &lt;th&gt;Danger Sign&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;SFT&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Training loss ↓&lt;/td&gt;&#xA;          &lt;td&gt;Eval loss ↑ (overfitting)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;RM&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Ranking accuracy ↑&lt;/td&gt;&#xA;          &lt;td&gt;Reward always higher for longer text (length bias)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;PPO&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Mean reward ↑&lt;/td&gt;&#xA;          &lt;td&gt;KL &amp;gt; 0.5 (policy collapse)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;why-these-specific-values&#34;&gt;&#xA;  Why These Specific Values?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#why-these-specific-values&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;learning-rate-decay-pattern&#34;&gt;&#xA;  Learning Rate Decay Pattern&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#learning-rate-decay-pattern&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;SFT (2e-4)&lt;/strong&gt;: Highest LR for initial adaptation from base model&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RM (5e-5)&lt;/strong&gt;: Lower to preserve SFT knowledge while learning preferences&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;PPO (1e-6)&lt;/strong&gt;: Tiny updates to avoid destroying alignment from RM&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;batch-size-strategy&#34;&gt;&#xA;  Batch Size Strategy&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#batch-size-strategy&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Small per-device (1)&lt;/strong&gt;: GPU memory constraint with 7B model&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Large accumulation (16-32)&lt;/strong&gt;: Stabilizes gradients for contrastive learning (RM)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;PPO (8 rollouts)&lt;/strong&gt;: Enough diversity for policy gradient estimation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;quantization-choices&#34;&gt;&#xA;  Quantization Choices&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#quantization-choices&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;4-bit&lt;/strong&gt;: Only option that fits 7B + optimizer states in 24GB&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;NF4&lt;/strong&gt;: Specifically designed for neural network weight distributions&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Double quant&lt;/strong&gt;: Squeezes extra ~1GB by quantizing quantization parameters&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bfloat16 compute&lt;/strong&gt;: Prevents underflow in gradients during backprop&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;lora-design&#34;&gt;&#xA;  LoRA Design&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#lora-design&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;r=16&lt;/strong&gt;: Sweet spot for 7B models (too low = capacity loss, too high = overfitting)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;alpha=32&lt;/strong&gt;: Standard 2× scaling keeps update magnitudes reasonable&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;All attention + FFN&lt;/strong&gt;: Covers both information routing and transformation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;ppo-parameters&#34;&gt;&#xA;  PPO Parameters&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ppo-parameters&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;KL penalty (0.1)&lt;/strong&gt;: Prevents catastrophic forgetting of SFT behavior&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Clip (0.2)&lt;/strong&gt;: Conservative updates reduce instability&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Gamma (1.0)&lt;/strong&gt;: No temporal discounting (each token equally important)&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>AI Eval Methods</title>
      <link>https://imipark.github.io/ai-workflows/eval/eval_method/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/eval/eval_method/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;AI Eval Methods&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Eval_Methods/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;├── AI_Evals/                    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Alignment-focused evals (e.g., OpenAI evals)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;│   ├── OpenAI_Evals/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;│   ├── Benchmark_Suites/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;│   └── Eval_Metrics/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;├── Human-in-the-Loop/          &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Evaluation strategies w/ annotators&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;│   ├── Labeler-Guides/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;│   └── HITL-Pipelines.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;├── Eval Frameworks/            &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Tools: helm, trl.eval, chat-arena&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;└── Monitoring_vs_Eval.md       &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Clarify ops-vs-research boundary&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;ai_evals--evaluation-content-focused-on-alignment&#34;&gt;&#xA;  &lt;strong&gt;AI_Evals/&lt;/strong&gt; — Evaluation Content Focused on Alignment&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ai_evals--evaluation-content-focused-on-alignment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Goal&lt;/strong&gt;: Evaluate &lt;em&gt;how well&lt;/em&gt; AI models behave according to human preferences and task goals.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Case Study: The Hidden Danger of Correlation in Healthcare AI</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/ehr_model_failure_case_study/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/ehr_model_failure_case_study/</guid>
      <description>&lt;h1 id=&#34;case-study-the-hidden-danger-of-correlation-in-healthcare-ai&#34;&gt;&#xA;  Case Study: The Hidden Danger of Correlation in Healthcare AI&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#case-study-the-hidden-danger-of-correlation-in-healthcare-ai&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-the-goal&#34;&gt;&#xA;  🎯 The Goal&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-the-goal&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Build a machine learning model to predict &lt;strong&gt;which pneumonia patients might die&lt;/strong&gt;, using historical &lt;strong&gt;Electronic Health Record (EHR)&lt;/strong&gt; data. This would help doctors:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Identify high-risk patients who need &lt;strong&gt;ICU care&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Identify low-risk patients who could &lt;strong&gt;recover at home&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-what-actually-happened&#34;&gt;&#xA;  ✅ What Actually Happened&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-what-actually-happened&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The model was trained on real EHR data and found a surprising pattern:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Categories of Machine Learning Applications in Healthcare</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/clinical_ml_categories/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/clinical_ml_categories/</guid>
      <description>&lt;h1 id=&#34;categories-of-machine-learning-applications-in-healthcare&#34;&gt;&#xA;  Categories of Machine Learning Applications in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#categories-of-machine-learning-applications-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;In the Stanford course and broader healthcare ML ecosystem, &lt;strong&gt;&amp;ldquo;practice of care&amp;rdquo;&lt;/strong&gt; is just one of several conceptual categories used to frame ML applications. Each category reflects a different &lt;strong&gt;purpose&lt;/strong&gt; and &lt;strong&gt;clinical context&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-1-diagnosis&#34;&gt;&#xA;  🧠 1. Diagnosis&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-1-diagnosis&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Question answered:&lt;/strong&gt; &lt;em&gt;What is wrong with the patient?&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Machine learning identifies diseases or conditions based on input data.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Detecting pneumonia from a chest X-ray (image classification)&lt;/li&gt;&#xA;&lt;li&gt;Identifying arrhythmias from ECG waveforms&lt;/li&gt;&#xA;&lt;li&gt;Classifying skin lesions as malignant vs benign&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-2-prediction--prognosis&#34;&gt;&#xA;  📈 2. Prediction / Prognosis&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-2-prediction--prognosis&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Question answered:&lt;/strong&gt; &lt;em&gt;What will happen to the patient?&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ch12. Synthetic Data</title>
      <link>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ch12_synthetic_data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ch12_synthetic_data/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Ch12. Synthetic Data&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;br&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;where-synthetic-data-appears-in-the-training-pipeline&#34;&gt;&#xA;  Where Synthetic Data appears in the training pipeline&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#where-synthetic-data-appears-in-the-training-pipeline&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre style=&#34;line-height: 1.2;&#34;&gt;&#xA;Stage 1: SFT (Ch 4)                  Stage 2: RLHF (Ch 11)&#xA;─────────────────                    ────────────────────&#xA;   [Prompts]                            [On-policy model]&#xA;       ↓                                      ↓&#xA;   ┌────────┐                          [Generate 2+ responses]&#xA;   │ Human  │ → Completions                   ↓&#xA;   │Writers │                            ┌─────────┐&#xA;   └────────┘                            │ Human   │ → Preference labels&#xA;       ↓                                 │ Raters  │&#xA;   OR  ← CH 12 HERE!                     └─────────┘&#xA;       ↓                                      ↓&#xA;   ┌────────┐                            OR  ← CH 12 HERE TOO!&#xA;   │ GPT-4o │ → Completions (cheaper)         ↓&#xA;   │Distill │ ← DISTILLATION (Ch 12.1)   ┌─────────┐&#xA;   └────────┘                            │LLM Judge│ ← AI FEEDBACK (Ch 12.2)&#xA;       ↓                                 │ (RLAIF) │ ← CONSTITUTIONAL AI (Ch 12.3)&#xA;   [SFT Dataset]                         └─────────┘&#xA;       ↓                                      ↓&#xA;   Train base model                      [Preference Dataset]&#xA;       ↓                                      ↓&#xA;   [Instruction-tuned model] ────────→  Train reward model → PPO/GRPO&#xA;                                             ↓&#xA;                                        [Aligned model]&#xA;&lt;/pre&gt;&#xA;&lt;br&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;the-big-picture---why-synthetic-data-matters&#34;&gt;&#xA;  &lt;strong&gt;THE BIG PICTURE - WHY SYNTHETIC DATA MATTERS&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#the-big-picture---why-synthetic-data-matters&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h3 id=&#34;q1-what-is-the-central-thesis-of-chapter-12&#34;&gt;&#xA;  Q1: What is the central thesis of Chapter 12?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-the-central-thesis-of-chapter-12&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;A: &amp;#34;RLHF was rooted in keeping humans in the loop. But as AI models got better, they became better than humans at creating training data. This changed everything.&amp;#34;&#xA;   This represents a fundamental paradigm shift in how we think about&#xA;   training data for modern language models.&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;q2-what-was-the-paradigm-shift-that-chapter-12-documents&#34;&gt;&#xA;  Q2: What was the paradigm shift that Chapter 12 documents?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-was-the-paradigm-shift-that-chapter-12-documents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: The evolution happened in three waves:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ch7. Reasoning &amp; Inference-time Scaling</title>
      <link>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ch7_reasoning_inference_time_scaling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ch7_reasoning_inference_time_scaling/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Ch7. REASONING &amp; INFERENCE-TIME SCALING&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;br&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;the-big-picture---why-is-this-breakthrough&#34;&gt;&#xA;  &lt;strong&gt;THE BIG PICTURE - WHY IS THIS BREAKTHROUGH?&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#the-big-picture---why-is-this-breakthrough&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h3 id=&#34;q1-what-actually-happened-in-2025-that-makes-chapter-7-revolutionary&#34;&gt;&#xA;  Q1: What actually happened in 2025 that makes Chapter 7 revolutionary?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-actually-happened-in-2025-that-makes-chapter-7-revolutionary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Two seismic events changed everything:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;OpenAI o1 (Sep 2024)&lt;/strong&gt; - Showed reasoning models work at scale&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DeepSeek R1 (Jan 2025)&lt;/strong&gt; - Fully documented the recipe openly&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;Timeline:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Before:&lt;/strong&gt; &amp;ldquo;RL doesn&amp;rsquo;t work&amp;rdquo; (2018 famous blog post)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;After:&lt;/strong&gt; 20+ reasoning models released in 6 months (Jan-Jul 2025)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is like going from &amp;ldquo;flight is impossible&amp;rdquo; to &amp;ldquo;commercial airlines everywhere&amp;rdquo; in 6 months. The paradigm shifted THAT fast.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ch9. Instruction Fine-Tuning (IFT/SFT)</title>
      <link>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ch9_sft/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ch9_sft/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Ch9: Instruction Fine-Tuning (IFT/SFT)&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-are-chat-templates-and-why-do-they-matter&#34;&gt;&#xA;  &lt;strong&gt;Q1: What are chat templates and why do they matter?&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-are-chat-templates-and-why-do-they-matter&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Chat templates are formatting systems that structure conversations into a format language models can process. They use special tokens (like &lt;code&gt;&amp;lt;|im_start|&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;|im_end|&amp;gt;&lt;/code&gt;) to mark boundaries between different parts of the conversation.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;lt;|im_start|&amp;gt;system&#xA;You are a helpful assistant&amp;lt;|im_end|&amp;gt;&#xA;&amp;lt;|im_start|&amp;gt;user&#xA;What is 2+2?&amp;lt;|im_end|&amp;gt;&#xA;&amp;lt;|im_start|&amp;gt;assistant&#xA;The answer is 4&amp;lt;|im_end|&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q2-what-are-the-three-message-roles-and-how-do-they-differ&#34;&gt;&#xA;  &lt;strong&gt;Q2: What are the three message roles and how do they differ?&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-are-the-three-message-roles-and-how-do-they-differ&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clinical Data Science</title>
      <link>https://imipark.github.io/healthcare/clinical_ai/clinical_ai_usecase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/clinical_ai/clinical_ai_usecase/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Clinical Data Science&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;core-priority-retrieval-augmented-generation-rag&#34;&gt;&#xA;  Core Priority: Retrieval-Augmented Generation (RAG)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#core-priority-retrieval-augmented-generation-rag&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;RAG is one of the most in-demand skills in clinical GenAI due to:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The need to &lt;strong&gt;ground LLMs in real patient data&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Compliance, privacy, and traceability&lt;/li&gt;&#xA;&lt;li&gt;Applications like:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Clinical Question Answering&lt;/li&gt;&#xA;&lt;li&gt;Summarization of EHRs&lt;/li&gt;&#xA;&lt;li&gt;Evidence-based recommendations&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;key-tools&#34;&gt;&#xA;  Key Tools:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#key-tools&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Vector DBs&lt;/strong&gt;: Vertex AI Search, Pinecone, FAISS&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;LLMs&lt;/strong&gt;: Gemini, GPT-4, PaLM, Med-PaLM&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Frameworks&lt;/strong&gt;: LangChain, LlamaIndex, Vertex Extensions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;other-high-demand-skillsets&#34;&gt;&#xA;  Other High-Demand Skillsets&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#other-high-demand-skillsets&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Clinical NLP &amp;amp; Information Extraction&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clinical Text Feature Extraction Using Dictionary-Based Filtering</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/nlp_clinical_text/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/nlp_clinical_text/</guid>
      <description>&lt;h1 id=&#34;-clinical-text-feature-extraction-using-dictionary-based-filtering&#34;&gt;&#xA;  🧬 Clinical Text Feature Extraction Using Dictionary-Based Filtering&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-clinical-text-feature-extraction-using-dictionary-based-filtering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide demonstrates a simplified approach for processing clinical text &lt;strong&gt;without removing PHI directly&lt;/strong&gt;. Instead, it &lt;strong&gt;extracts only medical terms&lt;/strong&gt; from a predefined dictionary (simulated knowledge graph), which &lt;strong&gt;passively excludes PHI&lt;/strong&gt; and enables downstream analyses.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-objective&#34;&gt;&#xA;  ✅ Objective&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-objective&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Extract &lt;strong&gt;present, positive mentions&lt;/strong&gt; of clinical concepts (e.g., diseases, symptoms, drugs).&lt;/li&gt;&#xA;&lt;li&gt;Avoid mentions that are &lt;strong&gt;negated&lt;/strong&gt; or refer to &lt;strong&gt;historical/family context&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Demonstrate the principle: &lt;strong&gt;&amp;ldquo;Keep only medical terms&amp;rdquo;&lt;/strong&gt; as an alternative to direct PHI removal.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-input-example&#34;&gt;&#xA;  🧾 Input Example&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-input-example&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Patient complains of chest pain. No signs of pneumonia. History of diabetes mellitus.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Prescribed metformin. Mother had breast cancer.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-procedure-overview&#34;&gt;&#xA;  🧠 Procedure Overview&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-procedure-overview&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Define a &lt;strong&gt;medical term dictionary&lt;/strong&gt; (simulating a knowledge graph).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Split the clinical note&lt;/strong&gt; into sentences.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ignore sentences&lt;/strong&gt; with negation or irrelevant context.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Match and extract terms&lt;/strong&gt; from the dictionary.&lt;/li&gt;&#xA;&lt;li&gt;Output &lt;strong&gt;structured features&lt;/strong&gt; for downstream use.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-code-implementation-python&#34;&gt;&#xA;  🧪 Code Implementation (Python)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-code-implementation-python&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#179299&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#fe640b&#34;&gt;re&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 1. Simulated clinical note&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clinical_note &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;Patient complains of chest pain. No signs of pneumonia. History of diabetes mellitus.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;Prescribed metformin. Mother had breast cancer.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 2. Simulated knowledge graph (medical term dictionary)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;medical_terms &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;chest pain&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;symptom&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;pneumonia&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;disease&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;diabetes mellitus&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;disease&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;metformin&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;drug&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;breast cancer&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;disease&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 3. Split into sentences&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sentences &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#d20f39&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;\.\s*&amp;#39;&lt;/span&gt;, clinical_note&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;strip())&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;features &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; []&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 4. Process each sentence&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8839ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentences:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sentence_lower &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; sentence&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;lower()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 5. Skip negated or historical context&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#8839ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;no &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;history of&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;mother had&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#8839ef&#34;&gt;continue&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 6. Match medical terms&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#8839ef&#34;&gt;for&lt;/span&gt; term &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; medical_terms:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#8839ef&#34;&gt;if&lt;/span&gt; term &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            features&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;append({&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;term&amp;#34;&lt;/span&gt;: term,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;: medical_terms[term],&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;sentence&amp;#34;&lt;/span&gt;: sentence&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;strip()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            })&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 7. Output extracted features&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8839ef&#34;&gt;for&lt;/span&gt; feature &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; features:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#04a5e5&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#d20f39&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Found &lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;{&lt;/span&gt;feature[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#40a02b&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt; → &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;{&lt;/span&gt;feature[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;term&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#40a02b&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39; in: &lt;/span&gt;&lt;span style=&#34;color:#1e66f5&#34;&gt;\&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;{&lt;/span&gt;feature[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;sentence&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#40a02b&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#1e66f5&#34;&gt;\&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-sample-output&#34;&gt;&#xA;  📤 Sample Output&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-sample-output&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Found symptom → &amp;#39;chest pain&amp;#39; in: &amp;#34;Patient complains of chest pain&amp;#34;&#xA;Found drug → &amp;#39;metformin&amp;#39; in: &amp;#34;Prescribed metformin&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary&#34;&gt;&#xA;  📌 Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;This method:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clinical Text Mining Pipeline (Steps 1–5)</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/clinical_text_mining_pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/clinical_text_mining_pipeline/</guid>
      <description>&lt;h1 id=&#34;-clinical-text-mining-pipeline-steps-15&#34;&gt;&#xA;  🏥 Clinical Text Mining Pipeline (Steps 1–5)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-clinical-text-mining-pipeline-steps-15&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document outlines a high-level clinical text mining pipeline using knowledge graphs, NLP, and structured indexing. The goal is to extract, enrich, and analyze clinical concepts from raw EMR text.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-1-preprocessing-clinical-documents&#34;&gt;&#xA;  🧾 &lt;strong&gt;Step 1: Preprocessing Clinical Documents&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-1-preprocessing-clinical-documents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; Prepare and normalize clinical notes for processing.&lt;br&gt;&#xA;&lt;strong&gt;Tools:&lt;/strong&gt; Text cleaning, sentence segmentation, tokenizer.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Example: Clean and split into sentences&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#179299&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#fe640b&#34;&gt;re&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clinical_note &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Pt c/o chest pain. No signs of pneumonia. History of stroke. Prescribed metformin.&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sentences &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#d20f39&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;\.\s*&amp;#39;&lt;/span&gt;, clinical_note&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;lower())&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-2-extract-terms-using-knowledge-graph--nlp&#34;&gt;&#xA;  🧠 &lt;strong&gt;Step 2: Extract Terms Using Knowledge Graph + NLP&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-2-extract-terms-using-knowledge-graph--nlp&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; Identify medical terms using a knowledge graph and remove ambiguous, negated, or contextual mentions.&lt;br&gt;&#xA;&lt;strong&gt;Tools:&lt;/strong&gt; Knowledge Graph (e.g., UMLS), NegEx, ConText&lt;/p&gt;</description>
    </item>
    <item>
      <title>Core Components and Fusion Strategies in Multimodal LLMs</title>
      <link>https://imipark.github.io/ai-workflows/genai/multimodel_llms/components_fusions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/multimodel_llms/components_fusions/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Core Components of a Multimodal LLM&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Visual Encoder&lt;/strong&gt;&lt;br&gt;&#xA;Converts input images into feature embeddings. Common choices include CLIP, ViT, and EVA.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Modality Adapter (Aligner)&lt;/strong&gt;&lt;br&gt;&#xA;Projects or transforms visual features to be compatible with the language model’s embedding space (e.g., via MLP or cross-attention).&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Language Model (LLM)&lt;/strong&gt;&lt;br&gt;&#xA;A large pretrained language model (e.g., LLaMA, GPT) that consumes both text and aligned visual inputs to generate or classify responses.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Preparation in RLHF -- Ch6 (Preference Data) vs Ch9 (SFT Data)</title>
      <link>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ch6_vs_ch9_data_comparison/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ch6_vs_ch9_data_comparison/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Data Prep in RLHF - Ch6 (Preference Data) vs Ch9 (SFT Data)&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;data-preparation-comparison-ch6-vs-ch9&#34;&gt;&#xA;  &lt;strong&gt;Data Preparation Comparison: Ch6 vs Ch9&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#data-preparation-comparison-ch6-vs-ch9&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Aspect&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Ch6: Preference Data&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Ch9: SFT/IFT Data&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Data Structure&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;PAIRWISE comparisons&lt;/strong&gt;: &lt;code&gt;(prompt, chosen_response, rejected_response)&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;SINGLE examples&lt;/strong&gt;: &lt;code&gt;(prompt, good_response)&lt;/code&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Purpose&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Learn to &lt;strong&gt;JUDGE&lt;/strong&gt; which response is better&lt;/td&gt;&#xA;          &lt;td&gt;Learn to &lt;strong&gt;GENERATE&lt;/strong&gt; good responses&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Data Format Example&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;{&amp;quot;prompt&amp;quot;: &amp;quot;What is 2+2?&amp;quot;,&lt;/code&gt;&lt;br&gt;&lt;code&gt;&amp;quot;chosen&amp;quot;: &amp;quot;The answer is 4&amp;quot;,&lt;/code&gt;&lt;br&gt;&lt;code&gt;&amp;quot;rejected&amp;quot;: &amp;quot;5&amp;quot;}&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;{&amp;quot;prompt&amp;quot;: &amp;quot;What is 2+2?&amp;quot;,&lt;/code&gt;&lt;br&gt;&lt;code&gt;&amp;quot;response&amp;quot;: &amp;quot;The answer is 4&amp;quot;}&lt;/code&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Collection Method&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;- Side-by-side comparison UI&lt;br&gt;- Likert scales (5-point, 8-point)&lt;br&gt;- Thumbs up/down&lt;br&gt;- ChatBotArena&lt;/td&gt;&#xA;          &lt;td&gt;- Human-written high-quality examples&lt;br&gt;- Curated Q&amp;amp;A pairs&lt;br&gt;- Single demonstrations&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Data Source&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human labelers&lt;/strong&gt; comparing responses&lt;br&gt;OR&lt;br&gt;&lt;strong&gt;Structured/Synthetic&lt;/strong&gt;:&lt;br&gt;- Correct vs incorrect (math)&lt;br&gt;- With constraint vs without&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human-written&lt;/strong&gt; completions&lt;br&gt;OR&lt;br&gt;&lt;strong&gt;Curated&lt;/strong&gt; high-quality examples&lt;br&gt;OR&lt;br&gt;&lt;strong&gt;Synthetic&lt;/strong&gt; (from stronger models)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Signal Type&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Comparative/Relative&lt;/strong&gt;: Which is better?&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Absolute&lt;/strong&gt;: This is a good response&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Typical Dataset Size&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;~100K preference pairs (InstructGPT)&lt;/td&gt;&#xA;          &lt;td&gt;~10K-1M examples (InstructGPT: 10K, modern: ~1M)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Multi-turn Handling&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;- Preference on &lt;strong&gt;final turn&lt;/strong&gt; only&lt;br&gt;- Continue with &amp;ldquo;chosen&amp;rdquo; answer&lt;br&gt;- Mask previous turns from loss&lt;/td&gt;&#xA;          &lt;td&gt;- Each turn = separate training example&lt;br&gt;- Unroll N-turn → N examples&lt;br&gt;- Mask prompts/previous turns&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Used to Train&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Ch7: Reward Model&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Ch9: SFT Model&lt;/strong&gt; (initial policy)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;What Gets Trained&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;L = -log(σ(r(chosen) - r(rejected)))&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;L = -log P(response|prompt)&lt;/code&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Next Stage Usage&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Ch11: RL training&lt;/strong&gt;&lt;br&gt;- Same/similar prompts can be reused&lt;br&gt;- RM provides scores&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Ch7: RM base model&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;Ch11: RL starting policy&lt;/strong&gt;&lt;br&gt;- Policy generates responses&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;key-insight-the-data-types-are-fundamentally-different&#34;&gt;&#xA;  &lt;strong&gt;Key Insight: The DATA TYPES are FUNDAMENTALLY DIFFERENT&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#key-insight-the-data-types-are-fundamentally-different&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ch9 SFT Data Says: &amp;ldquo;Here&amp;rsquo;s a good response. Learn to generate this.&amp;rdquo;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#8839ef&#34;&gt;&amp;#34;prompt&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Write a poem about goldfish&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#8839ef&#34;&gt;&amp;#34;response&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Golden swimmer, circling slow...&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Ch6 Preference Data Says: &amp;ldquo;Between these two responses, A is better than B. Learn to prefer A.&amp;rdquo;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#8839ef&#34;&gt;&amp;#34;prompt&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Write a poem about goldfish&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#8839ef&#34;&gt;&amp;#34;chosen&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Golden swimmer, circling slow... (follows constraint)&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#8839ef&#34;&gt;&amp;#34;rejected&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;In circles bright, the goldfish glides... (violates constraint)&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h3 id=&#34;the-complete-rlhf-pipeline&#34;&gt;&#xA;  &lt;strong&gt;The Complete RLHF Pipeline&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#the-complete-rlhf-pipeline&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre style=&#34;line-height: 1.0;&#34;&gt;&#xA;┌─────────────────────┐&#xA;│   Pretrained Model  │&#xA;└──────────┬──────────┘&#xA;           │&#xA;           ├──────────────────────────────┐&#xA;           ↓                              ↓&#xA;    ┌─────────────┐              ┌───────────────┐&#xA;    │  Ch9: SFT   │              │  Ch6: Collect │&#xA;    │             │              │  Preference   │&#xA;    │ Data:       │              │  Data         │&#xA;    │ (prompt,    │              │               │&#xA;    │  response)  │              │ Data:         │&#xA;    │             │              │ (prompt,      │&#xA;    │ Single good │              │  chosen,      │&#xA;    │ examples    │              │  rejected)    │&#xA;    └──────┬──────┘              │               │&#xA;           │                     │ Comparisons   │&#xA;           │                     └───────┬───────┘&#xA;           │                             │&#xA;           ↓                             ↓&#xA;    ┌─────────────┐              ┌───────────────┐&#xA;    │  SFT Model  │──base model─→│   Ch7: RM     │&#xA;    │  (Policy    │              │   Training    │&#xA;    │  starting   │              │               │&#xA;    │  point)     │              │ Uses Ch6 data │&#xA;    └──────┬──────┘              └───────┬───────┘&#xA;           │                             │&#xA;           │                             │&#xA;           └──────────┬──────────────────┘&#xA;                      ↓&#xA;              ┌───────────────┐&#xA;              │  Ch11: RL     │&#xA;              │  Optimization │&#xA;              │               │&#xA;              │ Policy: Ch9   │&#xA;              │ Scorer: Ch7   │&#xA;              │ Prompts: Ch6  │&#xA;              │ (or similar)  │&#xA;              └───────────────┘&#xA;&lt;/pre&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;summary&#34;&gt;&#xA;  &lt;strong&gt;Summary&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;The fundamental difference between Ch6 and Ch9 data lies in their &lt;strong&gt;learning objectives&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Quality, Labeling, and Weak Supervision in Clinical ML</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/data_quality_labeling_weak_supervision_qa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/data_quality_labeling_weak_supervision_qa/</guid>
      <description>&lt;h1 id=&#34;data-quality-labeling-and-weak-supervision-in-clinical-ml&#34;&gt;&#xA;  Data Quality, Labeling, and Weak Supervision in Clinical ML&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#data-quality-labeling-and-weak-supervision-in-clinical-ml&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;q1-what-does-garbage-in-garbage-out-mean-in-machine-learning&#34;&gt;&#xA;  Q1: What does &amp;ldquo;Garbage In, Garbage Out&amp;rdquo; mean in machine learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-does-garbage-in-garbage-out-mean-in-machine-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;It means that &lt;strong&gt;no model, no matter how advanced, can compensate for poor-quality data&lt;/strong&gt;. If your input data is noisy, biased, irrelevant, or mislabeled, your model will reflect those flaws.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;✅ The &lt;strong&gt;choice of data and problem&lt;/strong&gt; matters more than the algorithm itself.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;q2-can-large-rich-datasets-still-be-garbage&#34;&gt;&#xA;  Q2: Can large, rich datasets still be garbage?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-can-large-rich-datasets-still-be-garbage&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Yes — if the data is fundamentally flawed or based on faulty assumptions (like phrenology), more volume just means &lt;strong&gt;more noise&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diagnostic Metrics, Anchoring Perspectives, and Curve Interpretations</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/diagnostic_metrics_and_curves/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/diagnostic_metrics_and_curves/</guid>
      <description>&lt;h1 id=&#34;diagnostic-metrics-anchoring-perspectives-and-curve-interpretations&#34;&gt;&#xA;  Diagnostic Metrics, Anchoring Perspectives, and Curve Interpretations&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#diagnostic-metrics-anchoring-perspectives-and-curve-interpretations&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide summarizes the core diagnostic metrics based on anchoring logic (condition vs. prediction), and how these metrics relate to ROC and PR curves — especially under balanced vs. imbalanced class distributions.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-test-centric-metrics-anchored-on-actual-condition&#34;&gt;&#xA;  🔹 Test-Centric Metrics (Anchored on Actual Condition)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-test-centric-metrics-anchored-on-actual-condition&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Evaluates &lt;strong&gt;test performance&lt;/strong&gt;, &lt;strong&gt;independent&lt;/strong&gt; of disease prevalence.&lt;/li&gt;&#xA;&lt;li&gt;Anchor: &lt;strong&gt;Ground truth label&lt;/strong&gt; (actual condition).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;positive-focused-sensitivity&#34;&gt;&#xA;  Positive-Focused (Sensitivity)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#positive-focused-sensitivity&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fix actual &lt;strong&gt;Positive&lt;/strong&gt; label.&lt;/li&gt;&#xA;&lt;li&gt;Incorrect prediction: &lt;strong&gt;False Negative (FN)&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Pair: (TP, FN)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sensitivity&lt;/strong&gt; = TP / (TP + FN)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;negative-focused-specificity&#34;&gt;&#xA;  Negative-Focused (Specificity)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#negative-focused-specificity&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fix actual &lt;strong&gt;Negative&lt;/strong&gt; label.&lt;/li&gt;&#xA;&lt;li&gt;Incorrect prediction: &lt;strong&gt;False Positive (FP)&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Pair: (TN, FP)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Specificity&lt;/strong&gt; = TN / (TN + FP)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-outcome-centric-metrics-anchored-on-prediction&#34;&gt;&#xA;  🔸 Outcome-Centric Metrics (Anchored on Prediction)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-outcome-centric-metrics-anchored-on-prediction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Evaluates &lt;strong&gt;usefulness of test result&lt;/strong&gt;, dependent on &lt;strong&gt;both test performance and prevalence&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Anchor: &lt;strong&gt;Test result&lt;/strong&gt; (prediction output).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;positive-focused-ppv--precision&#34;&gt;&#xA;  Positive-Focused (PPV / Precision)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#positive-focused-ppv--precision&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fix &lt;strong&gt;Positive&lt;/strong&gt; prediction.&lt;/li&gt;&#xA;&lt;li&gt;Incorrect prediction: &lt;strong&gt;False Positive (FP)&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Pair: (TP, FP)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Positive Predictive Value (PPV)&lt;/strong&gt; = TP / (TP + FP)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;negative-focused-npv&#34;&gt;&#xA;  Negative-Focused (NPV)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#negative-focused-npv&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fix &lt;strong&gt;Negative&lt;/strong&gt; prediction.&lt;/li&gt;&#xA;&lt;li&gt;Incorrect prediction: &lt;strong&gt;False Negative (FN)&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Pair: (TN, FN)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Negative Predictive Value (NPV)&lt;/strong&gt; = TN / (TN + FN)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-extension-to-roc-and-pr-curves&#34;&gt;&#xA;  📊 Extension to ROC and PR Curves&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-extension-to-roc-and-pr-curves&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-roc-curve-receiver-operating-characteristic&#34;&gt;&#xA;  🎯 ROC Curve (Receiver Operating Characteristic)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-roc-curve-receiver-operating-characteristic&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;what-it-does&#34;&gt;&#xA;  What it does:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#what-it-does&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Plots &lt;strong&gt;True Positive Rate (TPR)&lt;/strong&gt; vs. &lt;strong&gt;False Positive Rate (FPR)&lt;/strong&gt; across thresholds.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;TPR = Sensitivity = TP / (TP + FN)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;FPR = 1 − Specificity = FP / (FP + TN)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;These metrics are calculated by conditioning on the &lt;strong&gt;actual class labels&lt;/strong&gt;, not predictions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;anchoring-view&#34;&gt;&#xA;  Anchoring View:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#anchoring-view&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;✅ &lt;strong&gt;Test-Centric / Condition-Anchored&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Starts from actual condition and evaluates how well the test distinguishes between classes.&lt;/li&gt;&#xA;&lt;li&gt;Independent of class imbalance in its calculation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;use-case&#34;&gt;&#xA;  Use Case:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#use-case&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Suitable when both positive and negative classes are equally important.&lt;/li&gt;&#xA;&lt;li&gt;Can be misleading in &lt;strong&gt;highly imbalanced&lt;/strong&gt; datasets (e.g., rare disease).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;-precision-recall-pr-curve&#34;&gt;&#xA;  📈 Precision-Recall (PR) Curve&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-precision-recall-pr-curve&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;what-it-does-1&#34;&gt;&#xA;  What it does:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#what-it-does-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Plots &lt;strong&gt;Precision (PPV)&lt;/strong&gt; vs. &lt;strong&gt;Recall (Sensitivity)&lt;/strong&gt; across thresholds.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Precision = TP / (TP + FP)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Recall = TP / (TP + FN)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;anchoring-view-1&#34;&gt;&#xA;  Anchoring View:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#anchoring-view-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;✅ &lt;strong&gt;Outcome-Centric / Prediction-Anchored&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Focuses on the model’s &lt;strong&gt;positive predictions&lt;/strong&gt; and how often they are correct.&lt;/li&gt;&#xA;&lt;li&gt;Particularly useful for evaluating performance on the &lt;strong&gt;positive class&lt;/strong&gt; in imbalanced datasets.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;use-case-1&#34;&gt;&#xA;  Use Case:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#use-case-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ideal for problems with &lt;strong&gt;class imbalance&lt;/strong&gt;, where the positive class is rare but important (e.g., cancer detection, fraud, anomaly detection).&lt;/li&gt;&#xA;&lt;li&gt;Answers: “When the model says positive, can I trust it?”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary-of-metric-anchors-and-curve-use&#34;&gt;&#xA;  🧠 Summary of Metric Anchors and Curve Use&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary-of-metric-anchors-and-curve-use&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Curve Type&lt;/th&gt;&#xA;          &lt;th&gt;Metrics Used&lt;/th&gt;&#xA;          &lt;th&gt;Anchored On&lt;/th&gt;&#xA;          &lt;th&gt;Evaluation Focus&lt;/th&gt;&#xA;          &lt;th&gt;Best For&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;ROC&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;TPR (Sensitivity), FPR&lt;/td&gt;&#xA;          &lt;td&gt;Actual condition&lt;/td&gt;&#xA;          &lt;td&gt;Discrimination ability&lt;/td&gt;&#xA;          &lt;td&gt;Balanced class settings&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;PR&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Precision (PPV), Recall&lt;/td&gt;&#xA;          &lt;td&gt;Prediction output&lt;/td&gt;&#xA;          &lt;td&gt;Precision of predictions&lt;/td&gt;&#xA;          &lt;td&gt;Imbalanced settings&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-takeaway&#34;&gt;&#xA;  💡 Takeaway:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-takeaway&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;ROC Curve&lt;/strong&gt; is a &lt;strong&gt;test-centric (condition-anchored)&lt;/strong&gt; tool: great for balanced data, focuses on test performance across thresholds.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;PR Curve&lt;/strong&gt; is an &lt;strong&gt;outcome-centric (prediction-anchored)&lt;/strong&gt; tool: best for imbalanced data, reflects how reliable positive predictions are.&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Ethics in AI for Healthcare</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/ethics_in_ai_healthcare_qna/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/ethics_in_ai_healthcare_qna/</guid>
      <description>&lt;h1 id=&#34;ethics-in-ai-for-healthcare-a-guided-qa-framework&#34;&gt;&#xA;  Ethics in AI for Healthcare: A Guided Q&amp;amp;A Framework&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ethics-in-ai-for-healthcare-a-guided-qa-framework&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document presents a structured chain-of-thought (CoT) using guiding questions and answers to understand ethical considerations in the development and deployment of AI in healthcare, based on Module 7 from the Stanford &amp;ldquo;Introduction to Clinical Data&amp;rdquo; course.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-why-is-ethics-important-in-the-context-of-ai-in-healthcare&#34;&gt;&#xA;  1. Why is ethics important in the context of AI in healthcare?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-is-ethics-important-in-the-context-of-ai-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Answer:&lt;/strong&gt;&lt;br&gt;&#xA;AI tools impact patients directly or indirectly, whether through their development (research) or their deployment (clinical practice). Each of these domains carries different ethical responsibilities that must be considered and governed carefully.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Eval Infra: Verifiable vs Non-Verifiable vs Hybrid</title>
      <link>https://imipark.github.io/ai-workflows/eval/eval_infra/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/eval/eval_infra/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Eval Infra: Verifiable (STEM) vs Non-Verifiable vs Hybrid&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;why-these-5-layers-separation-of-concerns&#34;&gt;&#xA;  Why These 5 Layers? Separation of Concerns&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#why-these-5-layers-separation-of-concerns&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Each layer serves a &lt;strong&gt;distinct purpose&lt;/strong&gt; in the AI evaluation lifecycle, from research to production deployment.&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Layer&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Purpose&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Key Question&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Stakeholder&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Output&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;L1: Benchmark Design&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Define what &amp;ldquo;good&amp;rdquo; means&lt;/td&gt;&#xA;          &lt;td&gt;What are we measuring?&lt;/td&gt;&#xA;          &lt;td&gt;Research Scientists&lt;/td&gt;&#xA;          &lt;td&gt;Test suite + evaluation protocol&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;L2: Evaluation Execution&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Actually measure performance&lt;/td&gt;&#xA;          &lt;td&gt;How do we score it?&lt;/td&gt;&#xA;          &lt;td&gt;ML Engineers&lt;/td&gt;&#xA;          &lt;td&gt;Raw scores/labels per example&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;L3: Scalability&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Handle volume &amp;amp; iteration speed&lt;/td&gt;&#xA;          &lt;td&gt;Can we do this 1000x?&lt;/td&gt;&#xA;          &lt;td&gt;MLOps/Infrastructure&lt;/td&gt;&#xA;          &lt;td&gt;Evaluation pipeline infrastructure&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;L4: Metrics &amp;amp; Reliability&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Trust the measurements&lt;/td&gt;&#xA;          &lt;td&gt;Is this signal real?&lt;/td&gt;&#xA;          &lt;td&gt;Data Scientists, Leadership&lt;/td&gt;&#xA;          &lt;td&gt;Aggregate metrics + confidence intervals&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;L5: Production Monitoring&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Maintain quality in the wild&lt;/td&gt;&#xA;          &lt;td&gt;Is it still working?&lt;/td&gt;&#xA;          &lt;td&gt;SREs, Product Managers&lt;/td&gt;&#xA;          &lt;td&gt;Live dashboards + alerting systems&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;how-layers-map-to-natural-workflow&#34;&gt;&#xA;  How Layers Map to Natural Workflow&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#how-layers-map-to-natural-workflow&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre style=&#34;line-height: 1.0;&#34;&gt;&#xA;RESEARCH PHASE (Offline Development)&#xA;│&#xA;├─ L1: Design Benchmarks&#xA;│   └─ &#34;What constitutes correct/good performance?&#34;&#xA;│&#xA;├─ L2: Run Evaluations  &#xA;│   └─ &#34;Generate responses and score them&#34;&#xA;│&#xA;├─ L3: Scale Infrastructure&#xA;│   └─ &#34;Need to iterate fast → evaluate 10K examples/day&#34;&#xA;│&#xA;└─ L4: Analyze Results&#xA;    └─ &#34;Aggregate metrics, validate reliability&#34;&#xA;&#xA;DEPLOYMENT PHASE (Online Production)&#xA;│&#xA;└─ L5: Monitor Production&#xA;    └─ &#34;Continuous validation, catch regressions&#34;&#xA;    └─ Feed failures back to L1 (closed loop)&#xA;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;different-stakeholders-own-each-layern&#34;&gt;&#xA;  Different Stakeholders Own Each Layern&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#different-stakeholders-own-each-layern&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre style=&#34;line-height: 1.0;&#34;&gt;&#xA;┌─────────────────────────────────────────────────────┐&#xA;│ L1: Research Scientists                             │&#xA;│     → Design evaluation protocols                   │&#xA;│     → Define what &#34;good&#34; means for the domain       │&#xA;└─────────────────────────────────────────────────────┘&#xA;&#xA;┌─────────────────────────────────────────────────────┐&#xA;│ L2: ML Engineers                                    │&#xA;│     → Implement evaluation scripts                  │&#xA;│     → Run model inference + scoring                 │&#xA;└─────────────────────────────────────────────────────┘&#xA;&#xA;┌─────────────────────────────────────────────────────┐&#xA;│ L3: MLOps / Infrastructure Engineers                │&#xA;│     → Build scalable eval pipelines                 │&#xA;│     → Manage compute resources                      │&#xA;└─────────────────────────────────────────────────────┘&#xA;&#xA;┌─────────────────────────────────────────────────────┐&#xA;│ L4: Data Scientists / Research Leadership           │&#xA;│     → Statistical analysis of eval results          │&#xA;│     → Validate metric reliability                   │&#xA;│     → Make deployment decisions                     │&#xA;└─────────────────────────────────────────────────────┘&#xA;&#xA;┌─────────────────────────────────────────────────────┐&#xA;│ L5: SREs / Product Managers                         │&#xA;│     → Monitor production performance                │&#xA;│     → Alert on regressions                          │&#xA;│     → Coordinate incident response                  │&#xA;└─────────────────────────────────────────────────────┘&#xA;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;the-spectrum-of-verifiability&#34;&gt;&#xA;  The Spectrum of Verifiability&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#the-spectrum-of-verifiability&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre style=&#34;line-height: 1.0;&#34;&gt;&#xA;Fully Verifiable ←――――――――――――――――――――――――→ Non-Verifiable&#xA;      │                    │                      │&#xA;   Code/Math          Technical Writing      Creative/Social&#xA;   (external          (hybrid: facts +       (judgment only)&#xA;    oracle)            style/clarity)&#xA;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;examples-by-category&#34;&gt;&#xA;  Examples by Category&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#examples-by-category&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Fully Verifiable&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Hybrid (Partially Verifiable)&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Non-Verifiable&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;• Code execution&lt;/td&gt;&#xA;          &lt;td&gt;• Technical writing (facts ✓, clarity ✗)&lt;/td&gt;&#xA;          &lt;td&gt;• Creative writing&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;• Math computation&lt;/td&gt;&#xA;          &lt;td&gt;• Translation (accuracy ✓, style ✗)&lt;/td&gt;&#xA;          &lt;td&gt;• Persuasive marketing&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;• Logic proofs&lt;/td&gt;&#xA;          &lt;td&gt;• Legal analysis (precedent ✓, judgment ✗)&lt;/td&gt;&#xA;          &lt;td&gt;• Empathetic therapy&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;• Data extraction&lt;/td&gt;&#xA;          &lt;td&gt;• Medical diagnosis (tests ✓, manner ✗)&lt;/td&gt;&#xA;          &lt;td&gt;• Humor generation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;• Fact checking&lt;/td&gt;&#xA;          &lt;td&gt;• Recipe generation (chemistry ✓, taste ✗)&lt;/td&gt;&#xA;          &lt;td&gt;• Art critique&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;• Physics simulation&lt;/td&gt;&#xA;          &lt;td&gt;• Code review (bugs ✓, readability ✗)&lt;/td&gt;&#xA;          &lt;td&gt;• Storytelling&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;layer-1-benchmark-design&#34;&gt;&#xA;  &lt;strong&gt;LAYER 1: BENCHMARK DESIGN&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#layer-1-benchmark-design&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Verifiable (Code/Math/Logic)&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Hybrid (Technical/Professional)&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Non-Verifiable (Creative/Social)&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Structure:&lt;/strong&gt; Problem + Test Suite → Automated Oracle&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Structure:&lt;/strong&gt; Task + Mixed Criteria → Automated + Human&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Structure:&lt;/strong&gt; Prompt + Rubric → Human/AI Judgment&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Key Benchmarks:&lt;/strong&gt;&lt;br&gt;• HumanEval (164 code problems)&lt;br&gt;• MATH (12K competition problems)&lt;br&gt;• GPQA (448 PhD questions)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Key Benchmarks:&lt;/strong&gt;&lt;br&gt;• Technical Writing Quality&lt;br&gt;• Translation (BLEU + human eval)&lt;br&gt;• Medical Q&amp;amp;A (facts + empathy)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Key Benchmarks:&lt;/strong&gt;&lt;br&gt;• MT-Bench (80 conversations)&lt;br&gt;• AlpacaEval (805 prompts)&lt;br&gt;• Chatbot Arena (live voting)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;br&gt;✅ Tests are deterministic&lt;br&gt;✅ Can generate infinite variants&lt;br&gt;✅ No human disagreement&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;br&gt;⚠️ Some aspects objective&lt;br&gt;⚠️ Some aspects subjective&lt;br&gt;⚠️ Requires dual evaluation&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;br&gt;❌ Ratings are subjective&lt;br&gt;❌ Context-dependent quality&lt;br&gt;❌ Humans disagree frequently&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Creation Time:&lt;/strong&gt; 1-2 weeks&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Creation Time:&lt;/strong&gt; 2-3 weeks&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Creation Time:&lt;/strong&gt; 3-4 weeks&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;br&gt;&lt;code&gt;assert reverse([1,2,3]) == [3,2,1]&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;br&gt;Accuracy: Does translation preserve meaning? (✓)&lt;br&gt;Fluency: Does it sound natural? (human)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;br&gt;&amp;ldquo;Is this story engaging?&amp;quot;&lt;br&gt;→ 5-point Likert scale (human)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;layer-2-evaluation-execution&#34;&gt;&#xA;  &lt;strong&gt;LAYER 2: EVALUATION EXECUTION&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#layer-2-evaluation-execution&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Verifiable&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Hybrid&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Non-Verifiable&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Pipeline:&lt;/strong&gt;&lt;br&gt;1. Generate solutions (10 min)&lt;br&gt;2. &lt;strong&gt;Execute &amp;amp; verify (5 min)&lt;/strong&gt;&lt;br&gt;3. Compute metrics (&amp;lt;1 min)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Pipeline:&lt;/strong&gt;&lt;br&gt;1. Generate outputs (10 min)&lt;br&gt;2. &lt;strong&gt;Automated checks (5 min)&lt;/strong&gt;&lt;br&gt;3. &lt;strong&gt;Human evaluation (4-20 hours)&lt;/strong&gt;&lt;br&gt;4. Combine scores (30 min)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Pipeline:&lt;/strong&gt;&lt;br&gt;1. Generate responses (5 min)&lt;br&gt;2. &lt;strong&gt;Human/AI rating (8-40 hours)&lt;/strong&gt;&lt;br&gt;3. Aggregate &amp;amp; validate (1 hour)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Verification:&lt;/strong&gt;&lt;br&gt;&lt;code&gt;python result = execute_code(solution)&amp;lt;br&amp;gt;label = PASS if tests_pass else FAIL&amp;lt;br&amp;gt;&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Verification:&lt;/strong&gt;&lt;br&gt;&lt;code&gt;python # Automated component&amp;lt;br&amp;gt;facts_correct = verify_facts(output)&amp;lt;br&amp;gt;# Human component&amp;lt;br&amp;gt;clarity = human_rate_clarity(output)&amp;lt;br&amp;gt;score = 0.5*facts + 0.5*clarity&amp;lt;br&amp;gt;&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Verification:&lt;/strong&gt;&lt;br&gt;&lt;code&gt;python ratings = get_human_ratings(n=3)&amp;lt;br&amp;gt;score = mean(ratings)&amp;lt;br&amp;gt;# Then validate inter-rater agreement&amp;lt;br&amp;gt;&lt;/code&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Throughput:&lt;/strong&gt; 10K-100K evals/hour&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Throughput:&lt;/strong&gt; 500-5K evals/hour&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Throughput:&lt;/strong&gt; 100-1K evals/hour&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Cost per eval:&lt;/strong&gt; $0.001-0.01&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Cost per eval:&lt;/strong&gt; $0.05-1.00&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Cost per eval:&lt;/strong&gt; $0.10-5.00&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human time:&lt;/strong&gt; 0 hours&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human time:&lt;/strong&gt; 4-20 hours (partial)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human time:&lt;/strong&gt; 24-120 hours (full)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;layer-3-scalability&#34;&gt;&#xA;  &lt;strong&gt;LAYER 3: SCALABILITY&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#layer-3-scalability&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Verifiable&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Hybrid&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Non-Verifiable&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Bottleneck:&lt;/strong&gt; Compute (GPU time)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Bottleneck:&lt;/strong&gt; Human time for subjective parts&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Bottleneck:&lt;/strong&gt; Human bandwidth&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Scaling Examples:&lt;/strong&gt;&lt;br&gt;• 164 problems → $2, 15 min&lt;br&gt;• 10K problems → $122, 2 hours&lt;br&gt;• 100K problems → $1,220, 8 hours&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Scaling Examples:&lt;/strong&gt;&lt;br&gt;• 100 docs → $50, 4 hours&lt;br&gt;• 1K docs → $500, 20 hours&lt;br&gt;• 10K docs → $5K, 200 hours&lt;br&gt;(Mix of automated + human)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Scaling Examples:&lt;/strong&gt;&lt;br&gt;• 80 prompts → $400, 8-40 hours&lt;br&gt;• 10K prompts → $37,500, 2,500 hours&lt;br&gt;• (Or $8K hybrid with AI judges)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human scaling:&lt;/strong&gt; 0 hours regardless of scale&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human scaling:&lt;/strong&gt; Sub-linear (automate what&amp;rsquo;s possible)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human scaling:&lt;/strong&gt; Linear or super-linear&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Constraint:&lt;/strong&gt; Money (buy more GPUs)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Constraint:&lt;/strong&gt; Time + money (human for quality checks)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Constraint:&lt;/strong&gt; Time (recruit, train raters)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Automation:&lt;/strong&gt; 99.9%&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Automation:&lt;/strong&gt; 40-70% (depends on domain)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Automation:&lt;/strong&gt; 5-30% (AI judges need validation)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Scalability Strategy:&lt;/strong&gt;&lt;br&gt;• Parallelize across GPUs&lt;br&gt;• Generate synthetic test cases&lt;br&gt;• Cost scales linearly&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Scalability Strategy:&lt;/strong&gt;&lt;br&gt;• Automate objective criteria&lt;br&gt;• Sample human evaluation (10-20%)&lt;br&gt;• Use AI judges for subjective parts (with validation)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Scalability Strategy:&lt;/strong&gt;&lt;br&gt;• Train reward models on human labels&lt;br&gt;• Use LLM-as-judge (must validate)&lt;br&gt;• Spot-check 5-10% with humans&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;layer-4-metrics--reliability&#34;&gt;&#xA;  &lt;strong&gt;LAYER 4: METRICS &amp;amp; RELIABILITY&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#layer-4-metrics--reliability&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Verifiable&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Hybrid&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Non-Verifiable&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Metrics:&lt;/strong&gt;&lt;br&gt;• pass@k (% solved in k tries)&lt;br&gt;• Compile rate&lt;br&gt;• Exact match accuracy&lt;br&gt;• Error tolerance&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Metrics:&lt;/strong&gt;&lt;br&gt;• Factual accuracy (automated)&lt;br&gt;• Readability score (formula)&lt;br&gt;• Clarity rating (human)&lt;br&gt;• Combined weighted score&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Metrics:&lt;/strong&gt;&lt;br&gt;• Likert scale (1-5 ratings)&lt;br&gt;• Win rate vs baseline&lt;br&gt;• Elo ratings (head-to-head)&lt;br&gt;• Thumbs up/down ratio&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;br&gt;✅ Objective &amp;amp; reproducible&lt;br&gt;✅ Labs can compare directly&lt;br&gt;✅ No gaming (oracle is external)&lt;br&gt;✅ Leaderboards meaningful&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;br&gt;⚠️ Partially objective&lt;br&gt;⚠️ Requires careful weighting&lt;br&gt;⚠️ Some gaming risk on subjective parts&lt;br&gt;⚠️ Need to report both auto + human metrics&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;br&gt;❌ Subjective &amp;amp; noisy&lt;br&gt;❌ Different protocols → incomparable&lt;br&gt;❌ Gaming risk (optimize for judge)&lt;br&gt;❌ Leaderboards have selection bias&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Inter-evaluator agreement:&lt;/strong&gt; 100%&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Inter-evaluator agreement:&lt;/strong&gt;&lt;br&gt;Facts: 95-100%&lt;br&gt;Quality: 70-85%&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Inter-evaluator agreement:&lt;/strong&gt; 60-80%&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Example Metrics:&lt;/strong&gt;&lt;br&gt;• HumanEval pass@1: 67.8%&lt;br&gt;• MATH accuracy: 82.3%&lt;br&gt;• Error rate: 5.2%&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Example Metrics:&lt;/strong&gt;&lt;br&gt;• Translation BLEU: 45.2 (auto)&lt;br&gt;• Fluency: 4.1/5 (human)&lt;br&gt;• Medical accuracy: 94% (auto), Empathy: 3.8/5 (human)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Example Metrics:&lt;/strong&gt;&lt;br&gt;• MT-Bench: 7.9/10 (GPT-4 judge)&lt;br&gt;• Human preference: 78% win rate&lt;br&gt;• Elo rating: 1,245&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;layer-5-production-monitoring&#34;&gt;&#xA;  &lt;strong&gt;LAYER 5: PRODUCTION MONITORING&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#layer-5-production-monitoring&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Verifiable&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Hybrid&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Non-Verifiable&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Real-time signals:&lt;/strong&gt;&lt;br&gt;• Does code compile? ✓/✗&lt;br&gt;• Tests pass? ✓/✗&lt;br&gt;• User accepted? ✓/✗&lt;br&gt;• Execution time OK? ✓/✗&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Real-time signals:&lt;/strong&gt;&lt;br&gt;• Facts verified? ✓/✗&lt;br&gt;• Format correct? ✓/✗&lt;br&gt;• User satisfaction proxy (usage time)&lt;br&gt;• Error rate&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Proxy signals:&lt;/strong&gt;&lt;br&gt;• Thumbs up/down ratio&lt;br&gt;• Session length&lt;br&gt;• Regeneration rate&lt;br&gt;• Response length&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Monitoring:&lt;/strong&gt;&lt;br&gt;• Every request → Automated check&lt;br&gt;• Dashboard updates: Real-time&lt;br&gt;• Regression alerts: Instant&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Monitoring:&lt;/strong&gt;&lt;br&gt;• Automated checks: Real-time&lt;br&gt;• Human spot-checks: Weekly (10% sample)&lt;br&gt;• Combined quality score trending&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Monitoring:&lt;/strong&gt;&lt;br&gt;• Sample 100 conversations/week&lt;br&gt;• 3 humans rate each&lt;br&gt;• Compare to last month&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Action:&lt;/strong&gt;&lt;br&gt;• Compile rate &amp;lt;90% → Auto rollback&lt;br&gt;• Pass@1 drops &amp;gt;5% → Alert engineer&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Action:&lt;/strong&gt;&lt;br&gt;• Fact accuracy &amp;lt;95% → Auto rollback&lt;br&gt;• Quality score drops &amp;gt;0.3 → Investigate&lt;br&gt;• Run deeper human eval if needed&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Action:&lt;/strong&gt;&lt;br&gt;• Quality drops &amp;gt;0.3 → Investigate&lt;br&gt;• A/B test for 7 days&lt;br&gt;• Need human eval to decide&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human role:&lt;/strong&gt; Only when alerts fire&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human role:&lt;/strong&gt; Weekly spot-checks (10%)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human role:&lt;/strong&gt; Continuous (weekly audits)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Dashboard Example:&lt;/strong&gt;&lt;br&gt;Compile Rate: 94.2% 🟢&lt;br&gt;Pass@1: 67.8% 🟢&lt;br&gt;Latency: 1.2s 🟡&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Dashboard Example:&lt;/strong&gt;&lt;br&gt;Fact Check: 96.1% 🟢&lt;br&gt;User Rating: 4.2/5 🟢&lt;br&gt;Clarity (sampled): 3.9/5 🟡&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Dashboard Example:&lt;/strong&gt;&lt;br&gt;Human Rating: 4.2/5 🔴&lt;br&gt;Thumbs Up: 78% 🟢&lt;br&gt;Session Time: 8.2min 🟢&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;each-layer-has-different-bottleneck&#34;&gt;&#xA;  EACH LAYER HAS DIFFERENT BOTTLENECK&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#each-layer-has-different-bottleneck&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Layer&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Verifiable Bottleneck&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Hybrid Bottleneck&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Non-Verifiable Bottleneck&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;L1: Design&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Writing test suite&lt;/td&gt;&#xA;          &lt;td&gt;Defining which parts are verifiable&lt;/td&gt;&#xA;          &lt;td&gt;Getting human agreement on rubric&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;L2: Execute&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;GPU inference time&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human time for quality checks&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Human annotation time&lt;/strong&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;L3: Scale&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Compute budget&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Hiring raters for quality&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Hiring/training many raters&lt;/strong&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;L4: Metrics&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Statistical analysis&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Balancing auto vs human metrics&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Inter-rater reliability&lt;/strong&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;L5: Monitor&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Infrastructure cost&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Continuous spot-checking&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Continuous human auditing&lt;/strong&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;real-world-examples-by-category&#34;&gt;&#xA;  REAL-WORLD EXAMPLES BY CATEGORY&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#real-world-examples-by-category&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Verifiable:&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Foundation Models for Healthcare</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/foundatoin_model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/foundatoin_model/</guid>
      <description>&lt;h2 id=&#34;foundation-models-for-healthcare&#34;&gt;&#xA;  Foundation Models for Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#foundation-models-for-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;what-are-foundation-models&#34;&gt;&#xA;  What are Foundation Models?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#what-are-foundation-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Foundation models are trained on massive amounts of &lt;strong&gt;unlabeled data&lt;/strong&gt; using &lt;strong&gt;self-supervised&lt;/strong&gt; or &lt;strong&gt;unsupervised learning&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;They are &amp;ldquo;foundational&amp;rdquo; because they can be &lt;strong&gt;adapted to multiple downstream tasks&lt;/strong&gt; with high efficiency and minimal data.&lt;/li&gt;&#xA;&lt;li&gt;They demonstrate &lt;strong&gt;sample efficiency&lt;/strong&gt; and can handle multiple modalities like text, images, genomics, etc.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;few-shot-vs-zero-shot-learning&#34;&gt;&#xA;  Few-Shot vs. Zero-Shot Learning&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#few-shot-vs-zero-shot-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Few-Shot Learning&lt;/strong&gt;: Learns from just a few labeled examples per class and generalizes to new examples.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Zero-Shot Learning&lt;/strong&gt;: Learns to perform tasks it hasn’t seen in training, relying on general knowledge from pretraining.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;➡️  These abilities allow foundation models to generalize efficiently across healthcare tasks, even with limited supervision.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Healthcare Data Layers</title>
      <link>https://imipark.github.io/healthcare/data/healthcare_data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/data/healthcare_data/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Healthcare Data Layers&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1--data-sources-raw-data--collection-level&#34;&gt;&#xA;  1️⃣  &lt;strong&gt;Data Sources (Raw Data &amp;amp; Collection Level)&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1--data-sources-raw-data--collection-level&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;These are the foundational data sources used in healthcare analysis, originating from clinical trials, hospitals, insurance claims, and patient records.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Clinical Data (RCTs, EHR, OMOP, CDM)&lt;/strong&gt; – Structured, controlled, and often randomized data used for regulatory and research applications.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Real-World Data (RWD: EHR, Claims, Registries)&lt;/strong&gt; – Observational and confounded, requiring advanced causal inference methods to extract meaningful insights.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Relationship:&lt;/strong&gt; Clinical Data is typically highly structured and standardized, whereas RWD is heterogeneous, requiring bias correction.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2--data-management--standardization-processing--infrastructure-level&#34;&gt;&#xA;  2️⃣  &lt;strong&gt;Data Management &amp;amp; Standardization (Processing &amp;amp; Infrastructure Level)&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2--data-management--standardization-processing--infrastructure-level&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;This layer ensures that raw clinical &amp;amp; real-world data are cleaned, structured, and made interoperable for analysis.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Healthcare Data Sources</title>
      <link>https://imipark.github.io/healthcare/data/healthcare_sources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/data/healthcare_sources/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Healthcare Data Sources&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;phenotype-knowledgebase-phekbhttpswwwphekborg&#34;&gt;&#xA;  &lt;a href=&#34;https://www.phekb.org/&#34;&gt;Phenotype KnowledgeBase (PheKB)&lt;/a&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#phenotype-knowledgebase-phekbhttpswwwphekborg&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;:&lt;br&gt;&#xA;A collaborative portal for sharing and validating electronic phenotype definitions used in observational health research.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Tags&lt;/strong&gt;: &lt;code&gt;phenotyping&lt;/code&gt;, &lt;code&gt;EHR&lt;/code&gt;, &lt;code&gt;cohort definitions&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Standardized phenotype definitions for conditions like diabetes, asthma, etc.&lt;/li&gt;&#xA;&lt;li&gt;Sharing phenotype algorithms across institutions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;mimic-iv-medical-information-mart-for-intensive-carehttpsphysionetorgcontentmimiciv&#34;&gt;&#xA;  &lt;a href=&#34;https://physionet.org/content/mimiciv/&#34;&gt;MIMIC-IV (Medical Information Mart for Intensive Care)&lt;/a&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mimic-iv-medical-information-mart-for-intensive-carehttpsphysionetorgcontentmimiciv&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;:&lt;br&gt;&#xA;A large, publicly available critical care database containing de-identified health data from ICU patients at the Beth Israel Deaconess Medical Center.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Healthcare Use Cases for Non-textual Unstructured Data</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/healthcare_use_cases_for_non_textual_unstructured_data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/healthcare_use_cases_for_non_textual_unstructured_data/</guid>
      <description>&lt;h1 id=&#34;healthcare-use-cases-for-non-textual-unstructured-data&#34;&gt;&#xA;  Healthcare Use Cases for Non-textual Unstructured Data&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#healthcare-use-cases-for-non-textual-unstructured-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-are-foundation-models-limited-to-text&#34;&gt;&#xA;  1. Are foundation models limited to text?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-are-foundation-models-limited-to-text&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;No. Although many early applications focus on text, foundation models are inherently multimodal. They can process and learn from images, audio, video, and other forms of unstructured data without modifying the core model.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-what-kind-of-unstructured-data-exists-in-healthcare-beyond-text&#34;&gt;&#xA;  2. What kind of unstructured data exists in healthcare beyond text?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-kind-of-unstructured-data-exists-in-healthcare-beyond-text&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Medical images&lt;/strong&gt;: X-rays, CT, MRI&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Audio data&lt;/strong&gt;: Patient speech, clinical voice notes&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Video data&lt;/strong&gt;: Endoscopy, movement assessments&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Digital pathology&lt;/strong&gt; and &lt;strong&gt;genomic data&lt;/strong&gt;: High-resolution slides and sequence strings&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;3-how-do-image-text-foundation-models-work-in-healthcare&#34;&gt;&#xA;  3. How do image-text foundation models work in healthcare?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-how-do-image-text-foundation-models-work-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;They learn from &lt;strong&gt;paired image and text data&lt;/strong&gt; (e.g., medical images and associated reports) to understand content holistically. This allows for better diagnostic performance and contextual understanding than single-modality models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Healthcare Use Cases for Text Data</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/healthcare_use_cases_for_text_data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/healthcare_use_cases_for_text_data/</guid>
      <description>&lt;h1 id=&#34;healthcare-use-cases-for-text-data&#34;&gt;&#xA;  Healthcare Use Cases for Text Data&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#healthcare-use-cases-for-text-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-can-large-language-models-like-chatgpt-perform-at-a-physician-level&#34;&gt;&#xA;  1. Can large language models like ChatGPT perform at a physician level?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-can-large-language-models-like-chatgpt-perform-at-a-physician-level&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Yes. ChatGPT has demonstrated performance comparable to expert physicians on tasks like the USMLE medical board exam. This raises important questions about the evolving role of human expertise in healthcare as LLMs continue to advance.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-should-llms-be-integrated-into-medical-training-or-exams&#34;&gt;&#xA;  2. Should LLMs be integrated into medical training or exams?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-should-llms-be-integrated-into-medical-training-or-exams&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Possibly. LLMs could enhance the medical licensing exam process by reflecting real-world clinical scenarios. However, it&amp;rsquo;s essential for healthcare professionals to understand their benefits and limitations before full integration.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How Foundation Models Work</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/how_foundation_models_work_in_healthcare_applications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/how_foundation_models_work_in_healthcare_applications/</guid>
      <description>&lt;h1 id=&#34;how-foundation-models-work-in-healthcare-applications&#34;&gt;&#xA;  How Foundation Models Work (in Healthcare Applications)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#how-foundation-models-work-in-healthcare-applications&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-what-are-foundation-models-and-why-are-large-language-models-llms-a-key-example&#34;&gt;&#xA;  1. What are foundation models and why are large language models (LLMs) a key example?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-what-are-foundation-models-and-why-are-large-language-models-llms-a-key-example&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Foundation models are large-scale machine learning models trained on vast and diverse datasets, enabling them to perform well across multiple tasks. Large Language Models (LLMs) like GPT are a major class of these, powering tools like ChatGPT and being early, widely successful examples.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-what-architecture-do-foundation-models-especially-llms-rely-on&#34;&gt;&#xA;  2. What architecture do foundation models, especially LLMs, rely on?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-architecture-do-foundation-models-especially-llms-rely-on&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;They rely heavily on the &lt;strong&gt;Transformer architecture&lt;/strong&gt;, introduced in the paper &lt;em&gt;“Attention Is All You Need”&lt;/em&gt;. This architecture uses &lt;strong&gt;self-attention&lt;/strong&gt; mechanisms to allow models to learn relationships across sequences of data, making them highly effective for tasks involving language and other sequential data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Use BERT&#39;s CLS Token for Classification</title>
      <link>https://imipark.github.io/ai-workflows/genai/bert_cls_classification_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/bert_cls_classification_summary/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;How to Use BERT&#39;s CLS Token for Classification&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-question&#34;&gt;&#xA;  ❓ Question&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-question&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;How can we use the &lt;code&gt;[CLS]&lt;/code&gt; token (i.e., &lt;code&gt;h_cls&lt;/code&gt;) from the last layer of BERT for classification tasks? Given that the BERT output has shape &lt;code&gt;[batch_size, sequence_length, hidden_size]&lt;/code&gt;, how is it valid to pass only &lt;code&gt;[batch_size, hidden_size]&lt;/code&gt; to a &lt;code&gt;nn.Linear(hidden_size, num_classes)&lt;/code&gt; without flattening the sequence? And why don&amp;rsquo;t we flatten the whole sequence — wouldn&amp;rsquo;t that destroy order?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Inputs and Data Preparation for Multimodal LLMs</title>
      <link>https://imipark.github.io/ai-workflows/genai/multimodel_llms/data_prep/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/multimodel_llms/data_prep/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Inputs and Data Preparation for Multimodal LLMs&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Multimodal LLMs are language models that can process and reason over &lt;strong&gt;multiple data types&lt;/strong&gt;, especially:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Text&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;(Optionally: audio, video, or other modalities)&lt;/em&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;They are designed to understand &lt;strong&gt;both visual and linguistic context&lt;/strong&gt;, enabling tasks like visual question answering, image captioning, grounding, and perception-based reasoning.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;---input-format&#34;&gt;&#xA;  🖼️ + 💬 Input Format&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#---input-format&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Inputs typically include:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Image(s)&lt;/strong&gt;: RGB images, optionally annotated (e.g., bounding boxes, circles)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Text Prompt&lt;/strong&gt;: Task instruction or question (e.g., &amp;ldquo;Which object is closer?&amp;rdquo;)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Answer Choices&lt;/strong&gt; (optional): For classification-style tasks like BLINK&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;inputs &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;images&amp;#34;&lt;/span&gt;: [&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;...&lt;/span&gt;],   &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# preprocessed (resized, normalized) tensors or raw image paths&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Which point is closer to the camera? (A) A (B) B&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Some APIs accept JSON-style mixed prompts with interleaved text and image tokens.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Missing Data Scenarios in Healthcare Modeling</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/missing_values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/missing_values/</guid>
      <description>&lt;h1 id=&#34;missing-data-scenarios-in-healthcare-modeling&#34;&gt;&#xA;  Missing Data Scenarios in Healthcare Modeling&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#missing-data-scenarios-in-healthcare-modeling&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-should-be-measured-but-wasnt&#34;&gt;&#xA;  1. Should Be Measured But Wasn’t&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-should-be-measured-but-wasnt&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: The value is expected but is missing due to random or procedural issues (e.g., lab error, missed test).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Technical Term&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;MCAR&lt;/strong&gt;: Missing Completely At Random&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MAR&lt;/strong&gt;: Missing At Random&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: A routine blood test wasn&amp;rsquo;t recorded because the sample was lost.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Impute (mean, median, or model-based).&lt;/li&gt;&#xA;&lt;li&gt;Add a missingness indicator variable (e.g., &lt;code&gt;var_missing = 1&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: The missingness is unrelated to the value itself, so estimation is relatively safe.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-mostly-zero-due-to-rare-occurrence&#34;&gt;&#xA;  2. Mostly Zero Due to Rare Occurrence&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-mostly-zero-due-to-rare-occurrence&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: Not truly missing — the value is &lt;strong&gt;zero or absent&lt;/strong&gt; for most patients because the condition/event is rare.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Technical Term&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Not Missing (No abbreviation needed)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: HIV diagnosis column is &lt;code&gt;0&lt;/code&gt; for most patients.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Do not impute&lt;/strong&gt; — the 0s are meaningful and reflect true absence.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: These are real values, and zeros carry clinical meaning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;3-deliberately-not-recorded&#34;&gt;&#xA;  3. Deliberately Not Recorded&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-deliberately-not-recorded&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: Clinician or system &lt;strong&gt;chooses not to record&lt;/strong&gt; a value based on context (e.g., patient clearly stable or too ill).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Technical Term&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;MNAR&lt;/strong&gt;: Missing Not At Random&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: Sodium level not tested because the patient was clearly stable.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Avoid imputation if possible — it may introduce bias.&lt;/li&gt;&#xA;&lt;li&gt;Use models that handle missingness natively (e.g., decision trees, XGBoost, LightGBM).&lt;/li&gt;&#xA;&lt;li&gt;Consider adding a missingness indicator.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: The missingness &lt;em&gt;depends on the unobserved value&lt;/em&gt; and may carry predictive signal.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;summary-table&#34;&gt;&#xA;  Summary Table&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#summary-table&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Case&lt;/th&gt;&#xA;          &lt;th&gt;Description&lt;/th&gt;&#xA;          &lt;th&gt;Abbreviation&lt;/th&gt;&#xA;          &lt;th&gt;Impute?&lt;/th&gt;&#xA;          &lt;th&gt;Extra Notes&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;Should be measured but wasn’t&lt;/td&gt;&#xA;          &lt;td&gt;MCAR / MAR&lt;/td&gt;&#xA;          &lt;td&gt;✅ Yes&lt;/td&gt;&#xA;          &lt;td&gt;Add indicator if signal is likely&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;Mostly zero (rare condition)&lt;/td&gt;&#xA;          &lt;td&gt;Not Missing&lt;/td&gt;&#xA;          &lt;td&gt;🚫 No&lt;/td&gt;&#xA;          &lt;td&gt;Keep as is — zeros are informative&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;          &lt;td&gt;Deliberately not recorded&lt;/td&gt;&#xA;          &lt;td&gt;MNAR&lt;/td&gt;&#xA;          &lt;td&gt;⚠️ Caution&lt;/td&gt;&#xA;          &lt;td&gt;Use native handling + possible indicator&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Neo4j GDS (Graph Data Science) vs. Core Neo4j (Cypher)</title>
      <link>https://imipark.github.io/ai-workflows/reasoning/graph-reasoning/knowledge-graphs/gds_vs_cypher/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/reasoning/graph-reasoning/knowledge-graphs/gds_vs_cypher/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Neo4j GDS (Graph Data Science) vs. Core Neo4j (Cypher) &#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-purpose-comparison&#34;&gt;&#xA;  1. Purpose Comparison&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-purpose-comparison&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Aspect&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Neo4j (Cypher)&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;GDS (Graph Data Science)&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Primary Purpose&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Transactional queries, CRUD operations&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Graph analytics, algorithms, machine learning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Execution&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Works directly on disk database&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Projects optimized graph into memory&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Speed&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Good for pattern match and retrieval&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Fast for graph-wide computations&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Scale&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Suited for operational systems&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Handles millions-billions of nodes/relationships&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Isolation&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Operates on live data&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Safe, read-only in-memory graphs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Flexibility&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Good for flexible queries&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Pre-built scalable algorithms (PageRank, Louvain, etc.)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Optimization&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Query optimization on indexes&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Memory-efficient subgraph projection&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Persistence&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Directly modifies database (unless read-only)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Results can stay in memory or optionally write back&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;2-summary-flow-of-gds-workflow&#34;&gt;&#xA;  2. Summary Flow of GDS Workflow&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-summary-flow-of-gds-workflow&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Step&lt;/th&gt;&#xA;          &lt;th&gt;Cypher Call&lt;/th&gt;&#xA;          &lt;th&gt;Purpose&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;① Project Graph&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;gds.graph.project&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Create an in-memory optimized graph&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;② List Graphs&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;gds.graph.list&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Manage in-memory graph catalog&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;③ Run Algorithm (Mutate)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;gds.pageRank.mutate&lt;/code&gt;, &lt;code&gt;gds.degree.mutate&lt;/code&gt;, etc.&lt;/td&gt;&#xA;          &lt;td&gt;Compute and store properties in memory&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;④ Stream Results&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;gds.graph.nodeProperties.stream&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Retrieve computed properties&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;⑤ (Optional) Write to DB&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;gds.pageRank.write&lt;/code&gt;, etc.&lt;/td&gt;&#xA;          &lt;td&gt;Persist computed results to database&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;⑥ Drop Graph&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;gds.graph.drop&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Free memory by deleting in-memory graphs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;// Neo4j GDS Flow Diagram&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;+----------------+   +-----------------------+   +----------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;| Neo4j Database |==&amp;gt;|  GDS Graph Projection |==&amp;gt;|  Graph Catalog       |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;| (Stored Nodes, |   |  (In-Memory Subgraph) |   | (Manage In-Memory    |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|  Relationships)|   |                       |   |  Graphs: List, Drop) |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;+----------------+   +-----------------------+   +----------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                           ||&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                           ||&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                           \/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 +---------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 |   GDS Algorithms    |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 |  (PageRank,         |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 |  Community Detect., |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 |  Similarity, ML)    |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 +---------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                           ||&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                           ||&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                           \/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 +---------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 |      Results        |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 | (Mutate, Write back,|&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 |  Stream to client)  |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                 +---------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3-example-gds-workflow-code-snippet-impossible-by-cypher-alone&#34;&gt;&#xA;  3. Example: GDS Workflow Code Snippet (Impossible by Cypher Alone)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-example-gds-workflow-code-snippet-impossible-by-cypher-alone&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cypher&#34; data-lang=&#34;cypher&#34;&gt;// Project graph into memory&#xA;CALL gds.graph.project(&#xA;  &amp;#39;friends-graph&amp;#39;,&#xA;  &amp;#39;Person&amp;#39;,&#xA;  &amp;#39;FRIEND&amp;#39;&#xA;);&#xA;&#xA;// Run PageRank algorithm and store scores in memory&#xA;CALL gds.pageRank.mutate(&#xA;  &amp;#39;friends-graph&amp;#39;,&#xA;  { mutateProperty: &amp;#39;pageRankScore&amp;#39; }&#xA;);&#xA;&#xA;// Stream top PageRank results&#xA;CALL gds.graph.nodeProperties.stream(&#xA;  &amp;#39;friends-graph&amp;#39;,&#xA;  [&amp;#39;pageRankScore&amp;#39;]&#xA;)&#xA;YIELD nodeId, propertyValue&#xA;RETURN gds.util.asNode(nodeId).name AS personName, propertyValue AS pageRankScore&#xA;ORDER BY pageRankScore DESC&#xA;LIMIT 10;&#xA;&#xA;// Clean up memory&#xA;CALL gds.graph.drop(&amp;#39;friends-graph&amp;#39;);&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;&#xA;&lt;p&gt;🚀 This full in-memory graph analysis flow &lt;strong&gt;cannot be achieved&lt;/strong&gt; using Cypher alone.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OMOP vs. RLHF</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/omop_vs_rlhf_comparison/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/omop_vs_rlhf_comparison/</guid>
      <description>&lt;h1 id=&#34;omop-vs-rlhf-a-side-by-side-comparison&#34;&gt;&#xA;  OMOP vs. RLHF: A Side-by-Side Comparison&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#omop-vs-rlhf-a-side-by-side-comparison&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document compares &lt;strong&gt;OMOP (Observational Medical Outcomes Partnership)&lt;/strong&gt; in healthcare with &lt;strong&gt;RLHF (Reinforcement Learning from Human Feedback)&lt;/strong&gt; in generative AI, focusing on their structures, purposes, and alignment with Learning Health System (LHS) principles.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary-table&#34;&gt;&#xA;  🔍 Summary Table&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary-table&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Aspect&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;OMOP (Healthcare)&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;RLHF (GenAI)&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Domain&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Clinical/healthcare data&lt;/td&gt;&#xA;          &lt;td&gt;Natural language modeling&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Purpose&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Standardize and structure real-world patient data for learning, analytics, and AI&lt;/td&gt;&#xA;          &lt;td&gt;Align AI model behavior with human preferences and values&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Core Process&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;ETL (Extract-Transform-Load) clinical data into a common format for analysis&lt;/td&gt;&#xA;          &lt;td&gt;Fine-tune a pretrained LLM using human-labeled preferences or rewards&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Data Source&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;EHRs, claims, labs, devices&lt;/td&gt;&#xA;          &lt;td&gt;Human judgments on AI-generated outputs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Feedback Type&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Structured medical events (diagnoses, drugs, labs, etc.)&lt;/td&gt;&#xA;          &lt;td&gt;Human preference signals on outputs (better/worse answers)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Learning Method&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Enables observational &amp;amp; causal learning from patient data&lt;/td&gt;&#xA;          &lt;td&gt;Reinforcement learning from ranked or scored examples&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Governance Layer&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Ethics via IRB, consent, privacy laws&lt;/td&gt;&#xA;          &lt;td&gt;Ethics via safety research, alignment goals, red-teaming&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Use in Feedback Loops&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;LHS uses OMOP to “learn from care to improve care”&lt;/td&gt;&#xA;          &lt;td&gt;RLHF uses feedback to “teach the model to behave better”&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-conceptual-analogy&#34;&gt;&#xA;  🔁 Conceptual Analogy&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-conceptual-analogy&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;OMOP + Learning Health System (LHS)&lt;/strong&gt; is to the health system&lt;br&gt;&#xA;as&lt;br&gt;&#xA;&lt;strong&gt;RLHF&lt;/strong&gt; is to a generative AI model.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Output-Action Pairing (OAP) Framework in Healthcare</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/oap_framework_healthcare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/oap_framework_healthcare/</guid>
      <description>&lt;h1 id=&#34;-output-action-pairing-oap-framework-in-healthcare&#34;&gt;&#xA;  🧠 Output-Action Pairing (OAP) Framework in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-output-action-pairing-oap-framework-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide provides real-world examples of the Output-Action Pairing (OAP) framework: aligning machine learning model &lt;strong&gt;outputs&lt;/strong&gt; with &lt;strong&gt;concrete clinical actions&lt;/strong&gt; to improve care.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-oap-template&#34;&gt;&#xA;  📋 OAP Template&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-oap-template&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Output (Prediction)&lt;/th&gt;&#xA;          &lt;th&gt;Action Taken&lt;/th&gt;&#xA;          &lt;th&gt;Who Acts&lt;/th&gt;&#xA;          &lt;th&gt;Why It Helps&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;What the model predicts&lt;/td&gt;&#xA;          &lt;td&gt;The clinical step or decision triggered&lt;/td&gt;&#xA;          &lt;td&gt;The role/team responsible&lt;/td&gt;&#xA;          &lt;td&gt;How it improves outcomes or safety&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-real-world-examples&#34;&gt;&#xA;  ✅ Real-World Examples&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-real-world-examples&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-sepsis-prediction&#34;&gt;&#xA;  1. Sepsis Prediction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-sepsis-prediction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; High risk of sepsis in next 6 hours&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Alert care team, initiate fluids/labs/antibiotics&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Rapid response team (nurses + physicians)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Early treatment improves survival&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2-readmission-risk-score&#34;&gt;&#xA;  2. Readmission Risk Score&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-readmission-risk-score&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; 30% chance of readmission within 30 days&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Extra discharge planning, follow-up calls, medication check&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Care coordinator + pharmacist&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Reduces avoidable readmissions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;3-pneumothorax-detection-on-chest-x-ray&#34;&gt;&#xA;  3. Pneumothorax Detection on Chest X-ray&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-pneumothorax-detection-on-chest-x-ray&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; Pneumothorax detected&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Immediate flag to radiologist and ER for review&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Radiologist + ER team&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Enables life-saving chest tube intervention&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;4-covid-19-triage&#34;&gt;&#xA;  4. COVID-19 Triage&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#4-covid-19-triage&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; High risk of severe COVID progression&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; ICU evaluation, enhanced monitoring, begin treatment&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Hospitalist or ICU triage physician&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Allocates ICU resources effectively&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;5-fall-risk-in-hospital&#34;&gt;&#xA;  5. Fall Risk in Hospital&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#5-fall-risk-in-hospital&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; High fall risk during admission&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Enable fall precautions (alarms, sitter, etc.)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Nursing team&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Prevents injury and hospital complications&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;6-stroke-detection-via-ct&#34;&gt;&#xA;  6. Stroke Detection via CT&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#6-stroke-detection-via-ct&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; Acute stroke suspected on scan&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Notify neurologist, activate stroke protocol (tPA window)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Radiologist + Stroke Response Team&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Reduces time to brain-saving treatment&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary&#34;&gt;&#xA;  🔄 Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The OAP framework ensures that ML predictions &lt;strong&gt;translate to action&lt;/strong&gt;, improving &lt;strong&gt;clinical relevance&lt;/strong&gt; and &lt;strong&gt;patient safety&lt;/strong&gt;. Every model in healthcare should answer:&lt;/p&gt;</description>
    </item>
    <item>
      <title>PPO in LLMs vs PPO in Walker2D</title>
      <link>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ppo_comparison/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ppo_comparison/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;🤖🦿 Understanding PPO: From Language Generation to Robot Control — Code, Concepts, and Comparisons&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Proximal Policy Optimization (PPO)&lt;/strong&gt; in both large language models (LLMs, e.g., GPT-style) and classical control environments (e.g., Walker2D), focusing on the structure of the PPO update and how actions are selected during inference.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1--ppo-step-call--argument-by-argument-breakdown&#34;&gt;&#xA;  1. 🧾 PPO &lt;code&gt;step()&lt;/code&gt; Call — Argument-by-Argument Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1--ppo-step-call--argument-by-argument-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ppo_trainer&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;step(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    queries&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;[input_ids[&lt;span style=&#34;color:#fe640b&#34;&gt;0&lt;/span&gt;]],       &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Prompt (tokenized) — represents the current state&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    responses&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;[response_ids[&lt;span style=&#34;color:#fe640b&#34;&gt;0&lt;/span&gt;]],  &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Generated tokens — represents the action taken&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    rewards&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;[reward]              &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Scalar from reward model — score for that action&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;mapping-to-classic-rl-walker2d&#34;&gt;&#xA;  Mapping to Classic RL (Walker2D)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mapping-to-classic-rl-walker2d&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;PPO Argument&lt;/th&gt;&#xA;          &lt;th&gt;🤖 LLM (RLHF)&lt;/th&gt;&#xA;          &lt;th&gt;🦿 Walker2D (Classic RL)&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;code&gt;queries = [input_ids[0]]&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Prompt as input (discrete tokenized state)&lt;/td&gt;&#xA;          &lt;td&gt;Robot&amp;rsquo;s continuous state (joint angles, velocities)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;code&gt;responses = [response_ids[0]]&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Generated tokens (sequence of actions)&lt;/td&gt;&#xA;          &lt;td&gt;Applied joint torques (vector of real numbers)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;code&gt;rewards = [reward]&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Reward model output (alignment score)&lt;/td&gt;&#xA;          &lt;td&gt;Environment reward (e.g., distance walked)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2--action-selection-in-ppo&#34;&gt;&#xA;  2. 🎯 Action Selection in PPO&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2--action-selection-in-ppo&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;How does the agent choose its next action, given a state/prompt?&lt;/p&gt;</description>
    </item>
    <item>
      <title>PPO vs DPO in RLHF</title>
      <link>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ppo_vs_dpo_comparison/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/ppo_vs_dpo_comparison/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;PPO vs DPO in RLHF&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;div style=&#34;display: grid; grid-template-columns: 1fr 1fr; gap: 20px;&#34;&gt;&#xA;&lt;div&gt;&#xA;&lt;h3 id=&#34;ppo-traditional-rlhf&#34;&gt;&#xA;  PPO (Traditional RLHF)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ppo-traditional-rlhf&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;core-concept&#34;&gt;&#xA;  Core Concept&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#core-concept&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&amp;ldquo;Let me &lt;strong&gt;generate new text&lt;/strong&gt;, score it with the reward model, and update my policy based on those scores.&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h4 id=&#34;pipeline&#34;&gt;&#xA;  Pipeline&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#pipeline&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Step 1: Train Reward Model (Ch7)&#xA;   Preference Data → Reward Model&#xA;   &#xA;Step 2: RL Optimization (Ch11)&#xA;   Policy generates text → RM scores it &#xA;   → PPO updates policy&#xA;   (Repeat with new generations)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;chapter-flow&#34;&gt;&#xA;  Chapter Flow&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#chapter-flow&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Ch6 (Preference Data)&#xA;    ↓&#xA;Ch7 (Reward Model Training)&#xA;    ↓&#xA;Ch11 (PPO RL Optimization)&#xA;    ↓&#xA;Final Model&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;example-code&#34;&gt;&#xA;  Example Code&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#example-code&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# PPO Training Loop&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8839ef&#34;&gt;for&lt;/span&gt; batch &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; prompts:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Generate NEW responses&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    responses &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; policy&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;generate(batch)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Score with reward model&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    rewards &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; reward_model(responses)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Compute advantages&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    advantages &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; compute_advantages(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        rewards, values&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    )&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Update with PPO&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    policy&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;update_with_ppo(advantages)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;the-math&#34;&gt;&#xA;  The Math&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#the-math&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;J(θ) = E[min(ratio * A, &#xA;             clip(ratio, 1-ε, 1+ε) * A)] &#xA;       - β * D_KL(π || π_ref)&#xA;&#xA;Where:&#xA;- ratio = π_θ(a|s) / π_old(a|s)&#xA;- A = advantage&#xA;- clip prevents large updates&#xA;- D_KL = distance from reference&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;pros&#34;&gt;&#xA;  Pros&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#pros&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;✅ &lt;strong&gt;Online learning&lt;/strong&gt;: Discover new responses&lt;/li&gt;&#xA;&lt;li&gt;✅ &lt;strong&gt;Best performance&lt;/strong&gt;: Highest quality&lt;/li&gt;&#xA;&lt;li&gt;✅ &lt;strong&gt;Adaptive&lt;/strong&gt;: Uses current policy&lt;/li&gt;&#xA;&lt;li&gt;✅ &lt;strong&gt;Proven&lt;/strong&gt;: ChatGPT, Claude, etc.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;cons&#34;&gt;&#xA;  Cons&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#cons&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;❌ &lt;strong&gt;Complex&lt;/strong&gt;: RM + value + PPO&lt;/li&gt;&#xA;&lt;li&gt;❌ &lt;strong&gt;Expensive&lt;/strong&gt;: Multiple models&lt;/li&gt;&#xA;&lt;li&gt;❌ &lt;strong&gt;High memory&lt;/strong&gt;: RM + policy + ref&lt;/li&gt;&#xA;&lt;li&gt;❌ &lt;strong&gt;Hard to tune&lt;/strong&gt;: Many hyperparameters&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;best-for&#34;&gt;&#xA;  Best For&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#best-for&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🎯 Maximum performance&lt;/li&gt;&#xA;&lt;li&gt;🎯 Large compute budgets&lt;/li&gt;&#xA;&lt;li&gt;🎯 Frontier models&lt;/li&gt;&#xA;&lt;li&gt;🎯 Continuous improvement&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;examples&#34;&gt;&#xA;  Examples&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#examples&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ChatGPT (OpenAI)&lt;/li&gt;&#xA;&lt;li&gt;Claude (Anthropic)&lt;/li&gt;&#xA;&lt;li&gt;InstructGPT (OpenAI)&lt;/li&gt;&#xA;&lt;li&gt;DeepSeek R1&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div&gt;&#xA;&lt;h3 id=&#34;dpo-direct-alignment&#34;&gt;&#xA;  DPO (Direct Alignment)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#dpo-direct-alignment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;core-concept-1&#34;&gt;&#xA;  Core Concept&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#core-concept-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&amp;ldquo;Let me &lt;strong&gt;directly learn&lt;/strong&gt; from the preference data without generating anything new.&amp;rdquo;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Rule-Based Electronic Phenotyping Example: Type 2 Diabetes</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/diabetes_phenotype_pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/diabetes_phenotype_pipeline/</guid>
      <description>&lt;h1 id=&#34;rule-based-electronic-phenotyping-example-type-2-diabetes&#34;&gt;&#xA;  Rule-Based Electronic Phenotyping Example: Type 2 Diabetes&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#rule-based-electronic-phenotyping-example-type-2-diabetes&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This notebook walks through the process of defining an &lt;strong&gt;electronic phenotype&lt;/strong&gt; using a &lt;strong&gt;rule-based&lt;/strong&gt; approach, with a focus on &lt;strong&gt;Type 2 Diabetes&lt;/strong&gt;. The pipeline includes concept mapping, multi-patient evaluation, and phenotype logic visualization.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-1-simulated-vocabulary-lookup-umls--omop&#34;&gt;&#xA;  🔹 Step 1: Simulated Vocabulary Lookup (UMLS / OMOP)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-1-simulated-vocabulary-lookup-umls--omop&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;We define the clinical concept (Type 2 Diabetes) using relevant ICD-10 and RxNorm codes.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Simulated UMLS/OMOP vocab mapping&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;UMLS_LOOKUP &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;type2_diabetes&amp;#34;&lt;/span&gt;: {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;icd10&amp;#34;&lt;/span&gt;: {&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;E11.9&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;E11.65&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;E11.00&amp;#34;&lt;/span&gt;},&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;rxnorm&amp;#34;&lt;/span&gt;: {&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;metformin&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;insulin&amp;#34;&lt;/span&gt;},&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-2-multi-patient-phenotyping-logic&#34;&gt;&#xA;  🔹 Step 2: Multi-Patient Phenotyping Logic&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-2-multi-patient-phenotyping-logic&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Each patient is checked for:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Self-Attention in Transformers: A Visual Breakdown</title>
      <link>https://imipark.github.io/ai-workflows/genai/self_attention_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/self_attention_summary/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Self-Attention in Transformers: A Visual Breakdown&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;This document summarizes key questions about self-attention, embedding vectors, positions, and the input matrix in Transformers — using the image you provided as the foundation.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-what-is-happening-in-the-diagram&#34;&gt;&#xA;  🧠 What Is Happening in the Diagram?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-what-is-happening-in-the-diagram&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The figure shows how &lt;strong&gt;self-attention&lt;/strong&gt; computes the output for a specific position (&amp;ldquo;detection&amp;rdquo;) by:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Generating &lt;strong&gt;attention weights&lt;/strong&gt; between that position and &lt;strong&gt;all other positions&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Using those weights to compute a &lt;strong&gt;weighted sum&lt;/strong&gt; of the input feature vectors.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://imipark.github.io/images/attention.png&#34; alt=&#34;Self-Attention Diagram&#34; /&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Single GPUT (RTX4090) RLHF Training Pipeline w/ TRL</title>
      <link>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/instruct_gpt_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/instruct_gpt_architecture/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Single GPUT (RTX4090) RLHF Training Pipeline w/ TRL&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;pre style=&#34;line-height: 1.0;&#34;&gt;&#xA;┌─────────────────────────────────────────────────────────────────┐&#xA;│                    Anthropic/hh-rlhf Dataset                    │&#xA;│  160k examples with &#34;chosen&#34; and &#34;rejected&#34; responses           │&#xA;└──────────────┬────────────────────────┬─────────────────────────┘&#xA;               │                        │&#xA;               │ &#34;chosen&#34; only          │ preference pairs&#xA;               │ (20k subset)           │ (50k subset)&#xA;               ↓                        │&#xA;┌──────────────────────────────────┐    │&#xA;│   meta-llama/Llama-2-7b-hf       │    │&#xA;│   (4-bit quantized base)         │    │&#xA;└──────────────┬───────────────────┘    │&#xA;               ↓                        │&#xA;┌──────────────────────────────────────────────────┐&#xA;│              STEP 1: SFT Training                │&#xA;│  ┌────────────────────────────────────────────┐  │&#xA;│  │ Input:  &#34;chosen&#34; responses (20k)           │  │&#xA;│  │ Loss:   Cross-entropy on completions       │  │&#xA;│  │ Metric: Perplexity → 3.3-4.5               │  │&#xA;│  │ Memory: 18-20 GB                           │  │&#xA;│  │ Time:   2-4 hours                          │  │&#xA;│  └────────────────────────────────────────────┘  │&#xA;└──────────────┬───────────────────────────────────┘&#xA;               ↓&#xA;       ┌───────────────┐&#xA;       │  SFT Model    │ (~50 MB LoRA adapters)&#xA;       └───────┬───────┘&#xA;               │&#xA;       ┌───────┴────────────────┬─────────────────┐&#xA;       │                        │                 │&#xA;       ↓                        ↓                 ↓&#xA;┌──────────────────┐   ┌─────────────────┐   ┌──────────────┐&#xA;│ Policy (PPO)     │   │ Reference (PPO) │   │ RM Base      │&#xA;│ +value head      │   │ frozen copy     │   │ +reward head │&#xA;│ trainable        │   │ for KL penalty  │   │              │&#xA;└──────┬───────────┘   └────────┬────────┘   └──────┬───────┘&#xA;       │                        │                   │ + pairs (50k)&#xA;       │                        │                   ↓&#xA;       │                        │         ┌─────────────────────────────┐&#xA;       │                        │         │  STEP 2: Reward Model       │&#xA;       │                        │         │  ┌────────────────────────┐ │&#xA;       │                        │         │  │ Input:  Pairs (50k)    │ │&#xA;       │                        │         │  │ Loss:   Ranking loss   │ │&#xA;       │                        │         │  │ Metric: Accuracy &gt;70%  │ │&#xA;       │                        │         │  │ Memory: 20-22 GB       │ │&#xA;       │                        │         │  │ Time:   3-6 hours      │ │&#xA;       │                        │         │  └────────────────────────┘ │&#xA;       │                        │         └──────────┬──────────────────┘&#xA;       │                        │                    ↓&#xA;       │                        │              ┌──────────────┐&#xA;       │                        │              │ Reward Model │ (frozen scorer)&#xA;       │                        │              └──────┬───────┘&#xA;       │                        │                     │&#xA;       └────────────────────────┴─────────────────────┘&#xA;                                │&#xA;                + prompts (20k) │&#xA;                                ↓&#xA;       ┌────────────────────────────────────────────────┐&#xA;       │         STEP 3: PPO RLHF Optimization          │&#xA;       │  ┌──────────────────────────────────────────┐  │&#xA;       │  │ Input:  Prompts (20k)                    │  │&#xA;       │  │         Policy + Reference + RM          │  │&#xA;       │  │ Loss:   PPO clipped + KL penalty         │  │&#xA;       │  │ Metric: Mean reward ↑, KL 0.1-0.3        │  │&#xA;       │  │ Memory: 22-24 GB                         │  │&#xA;       │  │ Time:   6-12 hours                       │  │&#xA;       │  │ Loop:   1000 PPO steps                   │  │&#xA;       │  └──────────────────────────────────────────┘  │&#xA;       └───────────────────────┬────────────────────────┘&#xA;                               ↓&#xA;                    ┌─────────────────────┐&#xA;                    │  Final RLHF Model   │&#xA;                    │  (LoRA adapters)    │&#xA;                    └─────────────────────┘&#xA;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;memory-usage-breakdown-rtx-4090---24-gb&#34;&gt;&#xA;  Memory Usage Breakdown (RTX 4090 - 24 GB)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#memory-usage-breakdown-rtx-4090---24-gb&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Component                  Memory      Notes&#xA;────────────────────────────────────────────────────────────&#xA;Base Model (4-bit)         ~3.5 GB    Llama-2-7B in NF4&#xA;LoRA Adapters              ~0.05 GB   r=16, small footprint&#xA;Optimizer States           ~8-10 GB   Paged AdamW 8-bit&#xA;Activations                ~6-8 GB    With gradient checkpointing&#xA;KV Cache (PPO generation)  ~2-4 GB    During generation phase&#xA;────────────────────────────────────────────────────────────&#xA;Total                      18-24 GB   Fits on RTX 4090!&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;training-metrics-timeline&#34;&gt;&#xA;  Training Metrics Timeline&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#training-metrics-timeline&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre style=&#34;line-height: 1.0;&#34;&gt;&#xA;                SFT                    RM                    PPO&#xA;Time:       0h────4h              4h────10h            10h────22h&#xA;            │                     │                    │&#xA;Loss:       2.5 → 1.2            0.69 → 0.35           -&#xA;Perplexity: 12 → 3.3             -                     -&#xA;Accuracy:   -                    50% → 72%             -&#xA;Reward:     -                    -                     +2 → +8&#xA;KL:         -                    -                     0.05 → 0.25&#xA;            │                     │                    │&#xA;Output:     SFT Model ────────────→ Reward Model ─────→ RLHF Model&#xA;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;key-relationships&#34;&gt;&#xA;  Key Relationships&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#key-relationships&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;SFT → RM&lt;/strong&gt;: Warm start (better initialization than random)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SFT → Policy&lt;/strong&gt;: Direct inheritance (then optimized)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SFT → Reference&lt;/strong&gt;: Frozen copy (anchor for KL penalty)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RM → PPO&lt;/strong&gt;: Provides reward signal (quality score)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;loss-functions&#34;&gt;&#xA;  Loss Functions&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#loss-functions&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;SFT Loss:&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Complete InstructGPT Recipe (Ch 4.2.1)</title>
      <link>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/instruct_gpt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/rlhf/rlhf2006/instruct_gpt/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;The Complete Instruct_GPT Recipe (Ch 4.2.1)&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;h3 id=&#34;sequential-and-two-separate-datasets-for-rlhf&#34;&gt;&#xA;  Sequential and Two Separate Datasets for RLHF&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#sequential-and-two-separate-datasets-for-rlhf&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Attribute&lt;/th&gt;&#xA;          &lt;th&gt;Dataset 1: comes 1st&lt;/th&gt;&#xA;          &lt;th&gt;Dataset 2: comes next&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Size&lt;/td&gt;&#xA;          &lt;td&gt;~10K examples (InstructGPT), ~1M modern&lt;/td&gt;&#xA;          &lt;td&gt;~100K preference pairs (InstructGPT)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Format&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;(prompt, good_response)&lt;/code&gt; - SINGLE examples&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;(prompt, chosen, rejected)&lt;/code&gt; - PAIRWISE comparisons&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Source&lt;/td&gt;&#xA;          &lt;td&gt;Human-written OR synthetic from strong models&lt;/td&gt;&#xA;          &lt;td&gt;Human labelers comparing SFT model outputs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Purpose&lt;/td&gt;&#xA;          &lt;td&gt;Teach the model HOW TO RESPOND in chat format&lt;/td&gt;&#xA;          &lt;td&gt;Teach what GOOD vs BAD responses look like&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;When Collected&lt;/td&gt;&#xA;          &lt;td&gt;BEFORE preference data collection&lt;/td&gt;&#xA;          &lt;td&gt;AFTER SFT model exists (use SFT to generate responses)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Used to Train&lt;/td&gt;&#xA;          &lt;td&gt;SFT Model (Ch9)&lt;/td&gt;&#xA;          &lt;td&gt;Reward Model (Ch7)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Example&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;{ &amp;quot;prompt&amp;quot;: &amp;quot;What is machine learning?&amp;quot;, &amp;quot;response&amp;quot;: &amp;quot;Machine learning is a branch of AI that...&amp;quot; }&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;code&gt;{&amp;quot;prompt&amp;quot;: &amp;quot;What is machine learning?&amp;quot;, &amp;quot;chosen&amp;quot;: &amp;quot;Machine learning is a branch of AI that enables...&amp;quot;, &amp;quot;rejected&amp;quot;: &amp;quot;ML is when computers learn stuff.&amp;quot; }&lt;/code&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;when-to-prepare-1st-and-2nd-dataset&#34;&gt;&#xA;  when to prepare 1st and 2nd dataset&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#when-to-prepare-1st-and-2nd-dataset&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre style=&#34;line-height: 1.0;&#34;&gt;&#xA;         ┌──────────┐&#xA;         │  Ch9 SFT │← FIRST: Prepare SFT data&#xA;         └───┬──────┘&#xA;             │&#xA;             ↓&#xA;      [Train SFT Model]&#xA;             │&#xA;             ├──────────────┐&#xA;             ↓              ↓&#xA;      ┌────────┐     Generate responses&#xA;      │ Use in │     for humans to compare&#xA;      │  Ch7   │            │&#xA;      │  RM    │            ↓&#xA;      └───┬────┘     ┌──────────────┐&#xA;          │          │Ch6 Pref Data │← SECOND: Collect preferences&#xA;          │          └───┬──────────┘&#xA;          │              │&#xA;          ↓              ↓&#xA;         Ch7 RM         Use RM in Ch11&#xA;          │              │&#xA;          └──────┬───────┘&#xA;                 ↓&#xA;               Ch11 RL(PPO)&#xA;&lt;/pre&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;the-complete-instructgpt-recipe-ch-421&#34;&gt;&#xA;  The Complete InstructGPT Recipe (Ch 4.2.1)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#the-complete-instructgpt-recipe-ch-421&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre style=&#34;line-height: 1.0;&#34;&gt;&#xA;┌─────────────────────────────────────────────────────────┐&#xA;│                    Pretrained Base Model                │&#xA;└──────────────────────┬──────────────────────────────────┘&#xA;                       │&#xA;                       ↓&#xA;┌────────────────────────────────────────────────────────┐&#xA;│  STEP 1: Ch9 SFT                                       │&#xA;│  • Prepare single good examples                        │&#xA;│  • Train model on (prompt, response) pairs             │&#xA;│  • Output: SFT Model (can generate responses)          │&#xA;└──────────────────────┬─────────────────────────────────┘&#xA;                       │&#xA;                       ├──────────────────┐&#xA;                       ↓                  ↓&#xA;┌──────────────────────────────┐  ┌─────────────────────┐&#xA;│  STEP 2a: Ch6 Data Collection│  │ STEP 2b: Ch7 RM     │&#xA;│  • Use SFT to generate       │  │ • Start from SFT    │&#xA;│  • Humans compare outputs    │─→│ • Train on Ch6 data │&#xA;│  • Create preference pairs   │  │ • Output: RM        │&#xA;└──────────────────────────────┘  └──────────┬──────────┘&#xA;                                             │&#xA;                       ┌─────────────────────┘&#xA;                       ↓&#xA;┌────────────────────────────────────────────────────────┐&#xA;│  STEP 3: Ch11 RL Optimization                          │&#xA;│  • Policy: SFT Model (from Step 1)                     │&#xA;│  • Scorer: Reward Model (from Step 2)                  │&#xA;│  • Optimize policy using RM feedback                   │&#xA;│  • Output: Final RLHF-trained Model                    │&#xA;└────────────────────────────────────────────────────────┘&#xA;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Tradeoffs in Machine Learning: Precision vs. Recall in Healthcare</title>
      <link>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/precision_vs_recall_in_healthcare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/precision_vs_recall_in_healthcare/</guid>
      <description>&lt;h1 id=&#34;tradeoffs-in-machine-learning-precision-vs-recall-in-healthcare&#34;&gt;&#xA;  Tradeoffs in Machine Learning: Precision vs. Recall in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#tradeoffs-in-machine-learning-precision-vs-recall-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide summarizes two key scenarios in healthcare where we might prefer:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;High Precision but Lower Recall&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;High Recall but Lower Precision&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-high-precision-lower-recall&#34;&gt;&#xA;  (1) High Precision, Lower Recall&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-high-precision-lower-recall&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-when-to-use&#34;&gt;&#xA;  ✅ When to Use:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-when-to-use&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When &lt;strong&gt;false positives are costly or harmful&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;When &lt;strong&gt;resources are limited&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;In &lt;strong&gt;early screening/filtering stages&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-justification&#34;&gt;&#xA;  📌 Justification:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-justification&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You want to be &lt;strong&gt;very confident&lt;/strong&gt; before taking action.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Missing some real cases&lt;/strong&gt; is acceptable if &lt;strong&gt;wrongly flagging someone&lt;/strong&gt; leads to &lt;strong&gt;emotional, financial, or clinical harm&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-examples&#34;&gt;&#xA;  💡 Examples:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-examples&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Genetic Testing for Rare Diseases&lt;/strong&gt;: Only flag patients when you&amp;rsquo;re very sure. A false positive could cause unnecessary panic or life changes.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;ICU Bed Allocation&lt;/strong&gt;: If you only have 5 beds, you’d want to use them for patients who are most certainly critical.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Drug Discovery Pre-Screening&lt;/strong&gt;: Select molecules that are most likely to work, even if some potential candidates are missed.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-high-recall-lower-precision&#34;&gt;&#xA;  (2) High Recall, Lower Precision&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-high-recall-lower-precision&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-when-to-use-1&#34;&gt;&#xA;  ✅ When to Use:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-when-to-use-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When &lt;strong&gt;missing a real case is dangerous&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;When &lt;strong&gt;early detection can improve outcomes&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;When &lt;strong&gt;follow-up tests or actions are safe and cheap&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-justification-1&#34;&gt;&#xA;  📌 Justification:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-justification-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It&amp;rsquo;s better to &lt;strong&gt;catch every possible case&lt;/strong&gt;, even if you have some false alarms.&lt;/li&gt;&#xA;&lt;li&gt;Especially important in &lt;strong&gt;serious or rapidly progressing conditions&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-examples-1&#34;&gt;&#xA;  💡 Examples:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-examples-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cancer Screening&lt;/strong&gt;: Better to flag more patients for follow-up than miss someone with early-stage cancer.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sepsis Prediction in ER&lt;/strong&gt;: Alerting the care team early—even with some false alarms—can save lives.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;COVID-19 Testing in High-Risk Areas&lt;/strong&gt;: Broad detection to prevent spread, even if some healthy people test positive.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary-table&#34;&gt;&#xA;  🧠 Summary Table&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary-table&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Scenario&lt;/th&gt;&#xA;          &lt;th&gt;Priority&lt;/th&gt;&#xA;          &lt;th&gt;Justification&lt;/th&gt;&#xA;          &lt;th&gt;Example&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;High Precision, Lower Recall&lt;/td&gt;&#xA;          &lt;td&gt;Precision 🟢&lt;/td&gt;&#xA;          &lt;td&gt;Avoid harm/cost from false positives&lt;/td&gt;&#xA;          &lt;td&gt;Genetic testing, ICU triage&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;High Recall, Lower Precision&lt;/td&gt;&#xA;          &lt;td&gt;Recall 🟢&lt;/td&gt;&#xA;          &lt;td&gt;Avoid missing critical or contagious conditions&lt;/td&gt;&#xA;          &lt;td&gt;Cancer screening, sepsis alert&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Traditional Data Science vs AI Data Science (Model-Centric)</title>
      <link>https://imipark.github.io/ai-workflows/eval/traditional_vs_ai_data_science/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/eval/traditional_vs_ai_data_science/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Traditional Data Science vs AI Data Science (Model-Centric)&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;mental-reset--workflow-shift&#34;&gt;&#xA;  Mental Reset &amp;amp; Workflow Shift&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mental-reset--workflow-shift&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Traditional data science&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Analyzes a stable world&lt;/li&gt;&#xA;&lt;li&gt;Collect → Clean → Model → Validate → Deploy&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;AI data science&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Measures and shapes a moving, self-modifying system.&lt;/li&gt;&#xA;&lt;li&gt;Hypothesis → Design probe → Stress / compare → Analyze failure distribution → Translate to training signal → Repeat&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;side-by-side-comparison&#34;&gt;&#xA;  Side-by-Side Comparison&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#side-by-side-comparison&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Dimension&lt;/th&gt;&#xA;          &lt;th&gt;Traditional Data Science&lt;/th&gt;&#xA;          &lt;th&gt;AI Data Science (Model-Centric)&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Data distribution&lt;/td&gt;&#xA;          &lt;td&gt;Mostly stationary&lt;/td&gt;&#xA;          &lt;td&gt;Strongly non-stationary&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Object of study&lt;/td&gt;&#xA;          &lt;td&gt;External systems (users, markets)&lt;/td&gt;&#xA;          &lt;td&gt;The model itself&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Errors&lt;/td&gt;&#xA;          &lt;td&gt;Mostly independent (noise)&lt;/td&gt;&#xA;          &lt;td&gt;Highly correlated (structure)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Metrics&lt;/td&gt;&#xA;          &lt;td&gt;Scalar, aggregate&lt;/td&gt;&#xA;          &lt;td&gt;Diagnostic, process-level&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Ground truth&lt;/td&gt;&#xA;          &lt;td&gt;Well-defined labels&lt;/td&gt;&#xA;          &lt;td&gt;Often ambiguous / constructed&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Feedback loop&lt;/td&gt;&#xA;          &lt;td&gt;Slow, indirect&lt;/td&gt;&#xA;          &lt;td&gt;Fast, tight, training-coupled&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Rare events&lt;/td&gt;&#xA;          &lt;td&gt;Often ignorable&lt;/td&gt;&#xA;          &lt;td&gt;Often highest-signal&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Evaluation goal&lt;/td&gt;&#xA;          &lt;td&gt;Optimize performance&lt;/td&gt;&#xA;          &lt;td&gt;Shape behavior &amp;amp; alignment&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Data generation&lt;/td&gt;&#xA;          &lt;td&gt;Observational&lt;/td&gt;&#xA;          &lt;td&gt;Experimental, adversarial&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Time horizon&lt;/td&gt;&#xA;          &lt;td&gt;Retrospective&lt;/td&gt;&#xA;          &lt;td&gt;Predictive, anticipatory&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;key-differences--implications&#34;&gt;&#xA;  Key Differences → Implications&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#key-differences--implications&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Aspect&lt;/th&gt;&#xA;          &lt;th&gt;Traditional DS&lt;/th&gt;&#xA;          &lt;th&gt;AI DS&lt;/th&gt;&#xA;          &lt;th&gt;Practical Implication&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Distribution shift&lt;/td&gt;&#xA;          &lt;td&gt;Exception&lt;/td&gt;&#xA;          &lt;td&gt;Default&lt;/td&gt;&#xA;          &lt;td&gt;Averages don’t predict the future&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Data source&lt;/td&gt;&#xA;          &lt;td&gt;World → data&lt;/td&gt;&#xA;          &lt;td&gt;Model → data&lt;/td&gt;&#xA;          &lt;td&gt;Evaluation is an intervention&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Error structure&lt;/td&gt;&#xA;          &lt;td&gt;Random noise&lt;/td&gt;&#xA;          &lt;td&gt;Clustered failures&lt;/td&gt;&#xA;          &lt;td&gt;One failure implies many&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Rarity&lt;/td&gt;&#xA;          &lt;td&gt;Low priority&lt;/td&gt;&#xA;          &lt;td&gt;High signal&lt;/td&gt;&#xA;          &lt;td&gt;Diagnose, don’t ignore&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Correctness&lt;/td&gt;&#xA;          &lt;td&gt;Given&lt;/td&gt;&#xA;          &lt;td&gt;Schema-defined&lt;/td&gt;&#xA;          &lt;td&gt;Label design is critical&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Metrics&lt;/td&gt;&#xA;          &lt;td&gt;Descriptive&lt;/td&gt;&#xA;          &lt;td&gt;Prescriptive&lt;/td&gt;&#xA;          &lt;td&gt;Bad metrics → bad models&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Outcome vs process&lt;/td&gt;&#xA;          &lt;td&gt;Outcome-focused&lt;/td&gt;&#xA;          &lt;td&gt;Process-focused&lt;/td&gt;&#xA;          &lt;td&gt;Right answer ≠ right reasoning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Evaluation style&lt;/td&gt;&#xA;          &lt;td&gt;Observational&lt;/td&gt;&#xA;          &lt;td&gt;Experimental&lt;/td&gt;&#xA;          &lt;td&gt;Probing is mandatory&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;final-takeaway&#34;&gt;&#xA;  Final takeaway&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#final-takeaway&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Traditional data science measures the world; AI data science measures and shapes a system that is itself evolving.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformer Attention: Full Conceptual Breakdown</title>
      <link>https://imipark.github.io/ai-workflows/genai/transformer_attention_concepts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/genai/transformer_attention_concepts/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Transformer Attention: Full Conceptual Breakdown&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;This document summarizes an in-depth discussion on attention mechanisms in Transformers, with a special focus on vocabulary embeddings, Q/K/V matrices, and multi-head attention.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-1-understanding-the-self-attention-image&#34;&gt;&#xA;  📌 1. Understanding the Self-Attention Image&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-1-understanding-the-self-attention-image&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The image shows a &lt;strong&gt;single-head self-attention&lt;/strong&gt; computation.&lt;/li&gt;&#xA;&lt;li&gt;Each &lt;strong&gt;row&lt;/strong&gt; is a token (element) at a &lt;strong&gt;position&lt;/strong&gt;, with a feature vector (embedding).&lt;/li&gt;&#xA;&lt;li&gt;The &lt;strong&gt;attention weights&lt;/strong&gt; (left column) are used to compute a &lt;strong&gt;weighted sum&lt;/strong&gt; over these vectors.&lt;/li&gt;&#xA;&lt;li&gt;The final output vector is shown at the bottom — this is the attention output for one token.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-2-element-vs-position&#34;&gt;&#xA;  🔍 2. Element vs. Position&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-2-element-vs-position&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Element&lt;/strong&gt;: the actual word or token in the input sequence.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Position&lt;/strong&gt;: the index of the element in the sequence.&lt;/li&gt;&#xA;&lt;li&gt;Though tightly coupled (1:1), they are conceptually different.&lt;/li&gt;&#xA;&lt;li&gt;Transformers rely on &lt;strong&gt;positional encoding&lt;/strong&gt; to retain order, since attention alone is orderless.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-3-how-attention-scores-are-computed&#34;&gt;&#xA;  🤖 3. How Attention Scores Are Computed&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-3-how-attention-scores-are-computed&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Input embeddings X&lt;/strong&gt; are projected into:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why Clinical NLP &amp; GenAI Are Growing in Healthcare</title>
      <link>https://imipark.github.io/healthcare/clinical_ai/why_clinical_ai/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare/clinical_ai/why_clinical_ai/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;https://imipark.github.io/images/AIR_logo.png&#34; alt=&#34;AI Reasoning Logo&#34; width=&#34;200&#34;/&gt;&#xA;&lt;strong style=&#34;font-size:1.4rem; color:#374151; display:block; margin-bottom:0.8rem; text-transform:uppercase; letter-spacing:0.0rem;&#34;&gt;&#xA;Why Clinical NLP &amp; GenAI Are Growing in Healthcare&#xA;&lt;/strong&gt;&#xA;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Clinical NLP &amp;amp; GenAI are &lt;strong&gt;growing rapidly in healthcare&lt;/strong&gt; because they unlock massive &lt;strong&gt;untapped value in unstructured data&lt;/strong&gt; — which has historically been hard to use, yet contains the &lt;strong&gt;richest clinical context&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-80-of-clinical-data-is-unstructured&#34;&gt;&#xA;  1. 80% of Clinical Data is Unstructured&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-80-of-clinical-data-is-unstructured&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;EHRs are full of &lt;strong&gt;free-text clinical notes&lt;/strong&gt;, discharge summaries, radiology reports, operative notes, etc.&lt;/li&gt;&#xA;&lt;li&gt;Traditional models work well with structured data (ICD, labs), but &lt;strong&gt;miss context&lt;/strong&gt; like:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;“Patient denies chest pain”&lt;/li&gt;&#xA;&lt;li&gt;“Family history of diabetes”&lt;/li&gt;&#xA;&lt;li&gt;“Patient expressed concern about medication side effects”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;NLP allows us to extract &lt;strong&gt;clinical meaning&lt;/strong&gt; from this text and turn it into computable features.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
