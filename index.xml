<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI Reasoning</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on AI Reasoning</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[ToC] Course 2</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/toc_course2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/toc_course2/</guid>
      <description>&lt;h2 id=&#34;toc-of-course-25-introduction-to-clinical-data&#34;&gt;&#xA;  ToC of Course 2/5: Introduction to Clinical Data&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#toc-of-course-25-introduction-to-clinical-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-1-asking-and-answering-questions-via-clinical-data-mining&#34;&gt;&#xA;  Module 1: Asking and Answering Questions via Clinical Data Mining&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-1-asking-and-answering-questions-via-clinical-data-mining&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to the data mining workflow&lt;/li&gt;&#xA;&lt;li&gt;Real Life Example&lt;/li&gt;&#xA;&lt;li&gt;Example: Finding similar patients&lt;/li&gt;&#xA;&lt;li&gt;Example: Estimating risk&lt;/li&gt;&#xA;&lt;li&gt;Putting patient data on timeline&lt;/li&gt;&#xA;&lt;li&gt;Revisit the data mining workflow steps&lt;/li&gt;&#xA;&lt;li&gt;Types of research questions&lt;/li&gt;&#xA;&lt;li&gt;Research questions suited for clinical data&lt;/li&gt;&#xA;&lt;li&gt;Example: making decision to treat&lt;/li&gt;&#xA;&lt;li&gt;Properties that make answering a research question useful&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-2-data-available-from-healthcare-systems&#34;&gt;&#xA;  Module 2: Data Available from Healthcare Systems&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-2-data-available-from-healthcare-systems&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Review of the healthcare system&lt;/li&gt;&#xA;&lt;li&gt;Review of key entities and the data they collect&lt;/li&gt;&#xA;&lt;li&gt;Actors with different interests&lt;/li&gt;&#xA;&lt;li&gt;Common data types in Healthcare&lt;/li&gt;&#xA;&lt;li&gt;Strengths and weaknesses of observational data&lt;/li&gt;&#xA;&lt;li&gt;Bias and error from the healthcare system perspective&lt;/li&gt;&#xA;&lt;li&gt;Bias and error of exposures and outcomes&lt;/li&gt;&#xA;&lt;li&gt;How a patient&amp;rsquo;s exposure might be misclassified&lt;/li&gt;&#xA;&lt;li&gt;How a patient&amp;rsquo;s outcome could be misclassified&lt;/li&gt;&#xA;&lt;li&gt;Electronic medical record data&lt;/li&gt;&#xA;&lt;li&gt;Claims data&lt;/li&gt;&#xA;&lt;li&gt;Pharmacy&lt;/li&gt;&#xA;&lt;li&gt;Surveillance datasets and Registries&lt;/li&gt;&#xA;&lt;li&gt;Population health data sets&lt;/li&gt;&#xA;&lt;li&gt;A framework to assess if a data source is useful&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-3-representing-time-and-timing-of-events-for-clinical-data-mining&#34;&gt;&#xA;  Module 3: Representing Time, and Timing of Events, for Clinical Data Mining&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-3-representing-time-and-timing-of-events-for-clinical-data-mining&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction&lt;/li&gt;&#xA;&lt;li&gt;Time, timelines, timescales and representations of time&lt;/li&gt;&#xA;&lt;li&gt;Timescale: Choosing the relevant units of time&lt;/li&gt;&#xA;&lt;li&gt;What affects the timescale&lt;/li&gt;&#xA;&lt;li&gt;Representation of time&lt;/li&gt;&#xA;&lt;li&gt;Time series and non-time series data&lt;/li&gt;&#xA;&lt;li&gt;Order of events&lt;/li&gt;&#xA;&lt;li&gt;Implicit representations of time&lt;/li&gt;&#xA;&lt;li&gt;Different ways to put data in bins&lt;/li&gt;&#xA;&lt;li&gt;Timing of exposures and outcomes&lt;/li&gt;&#xA;&lt;li&gt;Clinical processes are non-stationary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-4-creating-analysis-ready-datasets-from-patient-timelines&#34;&gt;&#xA;  Module 4: Creating Analysis Ready Datasets from Patient Timelines&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-4-creating-analysis-ready-datasets-from-patient-timelines&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Turning clinical data into something you can analyze&lt;/li&gt;&#xA;&lt;li&gt;Defining the unit of analysis&lt;/li&gt;&#xA;&lt;li&gt;Using features and the presence of features&lt;/li&gt;&#xA;&lt;li&gt;How to create features from structured sources&lt;/li&gt;&#xA;&lt;li&gt;Standardizing features&lt;/li&gt;&#xA;&lt;li&gt;Dealing with too many features&lt;/li&gt;&#xA;&lt;li&gt;The origins of missing values&lt;/li&gt;&#xA;&lt;li&gt;Dealing with missing values&lt;/li&gt;&#xA;&lt;li&gt;Summary recommendations for missing values&lt;/li&gt;&#xA;&lt;li&gt;Constructing new features&lt;/li&gt;&#xA;&lt;li&gt;Examples of engineered features&lt;/li&gt;&#xA;&lt;li&gt;When to consider engineered features&lt;/li&gt;&#xA;&lt;li&gt;Main points about creating analysis ready datasets&lt;/li&gt;&#xA;&lt;li&gt;Structured knowledge graphs&lt;/li&gt;&#xA;&lt;li&gt;So what exactly is in a knowledge graph&lt;/li&gt;&#xA;&lt;li&gt;What are important knowledge graphs&lt;/li&gt;&#xA;&lt;li&gt;How to choose which knowledge graph to use&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-5-handling-unstructured-healthcare-data-text-images-signals&#34;&gt;&#xA;  Module 5: Handling Unstructured Healthcare Data: Text, Images, Signals&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-5-handling-unstructured-healthcare-data-text-images-signals&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to unstructured data&lt;/li&gt;&#xA;&lt;li&gt;What is clinical text&lt;/li&gt;&#xA;&lt;li&gt;The value of clinical text&lt;/li&gt;&#xA;&lt;li&gt;What makes clinical text difficult to handle&lt;/li&gt;&#xA;&lt;li&gt;Privacy and de-identification&lt;/li&gt;&#xA;&lt;li&gt;A primer on Natural Language Processing&lt;/li&gt;&#xA;&lt;li&gt;Practical approach to processing clinical text&lt;/li&gt;&#xA;&lt;li&gt;Summary - Clinical text&lt;/li&gt;&#xA;&lt;li&gt;Overview and goals of medical imaging&lt;/li&gt;&#xA;&lt;li&gt;Why are images important?&lt;/li&gt;&#xA;&lt;li&gt;What are images?&lt;/li&gt;&#xA;&lt;li&gt;A typical image management process&lt;/li&gt;&#xA;&lt;li&gt;Summary - Images&lt;/li&gt;&#xA;&lt;li&gt;Overview of biomedical signals&lt;/li&gt;&#xA;&lt;li&gt;Why are signals important?&lt;/li&gt;&#xA;&lt;li&gt;What are signals?&lt;/li&gt;&#xA;&lt;li&gt;What are the major issues with using signals?&lt;/li&gt;&#xA;&lt;li&gt;Summary - Signals&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-6-putting-the-pieces-together-electronic-phenotyping&#34;&gt;&#xA;  Module 6: Putting the Pieces Together: Electronic Phenotyping&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-6-putting-the-pieces-together-electronic-phenotyping&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to electronic phenotyping&lt;/li&gt;&#xA;&lt;li&gt;Challenges in electronic phenotyping&lt;/li&gt;&#xA;&lt;li&gt;Specifying an electronic phenotype&lt;/li&gt;&#xA;&lt;li&gt;Two approaches to phenotyping&lt;/li&gt;&#xA;&lt;li&gt;Rule-based electronic phenotyping&lt;/li&gt;&#xA;&lt;li&gt;Examples of rule based electronic phenotype definitions&lt;/li&gt;&#xA;&lt;li&gt;Constructing a rule based phenotype definition&lt;/li&gt;&#xA;&lt;li&gt;Probabilistic phenotyping&lt;/li&gt;&#xA;&lt;li&gt;Approaches for creating a probabilistic phenotype definition&lt;/li&gt;&#xA;&lt;li&gt;Software for probabilistic phenotype definitions&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-7-ethics&#34;&gt;&#xA;  Module 7: Ethics&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-7-ethics&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to Research Ethics and AI&lt;/li&gt;&#xA;&lt;li&gt;The Belmont Report: A Framework for Research Ethics&lt;/li&gt;&#xA;&lt;li&gt;Ethical Issues in Data sources for AI&lt;/li&gt;&#xA;&lt;li&gt;Secondary Uses of Data&lt;/li&gt;&#xA;&lt;li&gt;Return of Results&lt;/li&gt;&#xA;&lt;li&gt;AI and The Learning Health System&lt;/li&gt;&#xA;&lt;li&gt;Ethics Summary&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>[ToC] Course 3</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/toc_course3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/toc_course3/</guid>
      <description>&lt;h2 id=&#34;toc-of-course-35-fundamentals-of-machine-learning-for-healthcare&#34;&gt;&#xA;  ToC of Course 3/5: Fundamentals of Machine Learning for Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#toc-of-course-35-fundamentals-of-machine-learning-for-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;module-3-concepts-and-principles-of-machine-learning-in-healthcare&#34;&gt;&#xA;  Module 3: Concepts and Principles of Machine Learning in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-3-concepts-and-principles-of-machine-learning-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to Deep Learning and Neural Networks&lt;/li&gt;&#xA;&lt;li&gt;Deep Learning and Neural Networks&lt;/li&gt;&#xA;&lt;li&gt;Cross Entropy Loss&lt;/li&gt;&#xA;&lt;li&gt;Gradient Descent&lt;/li&gt;&#xA;&lt;li&gt;Representing Unstructured Image and Text Data&lt;/li&gt;&#xA;&lt;li&gt;Convolutional Neural Networks&lt;/li&gt;&#xA;&lt;li&gt;Natural Language Processing and Recurrent Neural Networks&lt;/li&gt;&#xA;&lt;li&gt;The Transformer Architecture for Sequences&lt;/li&gt;&#xA;&lt;li&gt;Commonly Used and Advanced Neural Network Architectures&lt;/li&gt;&#xA;&lt;li&gt;Advanced Computer Vision Tasks and Wrap-Up&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-4-evaluation-and-metrics-for-machine-learning-in-healthcare&#34;&gt;&#xA;  Module 4: Evaluation and Metrics for Machine Learning in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-4-evaluation-and-metrics-for-machine-learning-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to Model Performance Evaluation&lt;/li&gt;&#xA;&lt;li&gt;Overfitting and Underfitting&lt;/li&gt;&#xA;&lt;li&gt;Strategies to Address Overfitting, Underfitting and Introduction to Regularization&lt;/li&gt;&#xA;&lt;li&gt;Statistical Approaches to Model Evaluation&lt;/li&gt;&#xA;&lt;li&gt;Receiver Operator and Precision Recall Curves as Evaluation Metrics&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-5-strategies-and-challenges-in-machine-learning-in-healthcare&#34;&gt;&#xA;  Module 5: Strategies and Challenges in Machine Learning in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-5-strategies-and-challenges-in-machine-learning-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to Common Clinical Machine Learning Challenges&lt;/li&gt;&#xA;&lt;li&gt;Utility of Causative Model Predictions&lt;/li&gt;&#xA;&lt;li&gt;Context in Clinical Machine Learning&lt;/li&gt;&#xA;&lt;li&gt;Intrinsic Interpretability&lt;/li&gt;&#xA;&lt;li&gt;Medical Data Challenges in Machine Learning Part 1&lt;/li&gt;&#xA;&lt;li&gt;Medical Data Challenges in Machine Learning Part 2&lt;/li&gt;&#xA;&lt;li&gt;How Much Data Do We Need?&lt;/li&gt;&#xA;&lt;li&gt;Retrospective Data in Medicine and &amp;ldquo;Shelf Life&amp;rdquo; for Data&lt;/li&gt;&#xA;&lt;li&gt;Medical Data: Quality vs Quantity&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-6-best-practices-teams-and-launching-your-machine-learning-journey&#34;&gt;&#xA;  Module 6: Best Practices, Teams, and Launching Your Machine Learning Journey&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-6-best-practices-teams-and-launching-your-machine-learning-journey&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Clinical Utility and Output Action Pairing&lt;/li&gt;&#xA;&lt;li&gt;Taking Action - Utilizing the OAP Framework&lt;/li&gt;&#xA;&lt;li&gt;Building Multidisciplinary Teams for Clinical Machine Learning&lt;/li&gt;&#xA;&lt;li&gt;Governance, Ethics, and Best Practices&lt;/li&gt;&#xA;&lt;li&gt;On Being Human in the Era of Clinical Machine Learning&lt;/li&gt;&#xA;&lt;li&gt;Death by GPS and Other Lessons of Automation Bias&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-7-foundation-models&#34;&gt;&#xA;  Module 7: Foundation Models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-7-foundation-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction to Foundation Models&lt;/li&gt;&#xA;&lt;li&gt;Adapting to Technology&lt;/li&gt;&#xA;&lt;li&gt;General AI and Emergent Behavior&lt;/li&gt;&#xA;&lt;li&gt;How Foundation Models Work&lt;/li&gt;&#xA;&lt;li&gt;Healthcare Use Cases for Text Data&lt;/li&gt;&#xA;&lt;li&gt;Healthcare Use Cases for Non-textual Unstructured Data&lt;/li&gt;&#xA;&lt;li&gt;Challenges and Pitfalls&lt;/li&gt;&#xA;&lt;li&gt;Conclusion&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>[ToC] Course 4</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/toc_course4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c4_ai_evaluation/toc_course4/</guid>
      <description>&lt;h2 id=&#34;toc-of-course-45-evaluations-of-ai-applications-in-healthcare&#34;&gt;&#xA;  ToC of Course 4/5: Evaluations of AI Applications in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#toc-of-course-45-evaluations-of-ai-applications-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-1-ai-in-healthcare&#34;&gt;&#xA;  Module 1: AI in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-1-ai-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Learning Objectives&lt;/li&gt;&#xA;&lt;li&gt;Common Definitions&lt;/li&gt;&#xA;&lt;li&gt;Overview&lt;/li&gt;&#xA;&lt;li&gt;Why AI is needed in Healthcare&lt;/li&gt;&#xA;&lt;li&gt;Examples of AI in Healthcare&lt;/li&gt;&#xA;&lt;li&gt;Growth of AI in Healthcare&lt;/li&gt;&#xA;&lt;li&gt;Questions Answered by AI&lt;/li&gt;&#xA;&lt;li&gt;AI Output&lt;/li&gt;&#xA;&lt;li&gt;Think beyond area under the curve&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-2-evaluations-of-ai-in-healthcare&#34;&gt;&#xA;  Module 2: Evaluations of AI in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-2-evaluations-of-ai-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Learning Objectives&lt;/li&gt;&#xA;&lt;li&gt;Recap: Framework&lt;/li&gt;&#xA;&lt;li&gt;Stakeholders&lt;/li&gt;&#xA;&lt;li&gt;Clinical Utility&lt;/li&gt;&#xA;&lt;li&gt;Outcome: Action Pairing, An Overview&lt;/li&gt;&#xA;&lt;li&gt;Lead Time&lt;/li&gt;&#xA;&lt;li&gt;Type of Action&lt;/li&gt;&#xA;&lt;li&gt;OAP Examples&lt;/li&gt;&#xA;&lt;li&gt;Number Needed to Treat&lt;/li&gt;&#xA;&lt;li&gt;Net Benefits&lt;/li&gt;&#xA;&lt;li&gt;Decision Curves&lt;/li&gt;&#xA;&lt;li&gt;Feasibility overview&lt;/li&gt;&#xA;&lt;li&gt;Implementation Costs&lt;/li&gt;&#xA;&lt;li&gt;Clinical Evaluation and Uptake&lt;/li&gt;&#xA;&lt;li&gt;Summary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-3-ai-deployment&#34;&gt;&#xA;  Module 3: AI Deployment&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-3-ai-deployment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Learning Objectives&lt;/li&gt;&#xA;&lt;li&gt;The Problem&lt;/li&gt;&#xA;&lt;li&gt;Practical Questions Prior to Deployment&lt;/li&gt;&#xA;&lt;li&gt;Deployment Pathway&lt;/li&gt;&#xA;&lt;li&gt;Design and Development&lt;/li&gt;&#xA;&lt;li&gt;Stakeholder Involvement&lt;/li&gt;&#xA;&lt;li&gt;Data Type and Sources&lt;/li&gt;&#xA;&lt;li&gt;Settings&lt;/li&gt;&#xA;&lt;li&gt;In Silico Evaluation&lt;/li&gt;&#xA;&lt;li&gt;Net Utility &amp;amp; Work Capacity&lt;/li&gt;&#xA;&lt;li&gt;Statistical Validity&lt;/li&gt;&#xA;&lt;li&gt;Care Integration, Silent Mode&lt;/li&gt;&#xA;&lt;li&gt;Clinical Integration, Considerations&lt;/li&gt;&#xA;&lt;li&gt;Technical Integration&lt;/li&gt;&#xA;&lt;li&gt;Deployment Modalities&lt;/li&gt;&#xA;&lt;li&gt;Continuous Monitoring and Maintenance&lt;/li&gt;&#xA;&lt;li&gt;Challenges of Deployment&lt;/li&gt;&#xA;&lt;li&gt;Sepsis Example&lt;/li&gt;&#xA;&lt;li&gt;Summary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-4-downstream-evaluations-of-ai-in-healthcare-bias-and-fairness&#34;&gt;&#xA;  Module 4: Downstream Evaluations of AI in Healthcare: Bias and Fairness&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-4-downstream-evaluations-of-ai-in-healthcare-bias-and-fairness&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Learning Objectives&lt;/li&gt;&#xA;&lt;li&gt;Real World Examples of AI Bias&lt;/li&gt;&#xA;&lt;li&gt;Introduction - Types of Bias&lt;/li&gt;&#xA;&lt;li&gt;Historical Bias&lt;/li&gt;&#xA;&lt;li&gt;Representation Bias&lt;/li&gt;&#xA;&lt;li&gt;Measurement Bias&lt;/li&gt;&#xA;&lt;li&gt;Aggregation Bias&lt;/li&gt;&#xA;&lt;li&gt;Evaluation Bias&lt;/li&gt;&#xA;&lt;li&gt;Deployment Bias&lt;/li&gt;&#xA;&lt;li&gt;What is algorithmic Fairness&lt;/li&gt;&#xA;&lt;li&gt;Anti-classification&lt;/li&gt;&#xA;&lt;li&gt;Parity Classification&lt;/li&gt;&#xA;&lt;li&gt;Calibration&lt;/li&gt;&#xA;&lt;li&gt;Applying Fairness Measures&lt;/li&gt;&#xA;&lt;li&gt;Lack of Transparency&lt;/li&gt;&#xA;&lt;li&gt;Minimal Reporting Standards&lt;/li&gt;&#xA;&lt;li&gt;Opportunities and Challenges&lt;/li&gt;&#xA;&lt;li&gt;Summary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-5-the-regulatory-environment-for-ai-in-healthcare&#34;&gt;&#xA;  Module 5: The Regulatory Environment for AI in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-5-the-regulatory-environment-for-ai-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Learning Objectives&lt;/li&gt;&#xA;&lt;li&gt;The Problem&lt;/li&gt;&#xA;&lt;li&gt;International Definitions Used for Regulatory Purposes&lt;/li&gt;&#xA;&lt;li&gt;Definition Statement &amp;amp; Risk Framework&lt;/li&gt;&#xA;&lt;li&gt;Valid Clinical Association&lt;/li&gt;&#xA;&lt;li&gt;Analytical Evaluation&lt;/li&gt;&#xA;&lt;li&gt;Clinical Evaluation&lt;/li&gt;&#xA;&lt;li&gt;General Control&lt;/li&gt;&#xA;&lt;li&gt;de novo Notifications&lt;/li&gt;&#xA;&lt;li&gt;Software Modification&lt;/li&gt;&#xA;&lt;li&gt;TPLC&lt;/li&gt;&#xA;&lt;li&gt;Locked vs Adapted AI solutions&lt;/li&gt;&#xA;&lt;li&gt;Examples&lt;/li&gt;&#xA;&lt;li&gt;Non-Regulated Products&lt;/li&gt;&#xA;&lt;li&gt;EU Regulations&lt;/li&gt;&#xA;&lt;li&gt;Chinese Guidelines&lt;/li&gt;&#xA;&lt;li&gt;OMB Guidelines&lt;/li&gt;&#xA;&lt;li&gt;Summary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;module-7-ai-and-medicine-optional-content&#34;&gt;&#xA;  Module 7: AI and Medicine (Optional Content)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-7-ai-and-medicine-optional-content&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Introduction: Navigating the Intersections of AI and Medicine&lt;/li&gt;&#xA;&lt;li&gt;Life Cycle of AI&lt;/li&gt;&#xA;&lt;li&gt;A Deep Dive into Historical and Societal Dimensions&lt;/li&gt;&#xA;&lt;li&gt;Race-Based Medicine and Race-Aware Approach&lt;/li&gt;&#xA;&lt;li&gt;Bias Mitigation Strategies&lt;/li&gt;&#xA;&lt;li&gt;Exploring Potentials and Ethical Quandaries&lt;/li&gt;&#xA;&lt;li&gt;Dismantling Race-Based Medicine&lt;/li&gt;&#xA;&lt;li&gt;Deploying AI into Healthcare Settings&lt;/li&gt;&#xA;&lt;li&gt;Conclusion&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Day 1 - Foundational LLMs &amp; Text Generation</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day1_foundational_llm_text_generation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day1_foundational_llm_text_generation/</guid>
      <description>&lt;h2 id=&#34;day-1---foundational-llms--text-generation&#34;&gt;&#xA;  Day 1 - Foundational LLMs &amp;amp; Text Generation&amp;quot;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-1---foundational-llms--text-generation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;foundations-of-llms&#34;&gt;&#xA;  &lt;strong&gt;Foundations of LLMs&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#foundations-of-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-why-llms-matter&#34;&gt;&#xA;  1. Why LLMs Matter&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-llms-matter&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Traditional NLP systems were narrow, but Large Language Models (LLMs) offer general-purpose capabilities like translation, Q&amp;amp;A, and summarization—all without explicit task-specific programming.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ How do LLMs work under the hood?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-what-powers-llms-the-transformer&#34;&gt;&#xA;  2. What Powers LLMs: The Transformer&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-powers-llms-the-transformer&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;The Transformer is the core architecture enabling LLMs. Unlike RNNs that process data sequentially, Transformers handle inputs in parallel using &lt;strong&gt;self-attention&lt;/strong&gt;, allowing them to model long-range dependencies more efficiently and scale training.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module 1: Asking Answering Questions via Clinical DataMining</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m1/</guid>
      <description>&lt;h2 id=&#34;module-1-asking-answering-questions-via-clinical-datamining&#34;&gt;&#xA;  &lt;strong&gt;Module 1: Asking Answering Questions via Clinical DataMining&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-1-asking-answering-questions-via-clinical-datamining&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-the-data-mining-workflow&#34;&gt;&#xA;  1 Introduction to the data mining workflow&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction-to-the-data-mining-workflow&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q-what-is-the-main-goal-of-this-course&#34;&gt;&#xA;  Q: What is the main goal of this course?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-is-the-main-goal-of-this-course&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: To explain how clinical data can be used to answer research questions that improve patient and population health.&lt;/p&gt;&#xA;&lt;h3 id=&#34;q-what-is-the-structure-of-the-course&#34;&gt;&#xA;  Q: What is the structure of the course?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-is-the-structure-of-the-course&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: It begins with choosing meaningful research questions, followed by understanding the healthcare system, exploring data types, reviewing processing and analysis methods, and addressing bias and error.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 1 – Prompt Engineering</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day1_prompt_engineering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day1_prompt_engineering/</guid>
      <description>&lt;h2 id=&#34;day-1--prompt-engineering&#34;&gt;&#xA;  Day 1 – Prompt Engineering&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-1--prompt-engineering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-why-prompt-engineering-matters&#34;&gt;&#xA;  1. Why Prompt Engineering Matters&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-prompt-engineering-matters&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;need for controlling LLM behavior&lt;/em&gt;. Although everyone can write prompts, crafting high-quality prompts is complex. The model, structure, tone, and context all affect the outcome. Prompt engineering is an iterative process requiring optimization and experimentation.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ how do we guide LLMs effectively without retraining them?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-how-llms-predict-text&#34;&gt;&#xA;  2. How LLMs Predict Text&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-how-llms-predict-text&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;LLMs are &lt;em&gt;token prediction machines&lt;/em&gt;. They predict the next likely token based on previous tokens and training data. Prompt engineering means designing inputs that lead the model toward the desired outputs using this prediction mechanism.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module2: Data Available From Healthcare Systems</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m2/</guid>
      <description>&lt;h2 id=&#34;module2-data-available-from-healthcare-systems&#34;&gt;&#xA;  Module2: Data Available From Healthcare Systems&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module2-data-available-from-healthcare-systems&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-review-of-the-healthcare-system&#34;&gt;&#xA;  1 Review of the healthcare system&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-review-of-the-healthcare-system&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q-what-is-the-focus-of-this-modules-introduction&#34;&gt;&#xA;  Q: What is the focus of this module&amp;rsquo;s introduction?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-is-the-focus-of-this-modules-introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: To demonstrate how clinical data from the healthcare system can be used to ask and answer meaningful research questions.&lt;/p&gt;&#xA;&lt;h3 id=&#34;q-what-key-topics-are-introduced-in-this-session&#34;&gt;&#xA;  Q: What key topics are introduced in this session?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-key-topics-are-introduced-in-this-session&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Common data sources in healthcare&lt;/li&gt;&#xA;&lt;li&gt;Types of data generated&lt;/li&gt;&#xA;&lt;li&gt;Systematic inaccuracies in the data&lt;/li&gt;&#xA;&lt;li&gt;Strategies for working with imperfect data&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;q-how-does-this-connect-to-the-earlier-module&#34;&gt;&#xA;  Q: How does this connect to the earlier module?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-how-does-this-connect-to-the-earlier-module&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: It builds on the discussion of research question formulation and data mining workflows by diving into real-world data availability and limitations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 2 – Embeddings &amp; Vector Databases</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day2_embeddings_vectordb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day2_embeddings_vectordb/</guid>
      <description>&lt;h2 id=&#34;day-2--embeddings--vector-databases&#34;&gt;&#xA;  Day 2 – Embeddings &amp;amp; Vector Databases&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-2--embeddings--vector-databases&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-why-embeddings&#34;&gt;&#xA;  1. Why Embeddings?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We begin with the &lt;em&gt;core problem of representing diverse data types&lt;/em&gt;. Images, text, audio, and structured data all need to be compared, retrieved, and clustered. Embeddings map these into a shared vector space where similarity can be computed numerically.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ how can we measure and preserve semantic meaning across different data types?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-mapping-data-to-vector-space&#34;&gt;&#xA;  2. Mapping Data to Vector Space&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-mapping-data-to-vector-space&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Embeddings reduce dimensionality while preserving meaning. For example, just like latitude and longitude embed Earth’s surface into 2D coordinates, BERT embeds text into 768D space. Distances represent semantic similarity.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module 3: Concepts and Principles of ML in Healthcare</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m3/</guid>
      <description>&lt;h2 id=&#34;module-3-concepts-and-principles-of-ml-in-healthcare&#34;&gt;&#xA;  &lt;strong&gt;Module 3: Concepts and Principles of ML in Healthcare&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-3-concepts-and-principles-of-ml-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-deep-learning-and-neural-networks&#34;&gt;&#xA;  1 Introduction to Deep Learning and Neural Networks&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction-to-deep-learning-and-neural-networks&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-why-are-neural-networks-considered-a-turning-point-in-machine-learning&#34;&gt;&#xA;  Q1: Why are neural networks considered a turning point in machine learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-why-are-neural-networks-considered-a-turning-point-in-machine-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Neural networks mark a major departure from traditional ML models because they enable much &lt;strong&gt;deeper interactions&lt;/strong&gt; between features and parameters. Unlike models like logistic regression or decision trees, neural networks—especially deep ones—organize parameters in &lt;strong&gt;layers&lt;/strong&gt;, allowing complex feature transformations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module3: Representing Time Timing Events For Clinical Data Mining</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m3/</guid>
      <description>&lt;h2 id=&#34;module3-representing-time-timing-events-for-clinical-data-mining&#34;&gt;&#xA;  Module3: Representing Time Timing Events For Clinical Data Mining&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module3-representing-time-timing-events-for-clinical-data-mining&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-time-timelines-timescales-and-representations-of-time&#34;&gt;&#xA;  1 Time, timelines, timescales and representations of time&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-time-timelines-timescales-and-representations-of-time&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q-why-is-it-useful-to-place-patient-events-on-a-timeline&#34;&gt;&#xA;  Q: Why is it useful to place patient events on a timeline?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-why-is-it-useful-to-place-patient-events-on-a-timeline&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: Timelines integrate diverse patient data sources, helping visualize when each event occurred, enabling analysis of sequence and duration.&lt;/p&gt;&#xA;&lt;h3 id=&#34;q-what-are-two-key-reasons-time-matters-in-healthcare-data&#34;&gt;&#xA;  Q: What are two key reasons time matters in healthcare data?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-are-two-key-reasons-time-matters-in-healthcare-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Patient age&lt;/strong&gt;: Impacts diagnosis, treatment decisions, metabolism, and insurance access.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Event order&lt;/strong&gt;: Helps infer causality — exposures should precede outcomes.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;q-how-do-timescales-vary-in-medical-questions&#34;&gt;&#xA;  Q: How do timescales vary in medical questions?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-how-do-timescales-vary-in-medical-questions&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: Medical events can span milliseconds (e.g., EKG signals), days (e.g., symptom onset), or decades (e.g., chronic disease progression), requiring careful scale selection.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module4 : Creating Analysis Ready Dataset from Patient Timelines</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/summary_m4/</guid>
      <description>&lt;h2 id=&#34;module4--creating-analysis-ready-dataset-from-patient-timelines&#34;&gt;&#xA;  &lt;strong&gt;Module4 : Creating Analysis Ready Dataset from Patient Timelines&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module4--creating-analysis-ready-dataset-from-patient-timelines&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-turning-clinical-data-into-something-you-can-analyze&#34;&gt;&#xA;  1 Turning clinical data into something you can analyze&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-turning-clinical-data-into-something-you-can-analyze&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q-what-is-the-main-objective-of-this-module&#34;&gt;&#xA;  Q: What is the main objective of this module?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-is-the-main-objective-of-this-module&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: To explain how to convert raw clinical data into a patient-feature matrix suitable for analysis and answering research questions.&lt;/p&gt;&#xA;&lt;h3 id=&#34;q-what-is-a-patient-feature-matrix&#34;&gt;&#xA;  Q: What is a patient-feature matrix?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q-what-is-a-patient-feature-matrix&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;A: A structured table where each row represents a patient and each column represents a clinical feature or measurement.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 3 – Generative Agents</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day3_generative_agents/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day3_generative_agents/</guid>
      <description>&lt;h2 id=&#34;day-3--generative-agents&#34;&gt;&#xA;  Day 3 – Generative Agents&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-3--generative-agents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-what-are-generative-agents&#34;&gt;&#xA;  1. What Are Generative Agents?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-what-are-generative-agents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;definition of agents&lt;/em&gt;—AI systems designed to achieve goals by perceiving their environment and taking actions using tools. Unlike static LLMs, generative agents combine models, tools, and orchestration to interact with the world dynamically.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ what components make these agents truly autonomous and intelligent?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-agent-architecture-breakdown&#34;&gt;&#xA;  2. Agent Architecture Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-agent-architecture-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;An agent’s architecture includes:&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module 4: Evaluation and Metrics for ML in Healthcare</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m4/</guid>
      <description>&lt;h2 id=&#34;module-4-evaluation-and-metrics-for-ml-in-healthcare&#34;&gt;&#xA;  &lt;strong&gt;Module 4: Evaluation and Metrics for ML in Healthcare&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-4-evaluation-and-metrics-for-ml-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-model-performance-evaluation&#34;&gt;&#xA;  1 Introduction to Model Performance Evaluation&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction-to-model-performance-evaluation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-why-is-model-evaluation-critical-in-healthcare-machine-learning&#34;&gt;&#xA;  Q1: Why is model evaluation critical in healthcare machine learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-why-is-model-evaluation-critical-in-healthcare-machine-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;In healthcare, decisions informed by ML models can have life-altering consequences:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It’s not enough for a model to perform well on training data.&lt;/li&gt;&#xA;&lt;li&gt;We need to ensure that the model performs well on &lt;strong&gt;unseen patients&lt;/strong&gt; and &lt;strong&gt;real-world conditions&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Rigorous evaluation is essential to &lt;strong&gt;trust and validate clinical usefulness&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;➡️  What does it mean for a model to generalize?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 4 – Domain-Specific LLMs</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day4_domainspecific_llms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day4_domainspecific_llms/</guid>
      <description>&lt;h2 id=&#34;day-4--domain-specific-llms&#34;&gt;&#xA;  Day 4 – Domain-Specific LLMs&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-4--domain-specific-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-the-rise-of-specialized-llms&#34;&gt;&#xA;  1. The Rise of Specialized LLMs&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-the-rise-of-specialized-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;evolution of LLMs&lt;/em&gt; from general-purpose to domain-specific tools. This shift was driven by challenges in fields like cybersecurity and medicine, where technical language and sensitive use cases demand more than general knowledge.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ why do general-purpose LLMs struggle in specialized domains?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-the-challenges-in-cybersecurity&#34;&gt;&#xA;  2. The Challenges in Cybersecurity&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-the-challenges-in-cybersecurity&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Cybersecurity experts face three main issues: rapidly evolving threats, repetitive manual work (toil), and a shortage of skilled talent. These bottlenecks make it hard to keep up with modern security needs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module 5: Strategies and Challenges in ML for Healthcare</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m5/</guid>
      <description>&lt;h2 id=&#34;module-5-strategies-and-challenges-in-ml-for-healthcare&#34;&gt;&#xA;  &lt;strong&gt;Module 5: Strategies and Challenges in ML for Healthcare&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-5-strategies-and-challenges-in-ml-for-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-common-clinical-machine-learning-challenges&#34;&gt;&#xA;  1 Introduction to Common Clinical Machine Learning Challenges&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction-to-common-clinical-machine-learning-challenges&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-why-is-deploying-machine-learning-in-healthcare-uniquely-challenging&#34;&gt;&#xA;  Q1: Why is deploying machine learning in healthcare uniquely challenging?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-why-is-deploying-machine-learning-in-healthcare-uniquely-challenging&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Healthcare presents &lt;strong&gt;complex, high-stakes environments&lt;/strong&gt; with unique constraints:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data is &lt;strong&gt;heterogeneous&lt;/strong&gt;, often unstructured and incomplete.&lt;/li&gt;&#xA;&lt;li&gt;Clinical settings are &lt;strong&gt;dynamic and contextual&lt;/strong&gt;, with human-in-the-loop decisions.&lt;/li&gt;&#xA;&lt;li&gt;Errors have &lt;strong&gt;real consequences&lt;/strong&gt;, requiring robustness and explainability.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;➡️  What specific areas of ML model development are affected by these clinical challenges?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Day 5 – MLOps for Generative AI</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day5_mlops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/5-day-genai-google/day5_mlops/</guid>
      <description>&lt;h2 id=&#34;day-5--mlops-for-generative-ai&#34;&gt;&#xA;  Day 5 – MLOps for Generative AI&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-5--mlops-for-generative-ai&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-introduction&#34;&gt;&#xA;  1. Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;The rise of &lt;strong&gt;foundation models&lt;/strong&gt; and &lt;strong&gt;generative AI (gen AI)&lt;/strong&gt; has brought a paradigm shift in how we build and deploy AI systems. From selecting architectures to managing prompts and grounding outputs in real data, traditional MLOps needs adaptation.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;So how do we evolve MLOps for this new generative world?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-what-are-devops-and-mlops&#34;&gt;&#xA;  2. What Are DevOps and MLOps?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-are-devops-and-mlops&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DevOps&lt;/strong&gt;: Automation + collaboration for software delivery (CI/CD, testing, reliability)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MLOps&lt;/strong&gt;: Adds ML-specific needs:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data validation&lt;/li&gt;&#xA;&lt;li&gt;Model evaluation&lt;/li&gt;&#xA;&lt;li&gt;Monitoring&lt;/li&gt;&#xA;&lt;li&gt;Experiment tracking&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;These core principles set the stage, but gen AI has unique needs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary]  Module 6: Best Practices, Terms, and Launching Your ML Journey</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m6/</guid>
      <description>&lt;h2 id=&#34;module-6-best-practices-terms-and-launching-your-ml-journey&#34;&gt;&#xA;  &lt;strong&gt;Module 6: Best Practices, Terms, and Launching Your ML Journey&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-6-best-practices-terms-and-launching-your-ml-journey&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-clinical-utility-and-output-action-pairing&#34;&gt;&#xA;  1 Clinical Utility and Output Action Pairing&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-clinical-utility-and-output-action-pairing&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-is-clinical-utility-and-why-is-it-important-in-ml&#34;&gt;&#xA;  Q1: What is clinical utility and why is it important in ML?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-clinical-utility-and-why-is-it-important-in-ml&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Clinical utility refers to the &lt;strong&gt;real-world usefulness&lt;/strong&gt; of a model’s predictions:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A model must &lt;strong&gt;enable action&lt;/strong&gt; that improves outcomes.&lt;/li&gt;&#xA;&lt;li&gt;Predictions that can&amp;rsquo;t lead to interventions or decisions have limited utility.&lt;/li&gt;&#xA;&lt;li&gt;This bridges the gap between technical performance and clinical relevance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;➡️  How can we ensure predictions are actually actionable?&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Summary] Module 7: Foundation Models</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/summary_m7/</guid>
      <description>&lt;h2 id=&#34;module-7-foundation-models&#34;&gt;&#xA;  &lt;strong&gt;Module 7: Foundation Models&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#module-7-foundation-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-foundation-models&#34;&gt;&#xA;  1 Introduction to Foundation Models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction-to-foundation-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q1-what-are-foundation-models-and-why-are-they-significant&#34;&gt;&#xA;  Q1: What are foundation models and why are they significant?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-are-foundation-models-and-why-are-they-significant&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Foundation models are &lt;strong&gt;large-scale models&lt;/strong&gt; trained on massive datasets:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They can be adapted for many downstream tasks with minimal fine-tuning.&lt;/li&gt;&#xA;&lt;li&gt;Examples include models like &lt;strong&gt;BERT, GPT, and CLIP&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Represent a shift from building task-specific models to training one model for many uses.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;➡️  Why have foundation models become so prominent recently?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ghibli Art Style Snapshots</title>
      <link>http://localhost:1313/posts/ghibli_style_snapshots/</link>
      <pubDate>Tue, 08 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/ghibli_style_snapshots/</guid>
      <description>&lt;img src=&#34;http://localhost:1313/images/ghibli-ipark0.png&#34; width=&#34;200&#34; /&gt;&#xA;&lt;img src=&#34;http://localhost:1313/images/ghibli-ipark1.png&#34; width=&#34;200&#34; /&gt;&#xA;&lt;img src=&#34;http://localhost:1313/images/ghibli-ipark2.png&#34; width=&#34;200&#34; /&gt;</description>
    </item>
    <item>
      <title>The AI Engineer Path – Scrimba</title>
      <link>http://localhost:1313/posts/ai_engineer_path_toc/</link>
      <pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/ai_engineer_path_toc/</guid>
      <description>&lt;h1 id=&#34;the-ai-engineer-path--scrimba&#34;&gt;&#xA;  The AI Engineer Path – Scrimba&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#the-ai-engineer-path--scrimba&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.coursera.org/specializations/ai-engineering#courses&#34;&gt;https://www.coursera.org/specializations/ai-engineering#courses&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;intro-to-ai-engineering-104-min&#34;&gt;&#xA;  Intro to AI Engineering (104 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#intro-to-ai-engineering-104-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Welcome to The AI Engineer Path!&lt;/li&gt;&#xA;&lt;li&gt;AI Engineering basics&lt;/li&gt;&#xA;&lt;li&gt;The code so far&lt;/li&gt;&#xA;&lt;li&gt;Polygon API sign-up &amp;amp; key&lt;/li&gt;&#xA;&lt;li&gt;Get an OpenAI API Key&lt;/li&gt;&#xA;&lt;li&gt;Overview of how the API works&lt;/li&gt;&#xA;&lt;li&gt;An API call: OpenAI dependency&lt;/li&gt;&#xA;&lt;li&gt;An API call: Instance and model&lt;/li&gt;&#xA;&lt;li&gt;An API call: The messages array&lt;/li&gt;&#xA;&lt;li&gt;A quick word about models&lt;/li&gt;&#xA;&lt;li&gt;Prompt Engineering and a challenge&lt;/li&gt;&#xA;&lt;li&gt;Adding AI to the App&lt;/li&gt;&#xA;&lt;li&gt;Tokens&lt;/li&gt;&#xA;&lt;li&gt;The OpenAI Playground&lt;/li&gt;&#xA;&lt;li&gt;Temperature&lt;/li&gt;&#xA;&lt;li&gt;The &amp;ldquo;Few Shot&amp;rdquo; Approach&lt;/li&gt;&#xA;&lt;li&gt;Adding Examples&lt;/li&gt;&#xA;&lt;li&gt;Stop Sequence&lt;/li&gt;&#xA;&lt;li&gt;Frequency and Presence Penalties&lt;/li&gt;&#xA;&lt;li&gt;Fine-tuning&lt;/li&gt;&#xA;&lt;li&gt;Creating Images with the DALL·E 3 API&lt;/li&gt;&#xA;&lt;li&gt;Intro to AI Safety&lt;/li&gt;&#xA;&lt;li&gt;Safety Best Practices&lt;/li&gt;&#xA;&lt;li&gt;Solo Project - PollyGlot&lt;/li&gt;&#xA;&lt;li&gt;You made it!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;deployment-50-min&#34;&gt;&#xA;  Deployment (50 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#deployment-50-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Learn secure &amp;amp; robust deployment strategies&lt;/li&gt;&#xA;&lt;li&gt;Create a Cloudflare worker&lt;/li&gt;&#xA;&lt;li&gt;Connect your worker to OpenAI&lt;/li&gt;&#xA;&lt;li&gt;Update client side data fetching&lt;/li&gt;&#xA;&lt;li&gt;Handle CORS and preflight requests&lt;/li&gt;&#xA;&lt;li&gt;OpenAI API requests &amp;amp; responses&lt;/li&gt;&#xA;&lt;li&gt;Create an AI Gateway&lt;/li&gt;&#xA;&lt;li&gt;Error handling&lt;/li&gt;&#xA;&lt;li&gt;Create &amp;amp; deploy the Polygon API worker&lt;/li&gt;&#xA;&lt;li&gt;Fetch the stock data&lt;/li&gt;&#xA;&lt;li&gt;Download files and push to GitHub&lt;/li&gt;&#xA;&lt;li&gt;Deploy your site with Cloudflare Pages&lt;/li&gt;&#xA;&lt;li&gt;Custom domains with Cloudflare&lt;/li&gt;&#xA;&lt;li&gt;Recap &amp;amp; next steps&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;open-source-models-33-min&#34;&gt;&#xA;  Open-source Models (33 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#open-source-models-33-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Open source vs closed source&lt;/li&gt;&#xA;&lt;li&gt;Intro To HuggingFace.js Inference&lt;/li&gt;&#xA;&lt;li&gt;Text To Speech With HuggingFace.js Inference&lt;/li&gt;&#xA;&lt;li&gt;Transforming Images with HuggingFace.js Inference&lt;/li&gt;&#xA;&lt;li&gt;AI Models In The Browser With Transformers.js&lt;/li&gt;&#xA;&lt;li&gt;Download and Run AI Models on Your Computer with Ollama&lt;/li&gt;&#xA;&lt;li&gt;Section Recap&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;embeddings-and-vector-databases-94-min&#34;&gt;&#xA;  Embeddings and Vector Databases (94 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#embeddings-and-vector-databases-94-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Your next big step in AI engineering&lt;/li&gt;&#xA;&lt;li&gt;What are embeddings?&lt;/li&gt;&#xA;&lt;li&gt;Set up environment variables&lt;/li&gt;&#xA;&lt;li&gt;Create an embedding&lt;/li&gt;&#xA;&lt;li&gt;Challenge: Pair text with embedding&lt;/li&gt;&#xA;&lt;li&gt;Vector databases&lt;/li&gt;&#xA;&lt;li&gt;Set up your vector database&lt;/li&gt;&#xA;&lt;li&gt;Store vector embeddings&lt;/li&gt;&#xA;&lt;li&gt;Semantic search&lt;/li&gt;&#xA;&lt;li&gt;Query embeddings using similarity search&lt;/li&gt;&#xA;&lt;li&gt;Create a conversational response using OpenAI&lt;/li&gt;&#xA;&lt;li&gt;Chunking text from documents&lt;/li&gt;&#xA;&lt;li&gt;Challenge: Split text, get vectors, insert into Supabase&lt;/li&gt;&#xA;&lt;li&gt;Error handling&lt;/li&gt;&#xA;&lt;li&gt;Query database and manage multiple matches&lt;/li&gt;&#xA;&lt;li&gt;AI chatbot proof of concept&lt;/li&gt;&#xA;&lt;li&gt;Retrieval-augmented generation (RAG)&lt;/li&gt;&#xA;&lt;li&gt;Solo Project: PopChoice&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;agents-117-min&#34;&gt;&#xA;  Agents (117 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#agents-117-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI Agent Intro&lt;/li&gt;&#xA;&lt;li&gt;Prompt Engineering 101&lt;/li&gt;&#xA;&lt;li&gt;Control Response Formats&lt;/li&gt;&#xA;&lt;li&gt;Zooming Out&lt;/li&gt;&#xA;&lt;li&gt;Agent Setup&lt;/li&gt;&#xA;&lt;li&gt;Introduction to ReAct prompting&lt;/li&gt;&#xA;&lt;li&gt;Build action functions&lt;/li&gt;&#xA;&lt;li&gt;Write ReAct prompt - part 1 - planning&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 2 - ReAct prompt&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 3 - how does the &amp;ldquo;loop&amp;rdquo; work?&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 4 - code setup&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 5 - Plan for parsing the response&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 6 - Parsing the Action&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 7 - Calling the function&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 8 - Housekeeping&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 9 - Finally! The loop!&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - part 1 - Intro&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - part 2 - Demo day&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - part 3 - Tools&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 4 - Loop Logic&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 5 - Setup Challenge&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 6 - Tool Calls&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 7 - Pushing to messages&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 8 - Adding arguments&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 9 - Automatic function calls&lt;/li&gt;&#xA;&lt;li&gt;Adding UI to agent - proof of concept&lt;/li&gt;&#xA;&lt;li&gt;Solo Project - AI Travel Agent&lt;/li&gt;&#xA;&lt;li&gt;Nice work!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;multimodality-62-min&#34;&gt;&#xA;  Multimodality (62 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#multimodality-62-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Introduction&lt;/li&gt;&#xA;&lt;li&gt;Generate original images from a text prompt&lt;/li&gt;&#xA;&lt;li&gt;Response formats&lt;/li&gt;&#xA;&lt;li&gt;Prompting for image generation&lt;/li&gt;&#xA;&lt;li&gt;Size, quality and style&lt;/li&gt;&#xA;&lt;li&gt;Editing images&lt;/li&gt;&#xA;&lt;li&gt;Image generation challenge&lt;/li&gt;&#xA;&lt;li&gt;Image generation challenge solution&lt;/li&gt;&#xA;&lt;li&gt;GPT-4 with Vision - Part 1&lt;/li&gt;&#xA;&lt;li&gt;GPT-4 with Vision - Part 2&lt;/li&gt;&#xA;&lt;li&gt;Image generation &amp;amp; Vision recap&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;openais-assistants-api-30-min&#34;&gt;&#xA;  OpenAI&amp;rsquo;s Assistants API (30 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#openais-assistants-api-30-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Introducing the Assistants API&lt;/li&gt;&#xA;&lt;li&gt;How OpenAI Assistants work&lt;/li&gt;&#xA;&lt;li&gt;Create an Assistant&lt;/li&gt;&#xA;&lt;li&gt;Create a thread and messages&lt;/li&gt;&#xA;&lt;li&gt;Running an Assistant&lt;/li&gt;&#xA;&lt;li&gt;Bring it all together&lt;/li&gt;&#xA;&lt;li&gt;More to explore&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>5 Steps Learning Template</title>
      <link>http://localhost:1313/posts/5_steps_learning_template/</link>
      <pubDate>Tue, 25 Mar 2025 13:19:10 -0700</pubDate>
      <guid>http://localhost:1313/posts/5_steps_learning_template/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;What&amp;rsquo;s the Problem?&#xA;&lt;em&gt;What is the issue, gap, or challenge this module/concept is trying to address?&lt;/em&gt;&#xA;→ &lt;strong&gt;Transition&lt;/strong&gt;: “So what if this problem exists?”&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Why Does It Matter?&#xA;&lt;em&gt;What are the real-world stakes or consequences of not solving this problem? Who or what is affected?&lt;/em&gt;&#xA;→ &lt;strong&gt;Transition&lt;/strong&gt;: “Given this urgency, what’s the smart way to tackle it?”&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;What’s the Core Idea?&#xA;&lt;em&gt;What is the central concept, structure, or strategy introduced to solve the problem?&lt;/em&gt;&#xA;→ &lt;strong&gt;Transition&lt;/strong&gt;: “Okay, so how would I actually &lt;em&gt;apply&lt;/em&gt; or &lt;em&gt;build&lt;/em&gt; this?”&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hugo Setup and Deploy</title>
      <link>http://localhost:1313/posts/hugo-setup/</link>
      <pubDate>Thu, 20 Mar 2025 21:23:49 -0700</pubDate>
      <guid>http://localhost:1313/posts/hugo-setup/</guid>
      <description>&lt;h1 id=&#34;-hugo--github-pages-setup-user-site&#34;&gt;&#xA;  🚀 Hugo + GitHub Pages Setup (User Site)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-hugo--github-pages-setup-user-site&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Minimal setup using &lt;code&gt;hugo-book&lt;/code&gt; theme inside a Conda environment, with GitHub Pages deployment.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-create-and-activate-conda-environment&#34;&gt;&#xA;  1. Create and Activate Conda Environment&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-create-and-activate-conda-environment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create -n hugo-env&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate hugo-env&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-install-hugo--create-hugo-site-with-hugo-book-theme&#34;&gt;&#xA;  2. Install Hugo &amp;amp; Create Hugo Site with &lt;code&gt;hugo-book&lt;/code&gt; Theme&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-install-hugo--create-hugo-site-with-hugo-book-theme&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Install Hugo&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install hugo         &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Or: brew install hugo&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Create Hugo site&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hugo new site hugo-site&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#04a5e5&#34;&gt;cd&lt;/span&gt; hugo-site&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Initialize git and add theme&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git init&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;3-configure-configtoml&#34;&gt;&#xA;  3. Configure &lt;code&gt;config.toml&lt;/code&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-configure-configtoml&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-toml&#34; data-lang=&#34;toml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;baseURL = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;https://your-username.github.io/&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;languageCode = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;en-us&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;title = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;My Hugo Site&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;theme = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;hugo-book&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[params]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookTheme = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;light&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookToC = &lt;span style=&#34;color:#fe640b&#34;&gt;true&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookCollapseSection = &lt;span style=&#34;color:#fe640b&#34;&gt;true&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookFlatSection = &lt;span style=&#34;color:#fe640b&#34;&gt;false&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[[menu.sidebar]]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Knowledge Graph&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  url = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;/kg/&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  weight = &lt;span style=&#34;color:#fe640b&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;4-create-content-and-_indexmd-files&#34;&gt;&#xA;  4. Create Content and &lt;code&gt;_index.md&lt;/code&gt; Files&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#4-create-content-and-_indexmd-files&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Create directories and content&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p content/kg/topic1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;touch content/_index.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;touch content/kg/_index.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;touch content/kg/topic1/_index.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hugo new kg/topic1/intro.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;directory-structure&#34;&gt;&#xA;  Directory Structure&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#directory-structure&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;content/&#xA;├── _index.md&#xA;├── kg/&#xA;│   ├── _index.md&#xA;│   └── topic1/&#xA;│       ├── _index.md&#xA;│       └── intro.md&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;_indexmd-contents&#34;&gt;&#xA;  &lt;code&gt;_index.md&lt;/code&gt; contents&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#_indexmd-contents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;content/_index.md&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hugo Source Backup</title>
      <link>http://localhost:1313/posts/hugo-source-backup/</link>
      <pubDate>Thu, 20 Mar 2025 21:23:49 -0700</pubDate>
      <guid>http://localhost:1313/posts/hugo-source-backup/</guid>
      <description>&lt;h1 id=&#34;-hugo-source-backup&#34;&gt;&#xA;  🔒 Hugo Source Backup&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-hugo-source-backup&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide outlines how to back up your &lt;strong&gt;Hugo source files&lt;/strong&gt; (excluding the &lt;code&gt;public/&lt;/code&gt; folder) to a &lt;strong&gt;private GitHub repository&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-folder-structure&#34;&gt;&#xA;  📁 Folder Structure&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-folder-structure&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Typical Hugo project structure:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hugo-site/&#xA;├── archetypes/&#xA;├── content/&#xA;├── layouts/&#xA;├── static/&#xA;├── themes/&#xA;├── config.toml&#xA;├── public/           # &amp;lt;- This is ignored for source backup&#xA;└── backup.sh         # Backup script&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-1-create-a-private-github-repo&#34;&gt;&#xA;  ✅ 1. Create a Private GitHub Repo&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-1-create-a-private-github-repo&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Go to &lt;a href=&#34;https://github.com/new&#34;&gt;https://github.com/new&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Name it something like &lt;code&gt;hugo-source&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Set visibility to &lt;strong&gt;Private&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Don’t initialize with README or license&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-2-initialize-git-in-your-hugo-site-if-not-already&#34;&gt;&#xA;  ✅ 2. Initialize Git in Your Hugo Site (if not already)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-2-initialize-git-in-your-hugo-site-if-not-already&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git init&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git remote add origin https://github.com/&amp;lt;your-username&amp;gt;/hugo-source.git&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#04a5e5&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;public/&amp;#34;&lt;/span&gt; &amp;gt;&amp;gt; .gitignore&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-3-create-the-backup-script&#34;&gt;&#xA;  ✅ 3. Create the Backup Script&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-3-create-the-backup-script&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Create a file named &lt;code&gt;backup.sh&lt;/code&gt; in the root of your Hugo project:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Azure vs AWS for AI/ML/GenAI</title>
      <link>http://localhost:1313/ai-workflows/mlops/ai_cloud_comparision/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/mlops/ai_cloud_comparision/</guid>
      <description>&lt;h1 id=&#34;azure-vs-aws-for-aimlgenai&#34;&gt;&#xA;  Azure vs AWS for AI/ML/GenAI&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#azure-vs-aws-for-aimlgenai&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Feature&lt;/th&gt;&#xA;          &lt;th&gt;Azure&lt;/th&gt;&#xA;          &lt;th&gt;AWS&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Market Share&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;~23%&lt;/td&gt;&#xA;          &lt;td&gt;~31% (still largest)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Enterprise Adoption&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Strong in healthcare, finance, gov (esp. with Microsoft 365/Teams/EHR ties)&lt;/td&gt;&#xA;          &lt;td&gt;Strong with startups, research, media, big tech&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;AI/ML Tools&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Azure Machine Learning, OpenAI on Azure, Synapse, Cognitive Services&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker, Bedrock, Comprehend, Rekognition&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;GenAI Integration&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🔥 Deep OpenAI partnership (GPT, Codex, DALL·E via Azure OpenAI Service)&lt;/td&gt;&#xA;          &lt;td&gt;Bedrock (Anthropic, Stability, Cohere), Titan (Amazon’s own)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Ease of Use&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;More integrated across MS ecosystem (Power BI, Excel, VS Code)&lt;/td&gt;&#xA;          &lt;td&gt;More flexible but often messier to set up&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Learning Curve&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Smoother onboarding if familiar with Microsoft tools&lt;/td&gt;&#xA;          &lt;td&gt;More customizable, but steeper learning curve&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Certifications&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Azure AI Engineer, Data Scientist, OpenAI Engineer (in preview)&lt;/td&gt;&#xA;          &lt;td&gt;AWS ML Specialty, Solutions Architect, Bedrock tracks&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Case Study: The Hidden Danger of Correlation in Healthcare AI</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/ehr_model_failure_case_study/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/ehr_model_failure_case_study/</guid>
      <description>&lt;h1 id=&#34;case-study-the-hidden-danger-of-correlation-in-healthcare-ai&#34;&gt;&#xA;  Case Study: The Hidden Danger of Correlation in Healthcare AI&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#case-study-the-hidden-danger-of-correlation-in-healthcare-ai&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-the-goal&#34;&gt;&#xA;  🎯 The Goal&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-the-goal&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Build a machine learning model to predict &lt;strong&gt;which pneumonia patients might die&lt;/strong&gt;, using historical &lt;strong&gt;Electronic Health Record (EHR)&lt;/strong&gt; data. This would help doctors:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Identify high-risk patients who need &lt;strong&gt;ICU care&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Identify low-risk patients who could &lt;strong&gt;recover at home&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-what-actually-happened&#34;&gt;&#xA;  ✅ What Actually Happened&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-what-actually-happened&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The model was trained on real EHR data and found a surprising pattern:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Categories of Machine Learning Applications in Healthcare</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/clinical_ml_categories/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/clinical_ml_categories/</guid>
      <description>&lt;h1 id=&#34;categories-of-machine-learning-applications-in-healthcare&#34;&gt;&#xA;  Categories of Machine Learning Applications in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#categories-of-machine-learning-applications-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;In the Stanford course and broader healthcare ML ecosystem, &lt;strong&gt;&amp;ldquo;practice of care&amp;rdquo;&lt;/strong&gt; is just one of several conceptual categories used to frame ML applications. Each category reflects a different &lt;strong&gt;purpose&lt;/strong&gt; and &lt;strong&gt;clinical context&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-1-diagnosis&#34;&gt;&#xA;  🧠 1. Diagnosis&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-1-diagnosis&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Question answered:&lt;/strong&gt; &lt;em&gt;What is wrong with the patient?&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Machine learning identifies diseases or conditions based on input data.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Detecting pneumonia from a chest X-ray (image classification)&lt;/li&gt;&#xA;&lt;li&gt;Identifying arrhythmias from ECG waveforms&lt;/li&gt;&#xA;&lt;li&gt;Classifying skin lesions as malignant vs benign&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-2-prediction--prognosis&#34;&gt;&#xA;  📈 2. Prediction / Prognosis&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-2-prediction--prognosis&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Question answered:&lt;/strong&gt; &lt;em&gt;What will happen to the patient?&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ch4 EHR</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/hands-on-healthcare-data/ch4_ehr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/hands-on-healthcare-data/ch4_ehr/</guid>
      <description>&lt;h1 id=&#34;ch4-deep-dive--electronic-health-records-ehr---convsummary&#34;&gt;&#xA;  Ch4 Deep Dive – Electronic Health Records (EHR) - ConvSummary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ch4-deep-dive--electronic-health-records-ehr---convsummary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;-qa-style-logical-summary&#34;&gt;&#xA;  🔍 Q&amp;amp;A-Style Logical Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-qa-style-logical-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;q1-what-is-the-central-focus-of-chapter-4&#34;&gt;&#xA;  Q1: What is the central focus of Chapter 4?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-the-central-focus-of-chapter-4&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Chapter 4 focuses on working with electronic health record (EHR) data using the &lt;strong&gt;MIMIC-III&lt;/strong&gt; dataset, and explores &lt;strong&gt;medication harmonization&lt;/strong&gt; using SQL, Neo4j (property graph), and TypeDB (typed hypergraph).&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q2-what-makes-working-with-ehr-data-complex&#34;&gt;&#xA;  Q2: What makes working with EHR data complex?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-makes-working-with-ehr-data-complex&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;EHRs are &lt;strong&gt;highly structured&lt;/strong&gt; but vary between implementations.&lt;/li&gt;&#xA;&lt;li&gt;Data is often &lt;strong&gt;redundant, inconsistent, or missing&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Clinical context and domain knowledge are crucial for correct interpretation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q3-why-was-medication-harmonization-chosen-as-the-use-case&#34;&gt;&#xA;  Q3: Why was &lt;strong&gt;medication harmonization&lt;/strong&gt; chosen as the use case?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-why-was-medication-harmonization-chosen-as-the-use-case&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Because medications are objective and widely used in EHRs, but the &lt;strong&gt;same drug&lt;/strong&gt; can appear under multiple names or codes (e.g. NDCs). Harmonization is necessary to:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ch6 ML and Graph Analytics</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/hands-on-healthcare-data/ch6_graph_ml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/hands-on-healthcare-data/ch6_graph_ml/</guid>
      <description>&lt;h1 id=&#34;ch6-machine-learning--graph-based-analytics---convsummary&#34;&gt;&#xA;  Ch6 Machine Learning &amp;amp; Graph-Based Analytics - ConvSummary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ch6-machine-learning--graph-based-analytics---convsummary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;part-1-qa-summary&#34;&gt;&#xA;  Part 1: Q&amp;amp;A Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#part-1-qa-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-what-is-the-difference-between-cleaning-harmonization-and-feature-engineering&#34;&gt;&#xA;  1. What is the difference between cleaning, harmonization, and feature engineering?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-what-is-the-difference-between-cleaning-harmonization-and-feature-engineering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cleaning&lt;/strong&gt;: Removing errors or inconsistencies in the raw data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Harmonization&lt;/strong&gt;: Mapping and aligning data semantically across datasets (e.g., converting NDC to RxNorm).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Feature Engineering&lt;/strong&gt;: Transforming data to fit the needs of specific algorithms or analysis (e.g., PCA, one-hot encoding).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-why-are-graphs-more-useful-for-harmonization-than-feature-engineering&#34;&gt;&#xA;  2. Why are graphs more useful for harmonization than feature engineering?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-why-are-graphs-more-useful-for-harmonization-than-feature-engineering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Graphs help link concepts across vocabularies, terminologies, or systems.&lt;/li&gt;&#xA;&lt;li&gt;Feature engineering tends to be model-specific and harder to generalize.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-what-are-the-downsides-of-repeating-cleaningharmonization-for-each-project&#34;&gt;&#xA;  3. What are the downsides of repeating cleaning/harmonization for each project?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-what-are-the-downsides-of-repeating-cleaningharmonization-for-each-project&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Redundancy: Same steps are repeated across projects.&lt;/li&gt;&#xA;&lt;li&gt;Inefficiency: Each team member duplicates similar work.&lt;/li&gt;&#xA;&lt;li&gt;Inconsistency: No central source of truth for processed data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;4-what-is-a-feature-store-and-how-does-it-help&#34;&gt;&#xA;  4. What is a feature store and how does it help?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#4-what-is-a-feature-store-and-how-does-it-help&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A &lt;strong&gt;feature store&lt;/strong&gt; centralizes reusable, preprocessed features.&lt;/li&gt;&#xA;&lt;li&gt;Helps reduce redundancy and promotes consistency.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;5-how-do-knowledge-graphs-improve-the-pipeline&#34;&gt;&#xA;  5. How do knowledge graphs improve the pipeline?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#5-how-do-knowledge-graphs-improve-the-pipeline&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data is cleaned and harmonized once at the graph level.&lt;/li&gt;&#xA;&lt;li&gt;All downstream users can reuse the harmonized view via queries or APIs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;6-what-assumptions-are-made-when-using-a-knowledge-graph&#34;&gt;&#xA;  6. What assumptions are made when using a knowledge graph?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#6-what-assumptions-are-made-when-using-a-knowledge-graph&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Patient-level data and terminology concepts are stored in the same graph.&lt;/li&gt;&#xA;&lt;li&gt;Nodes/edges are tagged with metadata (e.g., timestamps, source).&lt;/li&gt;&#xA;&lt;li&gt;The graph is a supergraph enabling subgraph extraction.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;7-what-are-graph-embeddings-and-why-are-they-useful&#34;&gt;&#xA;  7. What are graph embeddings and why are they useful?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#7-what-are-graph-embeddings-and-why-are-they-useful&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They convert graph structures into vectors usable in ML models.&lt;/li&gt;&#xA;&lt;li&gt;Enable pattern detection, similarity analysis, and deep learning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;8-what-is-node2vec&#34;&gt;&#xA;  8. What is &lt;code&gt;node2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#8-what-is-node2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Random walk-based graph embedding technique.&lt;/li&gt;&#xA;&lt;li&gt;Uses return (p) and in-out (q) parameters to tune graph walk.&lt;/li&gt;&#xA;&lt;li&gt;Captures homophily and structural equivalence.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;9-what-is-cui2vec&#34;&gt;&#xA;  9. What is &lt;code&gt;cui2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#9-what-is-cui2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Embeds UMLS CUIs based on co-occurrence in various RWD sources.&lt;/li&gt;&#xA;&lt;li&gt;Context-aware (claims, notes, publications).&lt;/li&gt;&#xA;&lt;li&gt;Useful for understanding concept similarity.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;10-what-is-med2vec&#34;&gt;&#xA;  10. What is &lt;code&gt;med2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#10-what-is-med2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Uses temporal sequence of medical events to create visit-based embeddings.&lt;/li&gt;&#xA;&lt;li&gt;Retains longitudinal context.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;11-what-is-snomed2vec&#34;&gt;&#xA;  11. What is &lt;code&gt;snomed2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#11-what-is-snomed2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Embeds SNOMED CT concepts using hierarchical and network-based methods.&lt;/li&gt;&#xA;&lt;li&gt;Includes alternatives like metapath2vec and Poincaré embeddings.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;12-what-are-some-challenges-with-pretrained-embeddings&#34;&gt;&#xA;  12. What are some challenges with pretrained embeddings?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#12-what-are-some-challenges-with-pretrained-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Risk of overfitting to training data domain (e.g., CMS claims).&lt;/li&gt;&#xA;&lt;li&gt;May not generalize well to other populations or use cases.&lt;/li&gt;&#xA;&lt;li&gt;Introduces extra model layer to maintain and tune.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;part-2-curriculum-style-breakdown-with-why&#34;&gt;&#xA;  Part 2: Curriculum-Style Breakdown with &amp;ldquo;Why&amp;rdquo;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#part-2-curriculum-style-breakdown-with-why&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-phase-1-understand-the-motivation&#34;&gt;&#xA;  🧭 Phase 1: Understand the Motivation&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-1-understand-the-motivation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Read and distinguish between cleaning, harmonization, and feature engineering.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Clarifies each pipeline component and prevents misuse of graphs for tasks like feature engineering.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-2-explore-pipeline-challenges&#34;&gt;&#xA;  🧱 Phase 2: Explore Pipeline Challenges&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-2-explore-pipeline-challenges&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Analyze Figures 6-6 to 6-9 on pipeline repetition and inefficiency.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Understand how lack of standardization leads to duplicated efforts.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-3-learn-about-feature-stores&#34;&gt;&#xA;  🧠 Phase 3: Learn about Feature Stores&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-3-learn-about-feature-stores&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Study how feature stores centralize and reuse engineered features.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Saves time, increases reproducibility, and reduces tech debt.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-4-integrate-knowledge-graphs&#34;&gt;&#xA;  🌐 Phase 4: Integrate Knowledge Graphs&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-4-integrate-knowledge-graphs&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Understand what goes into a knowledge graph (patient data + ontologies).&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Enables one-time harmonization per data source, allowing scalable reuse.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-5-explore-graph-embedding-techniques&#34;&gt;&#xA;  🧩 Phase 5: Explore Graph Embedding Techniques&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-5-explore-graph-embedding-techniques&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Implement &lt;code&gt;node2vec&lt;/code&gt; on a small graph.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Learn homophily vs structural equivalence, key for biomedical graph reasoning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-6-biomedical-concept-embeddings&#34;&gt;&#xA;  🧬 Phase 6: Biomedical Concept Embeddings&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-6-biomedical-concept-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Compare and contrast &lt;code&gt;cui2vec&lt;/code&gt;, &lt;code&gt;med2vec&lt;/code&gt;, and &lt;code&gt;snomed2vec&lt;/code&gt;.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Appreciate how embeddings differ by data type (temporal, co-occurrence, hierarchical).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-7-real-world-concerns-with-embeddings&#34;&gt;&#xA;  ⚠️ Phase 7: Real-World Concerns with Embeddings&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-7-real-world-concerns-with-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Evaluate pretrained embeddings and consider limitations (overfitting, generalizability).&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Embeddings may look good on paper but can fail in new domains.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-8-apply-to-your-use-case&#34;&gt;&#xA;  🔁 Phase 8: Apply to Your Use Case&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-8-apply-to-your-use-case&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Pick a small real-world use case and simulate a pipeline using a knowledge graph and embedding.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Reinforces learning and identifies operational gaps in pipeline design.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>ChatGPT Prompt-Only vs OpenAI API &#43; Function Calling</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/ai_agents/openai_api_function_calling_comparison/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/ai_agents/openai_api_function_calling_comparison/</guid>
      <description>&lt;h1 id=&#34;chatgpt-prompt-only-vs-openai-api--function-calling&#34;&gt;&#xA;  ChatGPT Prompt-Only vs OpenAI API + Function Calling&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#chatgpt-prompt-only-vs-openai-api--function-calling&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document shows a side-by-side comparison between using ChatGPT manually (prompt-only) and using the OpenAI API with function calling.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-chatgpt-prompt-only--ui-version&#34;&gt;&#xA;  🟦 ChatGPT (Prompt-Only / UI Version)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-chatgpt-prompt-only--ui-version&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;This is what you do in the browser:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;User: What’s the weather in Paris?&#xA;&#xA;ChatGPT: The weather in Paris is likely mild and partly cloudy this time of year.&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;No function is actually called&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;The model &lt;strong&gt;guesses&lt;/strong&gt; based on training data&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Not real-time, not accurate, not programmable&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-openai-api--function-calling-version-working--realistic&#34;&gt;&#xA;  🟨 OpenAI API + Function Calling Version (Working + Realistic)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-openai-api--function-calling-version-working--realistic&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#179299&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#fe640b&#34;&gt;openai&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#179299&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#fe640b&#34;&gt;json&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;openai&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;api_key &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;your_api_key_here&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 1. Define the available function&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;functions &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; [&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;get_weather&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;description&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Get the current weather in a given city.&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;parameters&amp;#34;&lt;/span&gt;: {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;object&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;properties&amp;#34;&lt;/span&gt;: {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;city&amp;#34;&lt;/span&gt;: {&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;string&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;description&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Name of the city&amp;#34;&lt;/span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            },&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;required&amp;#34;&lt;/span&gt;: [&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;city&amp;#34;&lt;/span&gt;]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 2. Send user prompt + function list to GPT&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;response &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; openai&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;ChatCompletion&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;create(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;gpt-4-0613&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    messages&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;[{&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;What’s the weather in Paris?&amp;#34;&lt;/span&gt;}],&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    functions&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;functions,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    function_call&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;auto&amp;#34;&lt;/span&gt;  &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Let GPT decide&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 3. GPT returns a function call (it won&amp;#39;t run it)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;function_call &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; response[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;choices&amp;#34;&lt;/span&gt;][&lt;span style=&#34;color:#fe640b&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;function_call&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8839ef&#34;&gt;if&lt;/span&gt; function_call:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Parse the function name and arguments&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    fn_name &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; function_call[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    args &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; json&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;loads(function_call[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;arguments&amp;#34;&lt;/span&gt;])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 4. Run the function yourself (e.g., call a real API or simulate)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#8839ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#1e66f5&#34;&gt;get_weather&lt;/span&gt;(city):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# In reality, you&amp;#39;d call a weather API like OpenWeatherMap here&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#8839ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#d20f39&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;The current weather in &lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;{&lt;/span&gt;city&lt;span style=&#34;color:#40a02b&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt; is 68°F and sunny.&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    result &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; get_weather(args[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;city&amp;#34;&lt;/span&gt;])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 5. Send result back to GPT for natural language output&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    followup &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; openai&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;ChatCompletion&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;create(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        model&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;gpt-4-0613&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        messages&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;[&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            {&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;What’s the weather in Paris?&amp;#34;&lt;/span&gt;},&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            {&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;function&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: fn_name, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: result}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        ]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    )&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#04a5e5&#34;&gt;print&lt;/span&gt;(followup[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;choices&amp;#34;&lt;/span&gt;][&lt;span style=&#34;color:#fe640b&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;][&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8839ef&#34;&gt;else&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#04a5e5&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;GPT did not call a function.&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary-table&#34;&gt;&#xA;  🔍 Summary Table&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary-table&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Step&lt;/th&gt;&#xA;          &lt;th&gt;Prompt-Only (UI)&lt;/th&gt;&#xA;          &lt;th&gt;API + Function Calling&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Input&lt;/td&gt;&#xA;          &lt;td&gt;User types text prompt&lt;/td&gt;&#xA;          &lt;td&gt;Dev sends user prompt + function definitions&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Function selection&lt;/td&gt;&#xA;          &lt;td&gt;None — model guesses&lt;/td&gt;&#xA;          &lt;td&gt;GPT chooses from provided functions&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Execution&lt;/td&gt;&#xA;          &lt;td&gt;Not possible&lt;/td&gt;&#xA;          &lt;td&gt;Developer runs function (e.g., API call)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Output&lt;/td&gt;&#xA;          &lt;td&gt;Text only, not real-time&lt;/td&gt;&#xA;          &lt;td&gt;GPT formats real function output into natural reply&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Clinical Data Science</title>
      <link>http://localhost:1313/healthcare/clinical_ai/clinical_ai_usecase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/clinical_ai/clinical_ai_usecase/</guid>
      <description>&lt;h2 id=&#34;clinical-data-science&#34;&gt;&#xA;  Clinical Data Science&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#clinical-data-science&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;core-priority-retrieval-augmented-generation-rag&#34;&gt;&#xA;  Core Priority: Retrieval-Augmented Generation (RAG)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#core-priority-retrieval-augmented-generation-rag&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;RAG is one of the most in-demand skills in clinical GenAI due to:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The need to &lt;strong&gt;ground LLMs in real patient data&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Compliance, privacy, and traceability&lt;/li&gt;&#xA;&lt;li&gt;Applications like:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Clinical Question Answering&lt;/li&gt;&#xA;&lt;li&gt;Summarization of EHRs&lt;/li&gt;&#xA;&lt;li&gt;Evidence-based recommendations&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;key-tools&#34;&gt;&#xA;  Key Tools:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#key-tools&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Vector DBs&lt;/strong&gt;: Vertex AI Search, Pinecone, FAISS&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;LLMs&lt;/strong&gt;: Gemini, GPT-4, PaLM, Med-PaLM&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Frameworks&lt;/strong&gt;: LangChain, LlamaIndex, Vertex Extensions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;other-high-demand-skillsets&#34;&gt;&#xA;  Other High-Demand Skillsets&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#other-high-demand-skillsets&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Clinical NLP &amp;amp; Information Extraction&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clinical Text Feature Extraction Using Dictionary-Based Filtering</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/nlp_clinical_text/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/nlp_clinical_text/</guid>
      <description>&lt;h1 id=&#34;-clinical-text-feature-extraction-using-dictionary-based-filtering&#34;&gt;&#xA;  🧬 Clinical Text Feature Extraction Using Dictionary-Based Filtering&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-clinical-text-feature-extraction-using-dictionary-based-filtering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide demonstrates a simplified approach for processing clinical text &lt;strong&gt;without removing PHI directly&lt;/strong&gt;. Instead, it &lt;strong&gt;extracts only medical terms&lt;/strong&gt; from a predefined dictionary (simulated knowledge graph), which &lt;strong&gt;passively excludes PHI&lt;/strong&gt; and enables downstream analyses.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-objective&#34;&gt;&#xA;  ✅ Objective&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-objective&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Extract &lt;strong&gt;present, positive mentions&lt;/strong&gt; of clinical concepts (e.g., diseases, symptoms, drugs).&lt;/li&gt;&#xA;&lt;li&gt;Avoid mentions that are &lt;strong&gt;negated&lt;/strong&gt; or refer to &lt;strong&gt;historical/family context&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Demonstrate the principle: &lt;strong&gt;&amp;ldquo;Keep only medical terms&amp;rdquo;&lt;/strong&gt; as an alternative to direct PHI removal.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-input-example&#34;&gt;&#xA;  🧾 Input Example&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-input-example&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Patient complains of chest pain. No signs of pneumonia. History of diabetes mellitus.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Prescribed metformin. Mother had breast cancer.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-procedure-overview&#34;&gt;&#xA;  🧠 Procedure Overview&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-procedure-overview&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Define a &lt;strong&gt;medical term dictionary&lt;/strong&gt; (simulating a knowledge graph).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Split the clinical note&lt;/strong&gt; into sentences.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ignore sentences&lt;/strong&gt; with negation or irrelevant context.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Match and extract terms&lt;/strong&gt; from the dictionary.&lt;/li&gt;&#xA;&lt;li&gt;Output &lt;strong&gt;structured features&lt;/strong&gt; for downstream use.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-code-implementation-python&#34;&gt;&#xA;  🧪 Code Implementation (Python)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-code-implementation-python&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#179299&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#fe640b&#34;&gt;re&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 1. Simulated clinical note&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clinical_note &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;Patient complains of chest pain. No signs of pneumonia. History of diabetes mellitus.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;Prescribed metformin. Mother had breast cancer.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 2. Simulated knowledge graph (medical term dictionary)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;medical_terms &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;chest pain&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;symptom&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;pneumonia&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;disease&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;diabetes mellitus&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;disease&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;metformin&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;drug&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;breast cancer&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;disease&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 3. Split into sentences&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sentences &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#d20f39&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;\.\s*&amp;#39;&lt;/span&gt;, clinical_note&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;strip())&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;features &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; []&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 4. Process each sentence&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8839ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentences:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sentence_lower &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; sentence&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;lower()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 5. Skip negated or historical context&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#8839ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;no &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;history of&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;mother had&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#8839ef&#34;&gt;continue&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 6. Match medical terms&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#8839ef&#34;&gt;for&lt;/span&gt; term &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; medical_terms:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#8839ef&#34;&gt;if&lt;/span&gt; term &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            features&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;append({&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;term&amp;#34;&lt;/span&gt;: term,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;: medical_terms[term],&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;sentence&amp;#34;&lt;/span&gt;: sentence&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;strip()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            })&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 7. Output extracted features&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8839ef&#34;&gt;for&lt;/span&gt; feature &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; features:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#04a5e5&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#d20f39&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Found &lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;{&lt;/span&gt;feature[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#40a02b&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt; → &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;{&lt;/span&gt;feature[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;term&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#40a02b&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39; in: &lt;/span&gt;&lt;span style=&#34;color:#1e66f5&#34;&gt;\&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;{&lt;/span&gt;feature[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;sentence&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#40a02b&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#1e66f5&#34;&gt;\&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-sample-output&#34;&gt;&#xA;  📤 Sample Output&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-sample-output&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Found symptom → &amp;#39;chest pain&amp;#39; in: &amp;#34;Patient complains of chest pain&amp;#34;&#xA;Found drug → &amp;#39;metformin&amp;#39; in: &amp;#34;Prescribed metformin&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary&#34;&gt;&#xA;  📌 Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;This method:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clinical Text Mining Pipeline (Steps 1–5)</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/clinical_text_mining_pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/clinical_text_mining_pipeline/</guid>
      <description>&lt;h1 id=&#34;-clinical-text-mining-pipeline-steps-15&#34;&gt;&#xA;  🏥 Clinical Text Mining Pipeline (Steps 1–5)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-clinical-text-mining-pipeline-steps-15&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document outlines a high-level clinical text mining pipeline using knowledge graphs, NLP, and structured indexing. The goal is to extract, enrich, and analyze clinical concepts from raw EMR text.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-1-preprocessing-clinical-documents&#34;&gt;&#xA;  🧾 &lt;strong&gt;Step 1: Preprocessing Clinical Documents&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-1-preprocessing-clinical-documents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; Prepare and normalize clinical notes for processing.&lt;br&gt;&#xA;&lt;strong&gt;Tools:&lt;/strong&gt; Text cleaning, sentence segmentation, tokenizer.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Example: Clean and split into sentences&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#179299&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#fe640b&#34;&gt;re&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clinical_note &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Pt c/o chest pain. No signs of pneumonia. History of stroke. Prescribed metformin.&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sentences &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#d20f39&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;\.\s*&amp;#39;&lt;/span&gt;, clinical_note&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;lower())&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-2-extract-terms-using-knowledge-graph--nlp&#34;&gt;&#xA;  🧠 &lt;strong&gt;Step 2: Extract Terms Using Knowledge Graph + NLP&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-2-extract-terms-using-knowledge-graph--nlp&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; Identify medical terms using a knowledge graph and remove ambiguous, negated, or contextual mentions.&lt;br&gt;&#xA;&lt;strong&gt;Tools:&lt;/strong&gt; Knowledge Graph (e.g., UMLS), NegEx, ConText&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Quality, Labeling, and Weak Supervision in Clinical ML</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/data_quality_labeling_weak_supervision_qa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/data_quality_labeling_weak_supervision_qa/</guid>
      <description>&lt;h1 id=&#34;data-quality-labeling-and-weak-supervision-in-clinical-ml&#34;&gt;&#xA;  Data Quality, Labeling, and Weak Supervision in Clinical ML&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#data-quality-labeling-and-weak-supervision-in-clinical-ml&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;q1-what-does-garbage-in-garbage-out-mean-in-machine-learning&#34;&gt;&#xA;  Q1: What does &amp;ldquo;Garbage In, Garbage Out&amp;rdquo; mean in machine learning?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-does-garbage-in-garbage-out-mean-in-machine-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;It means that &lt;strong&gt;no model, no matter how advanced, can compensate for poor-quality data&lt;/strong&gt;. If your input data is noisy, biased, irrelevant, or mislabeled, your model will reflect those flaws.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;✅ The &lt;strong&gt;choice of data and problem&lt;/strong&gt; matters more than the algorithm itself.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;q2-can-large-rich-datasets-still-be-garbage&#34;&gt;&#xA;  Q2: Can large, rich datasets still be garbage?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-can-large-rich-datasets-still-be-garbage&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Yes — if the data is fundamentally flawed or based on faulty assumptions (like phrenology), more volume just means &lt;strong&gt;more noise&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diagnostic Metrics, Anchoring Perspectives, and Curve Interpretations</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/diagnostic_metrics_and_curves/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/diagnostic_metrics_and_curves/</guid>
      <description>&lt;h1 id=&#34;diagnostic-metrics-anchoring-perspectives-and-curve-interpretations&#34;&gt;&#xA;  Diagnostic Metrics, Anchoring Perspectives, and Curve Interpretations&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#diagnostic-metrics-anchoring-perspectives-and-curve-interpretations&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide summarizes the core diagnostic metrics based on anchoring logic (condition vs. prediction), and how these metrics relate to ROC and PR curves — especially under balanced vs. imbalanced class distributions.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-test-centric-metrics-anchored-on-actual-condition&#34;&gt;&#xA;  🔹 Test-Centric Metrics (Anchored on Actual Condition)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-test-centric-metrics-anchored-on-actual-condition&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Evaluates &lt;strong&gt;test performance&lt;/strong&gt;, &lt;strong&gt;independent&lt;/strong&gt; of disease prevalence.&lt;/li&gt;&#xA;&lt;li&gt;Anchor: &lt;strong&gt;Ground truth label&lt;/strong&gt; (actual condition).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;positive-focused-sensitivity&#34;&gt;&#xA;  Positive-Focused (Sensitivity)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#positive-focused-sensitivity&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fix actual &lt;strong&gt;Positive&lt;/strong&gt; label.&lt;/li&gt;&#xA;&lt;li&gt;Incorrect prediction: &lt;strong&gt;False Negative (FN)&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Pair: (TP, FN)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sensitivity&lt;/strong&gt; = TP / (TP + FN)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;negative-focused-specificity&#34;&gt;&#xA;  Negative-Focused (Specificity)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#negative-focused-specificity&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fix actual &lt;strong&gt;Negative&lt;/strong&gt; label.&lt;/li&gt;&#xA;&lt;li&gt;Incorrect prediction: &lt;strong&gt;False Positive (FP)&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Pair: (TN, FP)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Specificity&lt;/strong&gt; = TN / (TN + FP)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-outcome-centric-metrics-anchored-on-prediction&#34;&gt;&#xA;  🔸 Outcome-Centric Metrics (Anchored on Prediction)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-outcome-centric-metrics-anchored-on-prediction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Evaluates &lt;strong&gt;usefulness of test result&lt;/strong&gt;, dependent on &lt;strong&gt;both test performance and prevalence&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Anchor: &lt;strong&gt;Test result&lt;/strong&gt; (prediction output).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;positive-focused-ppv--precision&#34;&gt;&#xA;  Positive-Focused (PPV / Precision)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#positive-focused-ppv--precision&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fix &lt;strong&gt;Positive&lt;/strong&gt; prediction.&lt;/li&gt;&#xA;&lt;li&gt;Incorrect prediction: &lt;strong&gt;False Positive (FP)&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Pair: (TP, FP)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Positive Predictive Value (PPV)&lt;/strong&gt; = TP / (TP + FP)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;negative-focused-npv&#34;&gt;&#xA;  Negative-Focused (NPV)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#negative-focused-npv&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fix &lt;strong&gt;Negative&lt;/strong&gt; prediction.&lt;/li&gt;&#xA;&lt;li&gt;Incorrect prediction: &lt;strong&gt;False Negative (FN)&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Pair: (TN, FN)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Negative Predictive Value (NPV)&lt;/strong&gt; = TN / (TN + FN)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-extension-to-roc-and-pr-curves&#34;&gt;&#xA;  📊 Extension to ROC and PR Curves&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-extension-to-roc-and-pr-curves&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-roc-curve-receiver-operating-characteristic&#34;&gt;&#xA;  🎯 ROC Curve (Receiver Operating Characteristic)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-roc-curve-receiver-operating-characteristic&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;what-it-does&#34;&gt;&#xA;  What it does:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#what-it-does&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Plots &lt;strong&gt;True Positive Rate (TPR)&lt;/strong&gt; vs. &lt;strong&gt;False Positive Rate (FPR)&lt;/strong&gt; across thresholds.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;TPR = Sensitivity = TP / (TP + FN)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;FPR = 1 − Specificity = FP / (FP + TN)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;These metrics are calculated by conditioning on the &lt;strong&gt;actual class labels&lt;/strong&gt;, not predictions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;anchoring-view&#34;&gt;&#xA;  Anchoring View:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#anchoring-view&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;✅ &lt;strong&gt;Test-Centric / Condition-Anchored&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Starts from actual condition and evaluates how well the test distinguishes between classes.&lt;/li&gt;&#xA;&lt;li&gt;Independent of class imbalance in its calculation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;use-case&#34;&gt;&#xA;  Use Case:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#use-case&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Suitable when both positive and negative classes are equally important.&lt;/li&gt;&#xA;&lt;li&gt;Can be misleading in &lt;strong&gt;highly imbalanced&lt;/strong&gt; datasets (e.g., rare disease).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;-precision-recall-pr-curve&#34;&gt;&#xA;  📈 Precision-Recall (PR) Curve&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-precision-recall-pr-curve&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;what-it-does-1&#34;&gt;&#xA;  What it does:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#what-it-does-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Plots &lt;strong&gt;Precision (PPV)&lt;/strong&gt; vs. &lt;strong&gt;Recall (Sensitivity)&lt;/strong&gt; across thresholds.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Precision = TP / (TP + FP)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Recall = TP / (TP + FN)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;anchoring-view-1&#34;&gt;&#xA;  Anchoring View:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#anchoring-view-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;✅ &lt;strong&gt;Outcome-Centric / Prediction-Anchored&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Focuses on the model’s &lt;strong&gt;positive predictions&lt;/strong&gt; and how often they are correct.&lt;/li&gt;&#xA;&lt;li&gt;Particularly useful for evaluating performance on the &lt;strong&gt;positive class&lt;/strong&gt; in imbalanced datasets.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;use-case-1&#34;&gt;&#xA;  Use Case:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#use-case-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ideal for problems with &lt;strong&gt;class imbalance&lt;/strong&gt;, where the positive class is rare but important (e.g., cancer detection, fraud, anomaly detection).&lt;/li&gt;&#xA;&lt;li&gt;Answers: “When the model says positive, can I trust it?”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary-of-metric-anchors-and-curve-use&#34;&gt;&#xA;  🧠 Summary of Metric Anchors and Curve Use&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary-of-metric-anchors-and-curve-use&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Curve Type&lt;/th&gt;&#xA;          &lt;th&gt;Metrics Used&lt;/th&gt;&#xA;          &lt;th&gt;Anchored On&lt;/th&gt;&#xA;          &lt;th&gt;Evaluation Focus&lt;/th&gt;&#xA;          &lt;th&gt;Best For&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;ROC&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;TPR (Sensitivity), FPR&lt;/td&gt;&#xA;          &lt;td&gt;Actual condition&lt;/td&gt;&#xA;          &lt;td&gt;Discrimination ability&lt;/td&gt;&#xA;          &lt;td&gt;Balanced class settings&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;PR&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Precision (PPV), Recall&lt;/td&gt;&#xA;          &lt;td&gt;Prediction output&lt;/td&gt;&#xA;          &lt;td&gt;Precision of predictions&lt;/td&gt;&#xA;          &lt;td&gt;Imbalanced settings&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-takeaway&#34;&gt;&#xA;  💡 Takeaway:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-takeaway&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;ROC Curve&lt;/strong&gt; is a &lt;strong&gt;test-centric (condition-anchored)&lt;/strong&gt; tool: great for balanced data, focuses on test performance across thresholds.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;PR Curve&lt;/strong&gt; is an &lt;strong&gt;outcome-centric (prediction-anchored)&lt;/strong&gt; tool: best for imbalanced data, reflects how reliable positive predictions are.&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Ethics in AI for Healthcare</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/ethics_in_ai_healthcare_qna/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/ethics_in_ai_healthcare_qna/</guid>
      <description>&lt;h1 id=&#34;ethics-in-ai-for-healthcare-a-guided-qa-framework&#34;&gt;&#xA;  Ethics in AI for Healthcare: A Guided Q&amp;amp;A Framework&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ethics-in-ai-for-healthcare-a-guided-qa-framework&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document presents a structured chain-of-thought (CoT) using guiding questions and answers to understand ethical considerations in the development and deployment of AI in healthcare, based on Module 7 from the Stanford &amp;ldquo;Introduction to Clinical Data&amp;rdquo; course.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-why-is-ethics-important-in-the-context-of-ai-in-healthcare&#34;&gt;&#xA;  1. Why is ethics important in the context of AI in healthcare?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-is-ethics-important-in-the-context-of-ai-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Answer:&lt;/strong&gt;&lt;br&gt;&#xA;AI tools impact patients directly or indirectly, whether through their development (research) or their deployment (clinical practice). Each of these domains carries different ethical responsibilities that must be considered and governed carefully.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Foundation Models for Healthcare</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/foundatoin_model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/foundatoin_model/</guid>
      <description>&lt;h2 id=&#34;foundation-models-for-healthcare&#34;&gt;&#xA;  Foundation Models for Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#foundation-models-for-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;what-are-foundation-models&#34;&gt;&#xA;  What are Foundation Models?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#what-are-foundation-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Foundation models are trained on massive amounts of &lt;strong&gt;unlabeled data&lt;/strong&gt; using &lt;strong&gt;self-supervised&lt;/strong&gt; or &lt;strong&gt;unsupervised learning&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;They are &amp;ldquo;foundational&amp;rdquo; because they can be &lt;strong&gt;adapted to multiple downstream tasks&lt;/strong&gt; with high efficiency and minimal data.&lt;/li&gt;&#xA;&lt;li&gt;They demonstrate &lt;strong&gt;sample efficiency&lt;/strong&gt; and can handle multiple modalities like text, images, genomics, etc.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;few-shot-vs-zero-shot-learning&#34;&gt;&#xA;  Few-Shot vs. Zero-Shot Learning&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#few-shot-vs-zero-shot-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Few-Shot Learning&lt;/strong&gt;: Learns from just a few labeled examples per class and generalizes to new examples.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Zero-Shot Learning&lt;/strong&gt;: Learns to perform tasks it hasn’t seen in training, relying on general knowledge from pretraining.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;➡️  These abilities allow foundation models to generalize efficiently across healthcare tasks, even with limited supervision.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Healthcare Data Layers</title>
      <link>http://localhost:1313/healthcare/data/healthcare_data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/data/healthcare_data/</guid>
      <description>&lt;h2 id=&#34;healthcare-data-layers&#34;&gt;&#xA;  Healthcare Data Layers&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#healthcare-data-layers&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1--data-sources-raw-data--collection-level&#34;&gt;&#xA;  1️⃣  &lt;strong&gt;Data Sources (Raw Data &amp;amp; Collection Level)&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1--data-sources-raw-data--collection-level&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;These are the foundational data sources used in healthcare analysis, originating from clinical trials, hospitals, insurance claims, and patient records.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Clinical Data (RCTs, EHR, OMOP, CDM)&lt;/strong&gt; – Structured, controlled, and often randomized data used for regulatory and research applications.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Real-World Data (RWD: EHR, Claims, Registries)&lt;/strong&gt; – Observational and confounded, requiring advanced causal inference methods to extract meaningful insights.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Relationship:&lt;/strong&gt; Clinical Data is typically highly structured and standardized, whereas RWD is heterogeneous, requiring bias correction.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2--data-management--standardization-processing--infrastructure-level&#34;&gt;&#xA;  2️⃣  &lt;strong&gt;Data Management &amp;amp; Standardization (Processing &amp;amp; Infrastructure Level)&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2--data-management--standardization-processing--infrastructure-level&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;This layer ensures that raw clinical &amp;amp; real-world data are cleaned, structured, and made interoperable for analysis.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Healthcare Data Sources</title>
      <link>http://localhost:1313/healthcare/data/healthcare_sources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/data/healthcare_sources/</guid>
      <description>&lt;h1 id=&#34;healthcare-data-sources&#34;&gt;&#xA;  Healthcare Data Sources&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#healthcare-data-sources&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;phenotype-knowledgebase-phekb&#34;&gt;&#xA;  &lt;a href=&#34;https://www.phekb.org/&#34;&gt;Phenotype KnowledgeBase (PheKB)&lt;/a&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#phenotype-knowledgebase-phekb&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;:&lt;br&gt;&#xA;A collaborative portal for sharing and validating electronic phenotype definitions used in observational health research.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Tags&lt;/strong&gt;: &lt;code&gt;phenotyping&lt;/code&gt;, &lt;code&gt;EHR&lt;/code&gt;, &lt;code&gt;cohort definitions&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Standardized phenotype definitions for conditions like diabetes, asthma, etc.&lt;/li&gt;&#xA;&lt;li&gt;Sharing phenotype algorithms across institutions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;mimic-iv-medical-information-mart-for-intensive-care&#34;&gt;&#xA;  &lt;a href=&#34;https://physionet.org/content/mimiciv/&#34;&gt;MIMIC-IV (Medical Information Mart for Intensive Care)&lt;/a&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mimic-iv-medical-information-mart-for-intensive-care&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;:&lt;br&gt;&#xA;A large, publicly available critical care database containing de-identified health data from ICU patients at the Beth Israel Deaconess Medical Center.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Healthcare Use Cases for Non-textual Unstructured Data</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/healthcare_use_cases_for_non_textual_unstructured_data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/healthcare_use_cases_for_non_textual_unstructured_data/</guid>
      <description>&lt;h1 id=&#34;healthcare-use-cases-for-non-textual-unstructured-data&#34;&gt;&#xA;  Healthcare Use Cases for Non-textual Unstructured Data&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#healthcare-use-cases-for-non-textual-unstructured-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-are-foundation-models-limited-to-text&#34;&gt;&#xA;  1. Are foundation models limited to text?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-are-foundation-models-limited-to-text&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;No. Although many early applications focus on text, foundation models are inherently multimodal. They can process and learn from images, audio, video, and other forms of unstructured data without modifying the core model.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-what-kind-of-unstructured-data-exists-in-healthcare-beyond-text&#34;&gt;&#xA;  2. What kind of unstructured data exists in healthcare beyond text?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-kind-of-unstructured-data-exists-in-healthcare-beyond-text&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Medical images&lt;/strong&gt;: X-rays, CT, MRI&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Audio data&lt;/strong&gt;: Patient speech, clinical voice notes&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Video data&lt;/strong&gt;: Endoscopy, movement assessments&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Digital pathology&lt;/strong&gt; and &lt;strong&gt;genomic data&lt;/strong&gt;: High-resolution slides and sequence strings&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;3-how-do-image-text-foundation-models-work-in-healthcare&#34;&gt;&#xA;  3. How do image-text foundation models work in healthcare?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-how-do-image-text-foundation-models-work-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;They learn from &lt;strong&gt;paired image and text data&lt;/strong&gt; (e.g., medical images and associated reports) to understand content holistically. This allows for better diagnostic performance and contextual understanding than single-modality models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Healthcare Use Cases for Text Data</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/healthcare_use_cases_for_text_data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/healthcare_use_cases_for_text_data/</guid>
      <description>&lt;h1 id=&#34;healthcare-use-cases-for-text-data&#34;&gt;&#xA;  Healthcare Use Cases for Text Data&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#healthcare-use-cases-for-text-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-can-large-language-models-like-chatgpt-perform-at-a-physician-level&#34;&gt;&#xA;  1. Can large language models like ChatGPT perform at a physician level?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-can-large-language-models-like-chatgpt-perform-at-a-physician-level&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Yes. ChatGPT has demonstrated performance comparable to expert physicians on tasks like the USMLE medical board exam. This raises important questions about the evolving role of human expertise in healthcare as LLMs continue to advance.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-should-llms-be-integrated-into-medical-training-or-exams&#34;&gt;&#xA;  2. Should LLMs be integrated into medical training or exams?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-should-llms-be-integrated-into-medical-training-or-exams&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Possibly. LLMs could enhance the medical licensing exam process by reflecting real-world clinical scenarios. However, it&amp;rsquo;s essential for healthcare professionals to understand their benefits and limitations before full integration.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How Foundation Models Work</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/how_foundation_models_work_in_healthcare_applications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/how_foundation_models_work_in_healthcare_applications/</guid>
      <description>&lt;h1 id=&#34;how-foundation-models-work-in-healthcare-applications&#34;&gt;&#xA;  How Foundation Models Work (in Healthcare Applications)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#how-foundation-models-work-in-healthcare-applications&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-what-are-foundation-models-and-why-are-large-language-models-llms-a-key-example&#34;&gt;&#xA;  1. What are foundation models and why are large language models (LLMs) a key example?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-what-are-foundation-models-and-why-are-large-language-models-llms-a-key-example&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Foundation models are large-scale machine learning models trained on vast and diverse datasets, enabling them to perform well across multiple tasks. Large Language Models (LLMs) like GPT are a major class of these, powering tools like ChatGPT and being early, widely successful examples.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-what-architecture-do-foundation-models-especially-llms-rely-on&#34;&gt;&#xA;  2. What architecture do foundation models, especially LLMs, rely on?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-architecture-do-foundation-models-especially-llms-rely-on&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;They rely heavily on the &lt;strong&gt;Transformer architecture&lt;/strong&gt;, introduced in the paper &lt;em&gt;“Attention Is All You Need”&lt;/em&gt;. This architecture uses &lt;strong&gt;self-attention&lt;/strong&gt; mechanisms to allow models to learn relationships across sequences of data, making them highly effective for tasks involving language and other sequential data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Missing Data Scenarios in Healthcare Modeling</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/missing_values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/missing_values/</guid>
      <description>&lt;h1 id=&#34;missing-data-scenarios-in-healthcare-modeling&#34;&gt;&#xA;  Missing Data Scenarios in Healthcare Modeling&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#missing-data-scenarios-in-healthcare-modeling&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-should-be-measured-but-wasnt&#34;&gt;&#xA;  1. Should Be Measured But Wasn’t&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-should-be-measured-but-wasnt&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: The value is expected but is missing due to random or procedural issues (e.g., lab error, missed test).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Technical Term&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;MCAR&lt;/strong&gt;: Missing Completely At Random&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MAR&lt;/strong&gt;: Missing At Random&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: A routine blood test wasn&amp;rsquo;t recorded because the sample was lost.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Impute (mean, median, or model-based).&lt;/li&gt;&#xA;&lt;li&gt;Add a missingness indicator variable (e.g., &lt;code&gt;var_missing = 1&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: The missingness is unrelated to the value itself, so estimation is relatively safe.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-mostly-zero-due-to-rare-occurrence&#34;&gt;&#xA;  2. Mostly Zero Due to Rare Occurrence&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-mostly-zero-due-to-rare-occurrence&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: Not truly missing — the value is &lt;strong&gt;zero or absent&lt;/strong&gt; for most patients because the condition/event is rare.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Technical Term&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Not Missing (No abbreviation needed)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: HIV diagnosis column is &lt;code&gt;0&lt;/code&gt; for most patients.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Do not impute&lt;/strong&gt; — the 0s are meaningful and reflect true absence.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: These are real values, and zeros carry clinical meaning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;3-deliberately-not-recorded&#34;&gt;&#xA;  3. Deliberately Not Recorded&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-deliberately-not-recorded&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: Clinician or system &lt;strong&gt;chooses not to record&lt;/strong&gt; a value based on context (e.g., patient clearly stable or too ill).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Technical Term&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;MNAR&lt;/strong&gt;: Missing Not At Random&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: Sodium level not tested because the patient was clearly stable.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Avoid imputation if possible — it may introduce bias.&lt;/li&gt;&#xA;&lt;li&gt;Use models that handle missingness natively (e.g., decision trees, XGBoost, LightGBM).&lt;/li&gt;&#xA;&lt;li&gt;Consider adding a missingness indicator.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: The missingness &lt;em&gt;depends on the unobserved value&lt;/em&gt; and may carry predictive signal.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;summary-table&#34;&gt;&#xA;  Summary Table&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#summary-table&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Case&lt;/th&gt;&#xA;          &lt;th&gt;Description&lt;/th&gt;&#xA;          &lt;th&gt;Abbreviation&lt;/th&gt;&#xA;          &lt;th&gt;Impute?&lt;/th&gt;&#xA;          &lt;th&gt;Extra Notes&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;Should be measured but wasn’t&lt;/td&gt;&#xA;          &lt;td&gt;MCAR / MAR&lt;/td&gt;&#xA;          &lt;td&gt;✅ Yes&lt;/td&gt;&#xA;          &lt;td&gt;Add indicator if signal is likely&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;Mostly zero (rare condition)&lt;/td&gt;&#xA;          &lt;td&gt;Not Missing&lt;/td&gt;&#xA;          &lt;td&gt;🚫 No&lt;/td&gt;&#xA;          &lt;td&gt;Keep as is — zeros are informative&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;          &lt;td&gt;Deliberately not recorded&lt;/td&gt;&#xA;          &lt;td&gt;MNAR&lt;/td&gt;&#xA;          &lt;td&gt;⚠️ Caution&lt;/td&gt;&#xA;          &lt;td&gt;Use native handling + possible indicator&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>OMOP vs. RLHF</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/omop_vs_rlhf_comparison/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/omop_vs_rlhf_comparison/</guid>
      <description>&lt;h1 id=&#34;omop-vs-rlhf-a-side-by-side-comparison&#34;&gt;&#xA;  OMOP vs. RLHF: A Side-by-Side Comparison&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#omop-vs-rlhf-a-side-by-side-comparison&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document compares &lt;strong&gt;OMOP (Observational Medical Outcomes Partnership)&lt;/strong&gt; in healthcare with &lt;strong&gt;RLHF (Reinforcement Learning from Human Feedback)&lt;/strong&gt; in generative AI, focusing on their structures, purposes, and alignment with Learning Health System (LHS) principles.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary-table&#34;&gt;&#xA;  🔍 Summary Table&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary-table&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Aspect&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;OMOP (Healthcare)&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;RLHF (GenAI)&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Domain&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Clinical/healthcare data&lt;/td&gt;&#xA;          &lt;td&gt;Natural language modeling&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Purpose&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Standardize and structure real-world patient data for learning, analytics, and AI&lt;/td&gt;&#xA;          &lt;td&gt;Align AI model behavior with human preferences and values&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Core Process&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;ETL (Extract-Transform-Load) clinical data into a common format for analysis&lt;/td&gt;&#xA;          &lt;td&gt;Fine-tune a pretrained LLM using human-labeled preferences or rewards&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Data Source&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;EHRs, claims, labs, devices&lt;/td&gt;&#xA;          &lt;td&gt;Human judgments on AI-generated outputs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Feedback Type&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Structured medical events (diagnoses, drugs, labs, etc.)&lt;/td&gt;&#xA;          &lt;td&gt;Human preference signals on outputs (better/worse answers)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Learning Method&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Enables observational &amp;amp; causal learning from patient data&lt;/td&gt;&#xA;          &lt;td&gt;Reinforcement learning from ranked or scored examples&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Governance Layer&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Ethics via IRB, consent, privacy laws&lt;/td&gt;&#xA;          &lt;td&gt;Ethics via safety research, alignment goals, red-teaming&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Use in Feedback Loops&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;LHS uses OMOP to “learn from care to improve care”&lt;/td&gt;&#xA;          &lt;td&gt;RLHF uses feedback to “teach the model to behave better”&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-conceptual-analogy&#34;&gt;&#xA;  🔁 Conceptual Analogy&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-conceptual-analogy&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;OMOP + Learning Health System (LHS)&lt;/strong&gt; is to the health system&lt;br&gt;&#xA;as&lt;br&gt;&#xA;&lt;strong&gt;RLHF&lt;/strong&gt; is to a generative AI model.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Output-Action Pairing (OAP) Framework in Healthcare</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/oap_framework_healthcare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/oap_framework_healthcare/</guid>
      <description>&lt;h1 id=&#34;-output-action-pairing-oap-framework-in-healthcare&#34;&gt;&#xA;  🧠 Output-Action Pairing (OAP) Framework in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-output-action-pairing-oap-framework-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide provides real-world examples of the Output-Action Pairing (OAP) framework: aligning machine learning model &lt;strong&gt;outputs&lt;/strong&gt; with &lt;strong&gt;concrete clinical actions&lt;/strong&gt; to improve care.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-oap-template&#34;&gt;&#xA;  📋 OAP Template&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-oap-template&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Output (Prediction)&lt;/th&gt;&#xA;          &lt;th&gt;Action Taken&lt;/th&gt;&#xA;          &lt;th&gt;Who Acts&lt;/th&gt;&#xA;          &lt;th&gt;Why It Helps&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;What the model predicts&lt;/td&gt;&#xA;          &lt;td&gt;The clinical step or decision triggered&lt;/td&gt;&#xA;          &lt;td&gt;The role/team responsible&lt;/td&gt;&#xA;          &lt;td&gt;How it improves outcomes or safety&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-real-world-examples&#34;&gt;&#xA;  ✅ Real-World Examples&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-real-world-examples&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-sepsis-prediction&#34;&gt;&#xA;  1. Sepsis Prediction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-sepsis-prediction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; High risk of sepsis in next 6 hours&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Alert care team, initiate fluids/labs/antibiotics&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Rapid response team (nurses + physicians)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Early treatment improves survival&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2-readmission-risk-score&#34;&gt;&#xA;  2. Readmission Risk Score&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-readmission-risk-score&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; 30% chance of readmission within 30 days&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Extra discharge planning, follow-up calls, medication check&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Care coordinator + pharmacist&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Reduces avoidable readmissions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;3-pneumothorax-detection-on-chest-x-ray&#34;&gt;&#xA;  3. Pneumothorax Detection on Chest X-ray&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-pneumothorax-detection-on-chest-x-ray&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; Pneumothorax detected&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Immediate flag to radiologist and ER for review&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Radiologist + ER team&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Enables life-saving chest tube intervention&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;4-covid-19-triage&#34;&gt;&#xA;  4. COVID-19 Triage&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#4-covid-19-triage&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; High risk of severe COVID progression&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; ICU evaluation, enhanced monitoring, begin treatment&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Hospitalist or ICU triage physician&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Allocates ICU resources effectively&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;5-fall-risk-in-hospital&#34;&gt;&#xA;  5. Fall Risk in Hospital&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#5-fall-risk-in-hospital&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; High fall risk during admission&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Enable fall precautions (alarms, sitter, etc.)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Nursing team&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Prevents injury and hospital complications&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;6-stroke-detection-via-ct&#34;&gt;&#xA;  6. Stroke Detection via CT&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#6-stroke-detection-via-ct&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; Acute stroke suspected on scan&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Notify neurologist, activate stroke protocol (tPA window)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Radiologist + Stroke Response Team&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Reduces time to brain-saving treatment&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary&#34;&gt;&#xA;  🔄 Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The OAP framework ensures that ML predictions &lt;strong&gt;translate to action&lt;/strong&gt;, improving &lt;strong&gt;clinical relevance&lt;/strong&gt; and &lt;strong&gt;patient safety&lt;/strong&gt;. Every model in healthcare should answer:&lt;/p&gt;</description>
    </item>
    <item>
      <title>PPO in LLMs vs PPO in Walker2D</title>
      <link>http://localhost:1313/ai-workflows/alignment-reasoning/rlhf/comparison_ppo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/alignment-reasoning/rlhf/comparison_ppo/</guid>
      <description>&lt;h2 id=&#34;-understanding-ppo-from-language-generation-to-robot-control--code-concepts-and-comparisons&#34;&gt;&#xA;  🤖🦿 Understanding PPO: From Language Generation to Robot Control — Code, Concepts, and Comparisons&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-understanding-ppo-from-language-generation-to-robot-control--code-concepts-and-comparisons&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Proximal Policy Optimization (PPO)&lt;/strong&gt; in both large language models (LLMs, e.g., GPT-style) and classical control environments (e.g., Walker2D), focusing on the structure of the PPO update and how actions are selected during inference.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1--ppo-step-call--argument-by-argument-breakdown&#34;&gt;&#xA;  1. 🧾 PPO &lt;code&gt;step()&lt;/code&gt; Call — Argument-by-Argument Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1--ppo-step-call--argument-by-argument-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ppo_trainer&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;step(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    queries&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;[input_ids[&lt;span style=&#34;color:#fe640b&#34;&gt;0&lt;/span&gt;]],       &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Prompt (tokenized) — represents the current state&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    responses&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;[response_ids[&lt;span style=&#34;color:#fe640b&#34;&gt;0&lt;/span&gt;]],  &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Generated tokens — represents the action taken&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    rewards&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt;[reward]              &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Scalar from reward model — score for that action&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;mapping-to-classic-rl-walker2d&#34;&gt;&#xA;  Mapping to Classic RL (Walker2D)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mapping-to-classic-rl-walker2d&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;PPO Argument&lt;/th&gt;&#xA;          &lt;th&gt;🤖 LLM (RLHF)&lt;/th&gt;&#xA;          &lt;th&gt;🦿 Walker2D (Classic RL)&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;code&gt;queries = [input_ids[0]]&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Prompt as input (discrete tokenized state)&lt;/td&gt;&#xA;          &lt;td&gt;Robot&amp;rsquo;s continuous state (joint angles, velocities)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;code&gt;responses = [response_ids[0]]&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Generated tokens (sequence of actions)&lt;/td&gt;&#xA;          &lt;td&gt;Applied joint torques (vector of real numbers)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;code&gt;rewards = [reward]&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Reward model output (alignment score)&lt;/td&gt;&#xA;          &lt;td&gt;Environment reward (e.g., distance walked)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2--action-selection-in-ppo&#34;&gt;&#xA;  2. 🎯 Action Selection in PPO&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2--action-selection-in-ppo&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;How does the agent choose its next action, given a state/prompt?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Rule-Based Electronic Phenotyping Example: Type 2 Diabetes</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/diabetes_phenotype_pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c2_clinical_data/diabetes_phenotype_pipeline/</guid>
      <description>&lt;h1 id=&#34;rule-based-electronic-phenotyping-example-type-2-diabetes&#34;&gt;&#xA;  Rule-Based Electronic Phenotyping Example: Type 2 Diabetes&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#rule-based-electronic-phenotyping-example-type-2-diabetes&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This notebook walks through the process of defining an &lt;strong&gt;electronic phenotype&lt;/strong&gt; using a &lt;strong&gt;rule-based&lt;/strong&gt; approach, with a focus on &lt;strong&gt;Type 2 Diabetes&lt;/strong&gt;. The pipeline includes concept mapping, multi-patient evaluation, and phenotype logic visualization.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-1-simulated-vocabulary-lookup-umls--omop&#34;&gt;&#xA;  🔹 Step 1: Simulated Vocabulary Lookup (UMLS / OMOP)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-1-simulated-vocabulary-lookup-umls--omop&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;We define the clinical concept (Type 2 Diabetes) using relevant ICD-10 and RxNorm codes.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Simulated UMLS/OMOP vocab mapping&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;UMLS_LOOKUP &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;type2_diabetes&amp;#34;&lt;/span&gt;: {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;icd10&amp;#34;&lt;/span&gt;: {&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;E11.9&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;E11.65&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;E11.00&amp;#34;&lt;/span&gt;},&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;rxnorm&amp;#34;&lt;/span&gt;: {&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;metformin&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;insulin&amp;#34;&lt;/span&gt;},&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-2-multi-patient-phenotyping-logic&#34;&gt;&#xA;  🔹 Step 2: Multi-Patient Phenotyping Logic&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-2-multi-patient-phenotyping-logic&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Each patient is checked for:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tradeoffs in Machine Learning: Precision vs. Recall in Healthcare</title>
      <link>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/precision_vs_recall_in_healthcare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/domain_knowledge/ai-in-healthcare/c3_ml_healthcare/precision_vs_recall_in_healthcare/</guid>
      <description>&lt;h1 id=&#34;tradeoffs-in-machine-learning-precision-vs-recall-in-healthcare&#34;&gt;&#xA;  Tradeoffs in Machine Learning: Precision vs. Recall in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#tradeoffs-in-machine-learning-precision-vs-recall-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide summarizes two key scenarios in healthcare where we might prefer:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;High Precision but Lower Recall&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;High Recall but Lower Precision&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-high-precision-lower-recall&#34;&gt;&#xA;  (1) High Precision, Lower Recall&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-high-precision-lower-recall&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-when-to-use&#34;&gt;&#xA;  ✅ When to Use:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-when-to-use&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When &lt;strong&gt;false positives are costly or harmful&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;When &lt;strong&gt;resources are limited&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;In &lt;strong&gt;early screening/filtering stages&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-justification&#34;&gt;&#xA;  📌 Justification:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-justification&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You want to be &lt;strong&gt;very confident&lt;/strong&gt; before taking action.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Missing some real cases&lt;/strong&gt; is acceptable if &lt;strong&gt;wrongly flagging someone&lt;/strong&gt; leads to &lt;strong&gt;emotional, financial, or clinical harm&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-examples&#34;&gt;&#xA;  💡 Examples:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-examples&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Genetic Testing for Rare Diseases&lt;/strong&gt;: Only flag patients when you&amp;rsquo;re very sure. A false positive could cause unnecessary panic or life changes.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;ICU Bed Allocation&lt;/strong&gt;: If you only have 5 beds, you’d want to use them for patients who are most certainly critical.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Drug Discovery Pre-Screening&lt;/strong&gt;: Select molecules that are most likely to work, even if some potential candidates are missed.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-high-recall-lower-precision&#34;&gt;&#xA;  (2) High Recall, Lower Precision&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-high-recall-lower-precision&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-when-to-use-1&#34;&gt;&#xA;  ✅ When to Use:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-when-to-use-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When &lt;strong&gt;missing a real case is dangerous&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;When &lt;strong&gt;early detection can improve outcomes&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;When &lt;strong&gt;follow-up tests or actions are safe and cheap&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-justification-1&#34;&gt;&#xA;  📌 Justification:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-justification-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It&amp;rsquo;s better to &lt;strong&gt;catch every possible case&lt;/strong&gt;, even if you have some false alarms.&lt;/li&gt;&#xA;&lt;li&gt;Especially important in &lt;strong&gt;serious or rapidly progressing conditions&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-examples-1&#34;&gt;&#xA;  💡 Examples:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-examples-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cancer Screening&lt;/strong&gt;: Better to flag more patients for follow-up than miss someone with early-stage cancer.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sepsis Prediction in ER&lt;/strong&gt;: Alerting the care team early—even with some false alarms—can save lives.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;COVID-19 Testing in High-Risk Areas&lt;/strong&gt;: Broad detection to prevent spread, even if some healthy people test positive.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary-table&#34;&gt;&#xA;  🧠 Summary Table&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary-table&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Scenario&lt;/th&gt;&#xA;          &lt;th&gt;Priority&lt;/th&gt;&#xA;          &lt;th&gt;Justification&lt;/th&gt;&#xA;          &lt;th&gt;Example&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;High Precision, Lower Recall&lt;/td&gt;&#xA;          &lt;td&gt;Precision 🟢&lt;/td&gt;&#xA;          &lt;td&gt;Avoid harm/cost from false positives&lt;/td&gt;&#xA;          &lt;td&gt;Genetic testing, ICU triage&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;High Recall, Lower Precision&lt;/td&gt;&#xA;          &lt;td&gt;Recall 🟢&lt;/td&gt;&#xA;          &lt;td&gt;Avoid missing critical or contagious conditions&lt;/td&gt;&#xA;          &lt;td&gt;Cancer screening, sepsis alert&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Transformer Attention: Full Conceptual Breakdown</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/transformer_attention_concepts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/transformer_attention_concepts/</guid>
      <description>&lt;h1 id=&#34;transformer-attention-full-conceptual-breakdown&#34;&gt;&#xA;  Transformer Attention: Full Conceptual Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#transformer-attention-full-conceptual-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document summarizes an in-depth discussion on attention mechanisms in Transformers, with a special focus on vocabulary embeddings, Q/K/V matrices, and multi-head attention.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-1-understanding-the-self-attention-image&#34;&gt;&#xA;  📌 1. Understanding the Self-Attention Image&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-1-understanding-the-self-attention-image&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The image shows a &lt;strong&gt;single-head self-attention&lt;/strong&gt; computation.&lt;/li&gt;&#xA;&lt;li&gt;Each &lt;strong&gt;row&lt;/strong&gt; is a token (element) at a &lt;strong&gt;position&lt;/strong&gt;, with a feature vector (embedding).&lt;/li&gt;&#xA;&lt;li&gt;The &lt;strong&gt;attention weights&lt;/strong&gt; (left column) are used to compute a &lt;strong&gt;weighted sum&lt;/strong&gt; over these vectors.&lt;/li&gt;&#xA;&lt;li&gt;The final output vector is shown at the bottom — this is the attention output for one token.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-2-element-vs-position&#34;&gt;&#xA;  🔍 2. Element vs. Position&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-2-element-vs-position&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Element&lt;/strong&gt;: the actual word or token in the input sequence.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Position&lt;/strong&gt;: the index of the element in the sequence.&lt;/li&gt;&#xA;&lt;li&gt;Though tightly coupled (1:1), they are conceptually different.&lt;/li&gt;&#xA;&lt;li&gt;Transformers rely on &lt;strong&gt;positional encoding&lt;/strong&gt; to retain order, since attention alone is orderless.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-3-how-attention-scores-are-computed&#34;&gt;&#xA;  🤖 3. How Attention Scores Are Computed&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-3-how-attention-scores-are-computed&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Input embeddings X&lt;/strong&gt; are projected into:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding How to Use BERT&#39;s CLS Token for Classification</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/bert_cls_classification_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/bert_cls_classification_summary/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Date:&lt;/strong&gt; 2025-03-31&lt;/p&gt;&#xA;&lt;h2 id=&#34;-question&#34;&gt;&#xA;  ❓ Question&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-question&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;How can we use the &lt;code&gt;[CLS]&lt;/code&gt; token (i.e., &lt;code&gt;h_cls&lt;/code&gt;) from the last layer of BERT for classification tasks? Given that the BERT output has shape &lt;code&gt;[batch_size, sequence_length, hidden_size]&lt;/code&gt;, how is it valid to pass only &lt;code&gt;[batch_size, hidden_size]&lt;/code&gt; to a &lt;code&gt;nn.Linear(hidden_size, num_classes)&lt;/code&gt; without flattening the sequence? And why don&amp;rsquo;t we flatten the whole sequence — wouldn&amp;rsquo;t that destroy order?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-answer&#34;&gt;&#xA;  ✅ Answer&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-answer&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-bert-output-and-the-cls-token&#34;&gt;&#xA;  🔹 BERT Output and the &lt;code&gt;[CLS]&lt;/code&gt; Token&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-bert-output-and-the-cls-token&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;BERT outputs a tensor of shape:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Self-Attention in Transformers: A Visual Breakdown</title>
      <link>http://localhost:1313/ai-workflows/genai-systems/self_attention_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ai-workflows/genai-systems/self_attention_summary/</guid>
      <description>&lt;h1 id=&#34;-understanding-self-attention-in-transformers-a-visual-breakdown&#34;&gt;&#xA;  🔍 Understanding Self-Attention in Transformers: A Visual Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-understanding-self-attention-in-transformers-a-visual-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document summarizes key questions about self-attention, embedding vectors, positions, and the input matrix in Transformers — using the image you provided as the foundation.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-what-is-happening-in-the-diagram&#34;&gt;&#xA;  🧠 What Is Happening in the Diagram?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-what-is-happening-in-the-diagram&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The figure shows how &lt;strong&gt;self-attention&lt;/strong&gt; computes the output for a specific position (&amp;ldquo;detection&amp;rdquo;) by:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Generating &lt;strong&gt;attention weights&lt;/strong&gt; between that position and &lt;strong&gt;all other positions&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Using those weights to compute a &lt;strong&gt;weighted sum&lt;/strong&gt; of the input feature vectors.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/attention.png&#34; alt=&#34;Self-Attention Diagram&#34; /&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why Clinical NLP &amp; GenAI Are Growing in Healthcare</title>
      <link>http://localhost:1313/healthcare/clinical_ai/why_clinical_ai/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/healthcare/clinical_ai/why_clinical_ai/</guid>
      <description>&lt;h2 id=&#34;-why-clinical-nlp--genai-are-growing-in-healthcare&#34;&gt;&#xA;  🚀 Why Clinical NLP &amp;amp; GenAI Are Growing in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-why-clinical-nlp--genai-are-growing-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Clinical NLP &amp;amp; GenAI are &lt;strong&gt;growing rapidly in healthcare&lt;/strong&gt; because they unlock massive &lt;strong&gt;untapped value in unstructured data&lt;/strong&gt; — which has historically been hard to use, yet contains the &lt;strong&gt;richest clinical context&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-80-of-clinical-data-is-unstructured&#34;&gt;&#xA;  1. 80% of Clinical Data is Unstructured&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-80-of-clinical-data-is-unstructured&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;EHRs are full of &lt;strong&gt;free-text clinical notes&lt;/strong&gt;, discharge summaries, radiology reports, operative notes, etc.&lt;/li&gt;&#xA;&lt;li&gt;Traditional models work well with structured data (ICD, labs), but &lt;strong&gt;miss context&lt;/strong&gt; like:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;“Patient denies chest pain”&lt;/li&gt;&#xA;&lt;li&gt;“Family history of diabetes”&lt;/li&gt;&#xA;&lt;li&gt;“Patient expressed concern about medication side effects”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;NLP allows us to extract &lt;strong&gt;clinical meaning&lt;/strong&gt; from this text and turn it into computable features.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
