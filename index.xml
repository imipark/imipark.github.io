<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI in Healthcare</title>
    <link>https://imipark.github.io/</link>
    <description>Recent content on AI in Healthcare</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Mar 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://imipark.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The AI Engineer Path – Scrimba</title>
      <link>https://imipark.github.io/posts/ai_engineer_path_toc/</link>
      <pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/posts/ai_engineer_path_toc/</guid>
      <description>&lt;h1 id=&#34;the-ai-engineer-path--scrimba&#34;&gt;&#xA;  The AI Engineer Path – Scrimba&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#the-ai-engineer-path--scrimba&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.coursera.org/specializations/ai-engineering#courses&#34;&gt;https://www.coursera.org/specializations/ai-engineering#courses&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;intro-to-ai-engineering-104-min&#34;&gt;&#xA;  Intro to AI Engineering (104 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#intro-to-ai-engineering-104-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Welcome to The AI Engineer Path!&lt;/li&gt;&#xA;&lt;li&gt;AI Engineering basics&lt;/li&gt;&#xA;&lt;li&gt;The code so far&lt;/li&gt;&#xA;&lt;li&gt;Polygon API sign-up &amp;amp; key&lt;/li&gt;&#xA;&lt;li&gt;Get an OpenAI API Key&lt;/li&gt;&#xA;&lt;li&gt;Overview of how the API works&lt;/li&gt;&#xA;&lt;li&gt;An API call: OpenAI dependency&lt;/li&gt;&#xA;&lt;li&gt;An API call: Instance and model&lt;/li&gt;&#xA;&lt;li&gt;An API call: The messages array&lt;/li&gt;&#xA;&lt;li&gt;A quick word about models&lt;/li&gt;&#xA;&lt;li&gt;Prompt Engineering and a challenge&lt;/li&gt;&#xA;&lt;li&gt;Adding AI to the App&lt;/li&gt;&#xA;&lt;li&gt;Tokens&lt;/li&gt;&#xA;&lt;li&gt;The OpenAI Playground&lt;/li&gt;&#xA;&lt;li&gt;Temperature&lt;/li&gt;&#xA;&lt;li&gt;The &amp;ldquo;Few Shot&amp;rdquo; Approach&lt;/li&gt;&#xA;&lt;li&gt;Adding Examples&lt;/li&gt;&#xA;&lt;li&gt;Stop Sequence&lt;/li&gt;&#xA;&lt;li&gt;Frequency and Presence Penalties&lt;/li&gt;&#xA;&lt;li&gt;Fine-tuning&lt;/li&gt;&#xA;&lt;li&gt;Creating Images with the DALL·E 3 API&lt;/li&gt;&#xA;&lt;li&gt;Intro to AI Safety&lt;/li&gt;&#xA;&lt;li&gt;Safety Best Practices&lt;/li&gt;&#xA;&lt;li&gt;Solo Project - PollyGlot&lt;/li&gt;&#xA;&lt;li&gt;You made it!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;deployment-50-min&#34;&gt;&#xA;  Deployment (50 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#deployment-50-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Learn secure &amp;amp; robust deployment strategies&lt;/li&gt;&#xA;&lt;li&gt;Create a Cloudflare worker&lt;/li&gt;&#xA;&lt;li&gt;Connect your worker to OpenAI&lt;/li&gt;&#xA;&lt;li&gt;Update client side data fetching&lt;/li&gt;&#xA;&lt;li&gt;Handle CORS and preflight requests&lt;/li&gt;&#xA;&lt;li&gt;OpenAI API requests &amp;amp; responses&lt;/li&gt;&#xA;&lt;li&gt;Create an AI Gateway&lt;/li&gt;&#xA;&lt;li&gt;Error handling&lt;/li&gt;&#xA;&lt;li&gt;Create &amp;amp; deploy the Polygon API worker&lt;/li&gt;&#xA;&lt;li&gt;Fetch the stock data&lt;/li&gt;&#xA;&lt;li&gt;Download files and push to GitHub&lt;/li&gt;&#xA;&lt;li&gt;Deploy your site with Cloudflare Pages&lt;/li&gt;&#xA;&lt;li&gt;Custom domains with Cloudflare&lt;/li&gt;&#xA;&lt;li&gt;Recap &amp;amp; next steps&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;open-source-models-33-min&#34;&gt;&#xA;  Open-source Models (33 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#open-source-models-33-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Open source vs closed source&lt;/li&gt;&#xA;&lt;li&gt;Intro To HuggingFace.js Inference&lt;/li&gt;&#xA;&lt;li&gt;Text To Speech With HuggingFace.js Inference&lt;/li&gt;&#xA;&lt;li&gt;Transforming Images with HuggingFace.js Inference&lt;/li&gt;&#xA;&lt;li&gt;AI Models In The Browser With Transformers.js&lt;/li&gt;&#xA;&lt;li&gt;Download and Run AI Models on Your Computer with Ollama&lt;/li&gt;&#xA;&lt;li&gt;Section Recap&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;embeddings-and-vector-databases-94-min&#34;&gt;&#xA;  Embeddings and Vector Databases (94 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#embeddings-and-vector-databases-94-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Your next big step in AI engineering&lt;/li&gt;&#xA;&lt;li&gt;What are embeddings?&lt;/li&gt;&#xA;&lt;li&gt;Set up environment variables&lt;/li&gt;&#xA;&lt;li&gt;Create an embedding&lt;/li&gt;&#xA;&lt;li&gt;Challenge: Pair text with embedding&lt;/li&gt;&#xA;&lt;li&gt;Vector databases&lt;/li&gt;&#xA;&lt;li&gt;Set up your vector database&lt;/li&gt;&#xA;&lt;li&gt;Store vector embeddings&lt;/li&gt;&#xA;&lt;li&gt;Semantic search&lt;/li&gt;&#xA;&lt;li&gt;Query embeddings using similarity search&lt;/li&gt;&#xA;&lt;li&gt;Create a conversational response using OpenAI&lt;/li&gt;&#xA;&lt;li&gt;Chunking text from documents&lt;/li&gt;&#xA;&lt;li&gt;Challenge: Split text, get vectors, insert into Supabase&lt;/li&gt;&#xA;&lt;li&gt;Error handling&lt;/li&gt;&#xA;&lt;li&gt;Query database and manage multiple matches&lt;/li&gt;&#xA;&lt;li&gt;AI chatbot proof of concept&lt;/li&gt;&#xA;&lt;li&gt;Retrieval-augmented generation (RAG)&lt;/li&gt;&#xA;&lt;li&gt;Solo Project: PopChoice&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;agents-117-min&#34;&gt;&#xA;  Agents (117 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#agents-117-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI Agent Intro&lt;/li&gt;&#xA;&lt;li&gt;Prompt Engineering 101&lt;/li&gt;&#xA;&lt;li&gt;Control Response Formats&lt;/li&gt;&#xA;&lt;li&gt;Zooming Out&lt;/li&gt;&#xA;&lt;li&gt;Agent Setup&lt;/li&gt;&#xA;&lt;li&gt;Introduction to ReAct prompting&lt;/li&gt;&#xA;&lt;li&gt;Build action functions&lt;/li&gt;&#xA;&lt;li&gt;Write ReAct prompt - part 1 - planning&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 2 - ReAct prompt&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 3 - how does the &amp;ldquo;loop&amp;rdquo; work?&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 4 - code setup&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 5 - Plan for parsing the response&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 6 - Parsing the Action&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 7 - Calling the function&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 8 - Housekeeping&lt;/li&gt;&#xA;&lt;li&gt;ReAct Agent - part 9 - Finally! The loop!&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - part 1 - Intro&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - part 2 - Demo day&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - part 3 - Tools&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 4 - Loop Logic&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 5 - Setup Challenge&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 6 - Tool Calls&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 7 - Pushing to messages&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 8 - Adding arguments&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Functions Agent - Part 9 - Automatic function calls&lt;/li&gt;&#xA;&lt;li&gt;Adding UI to agent - proof of concept&lt;/li&gt;&#xA;&lt;li&gt;Solo Project - AI Travel Agent&lt;/li&gt;&#xA;&lt;li&gt;Nice work!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;multimodality-62-min&#34;&gt;&#xA;  Multimodality (62 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#multimodality-62-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Introduction&lt;/li&gt;&#xA;&lt;li&gt;Generate original images from a text prompt&lt;/li&gt;&#xA;&lt;li&gt;Response formats&lt;/li&gt;&#xA;&lt;li&gt;Prompting for image generation&lt;/li&gt;&#xA;&lt;li&gt;Size, quality and style&lt;/li&gt;&#xA;&lt;li&gt;Editing images&lt;/li&gt;&#xA;&lt;li&gt;Image generation challenge&lt;/li&gt;&#xA;&lt;li&gt;Image generation challenge solution&lt;/li&gt;&#xA;&lt;li&gt;GPT-4 with Vision - Part 1&lt;/li&gt;&#xA;&lt;li&gt;GPT-4 with Vision - Part 2&lt;/li&gt;&#xA;&lt;li&gt;Image generation &amp;amp; Vision recap&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;openais-assistants-api-30-min&#34;&gt;&#xA;  OpenAI&amp;rsquo;s Assistants API (30 min)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#openais-assistants-api-30-min&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Introducing the Assistants API&lt;/li&gt;&#xA;&lt;li&gt;How OpenAI Assistants work&lt;/li&gt;&#xA;&lt;li&gt;Create an Assistant&lt;/li&gt;&#xA;&lt;li&gt;Create a thread and messages&lt;/li&gt;&#xA;&lt;li&gt;Running an Assistant&lt;/li&gt;&#xA;&lt;li&gt;Bring it all together&lt;/li&gt;&#xA;&lt;li&gt;More to explore&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>5 Steps Learning Template</title>
      <link>https://imipark.github.io/posts/5_steps_learning_template/</link>
      <pubDate>Tue, 25 Mar 2025 13:19:10 -0700</pubDate>
      <guid>https://imipark.github.io/posts/5_steps_learning_template/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;What&amp;rsquo;s the Problem?&#xA;&lt;em&gt;What is the issue, gap, or challenge this module/concept is trying to address?&lt;/em&gt;&#xA;→ &lt;strong&gt;Transition&lt;/strong&gt;: “So what if this problem exists?”&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Why Does It Matter?&#xA;&lt;em&gt;What are the real-world stakes or consequences of not solving this problem? Who or what is affected?&lt;/em&gt;&#xA;→ &lt;strong&gt;Transition&lt;/strong&gt;: “Given this urgency, what’s the smart way to tackle it?”&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;What’s the Core Idea?&#xA;&lt;em&gt;What is the central concept, structure, or strategy introduced to solve the problem?&lt;/em&gt;&#xA;→ &lt;strong&gt;Transition&lt;/strong&gt;: “Okay, so how would I actually &lt;em&gt;apply&lt;/em&gt; or &lt;em&gt;build&lt;/em&gt; this?”&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hugo Setup and Deploy</title>
      <link>https://imipark.github.io/posts/hugo-setup/</link>
      <pubDate>Thu, 20 Mar 2025 21:23:49 -0700</pubDate>
      <guid>https://imipark.github.io/posts/hugo-setup/</guid>
      <description>&lt;h1 id=&#34;-hugo--github-pages-setup-user-site&#34;&gt;&#xA;  🚀 Hugo + GitHub Pages Setup (User Site)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-hugo--github-pages-setup-user-site&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Minimal setup using &lt;code&gt;hugo-book&lt;/code&gt; theme inside a Conda environment, with GitHub Pages deployment.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-create-and-activate-conda-environment&#34;&gt;&#xA;  1. Create and Activate Conda Environment&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-create-and-activate-conda-environment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create -n hugo-env&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate hugo-env&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-install-hugo--create-hugo-site-with-hugo-book-theme&#34;&gt;&#xA;  2. Install Hugo &amp;amp; Create Hugo Site with &lt;code&gt;hugo-book&lt;/code&gt; Theme&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-install-hugo--create-hugo-site-with-hugo-book-theme&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Install Hugo&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install hugo         &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Or: brew install hugo&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Create Hugo site&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hugo new site hugo-site&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#04a5e5&#34;&gt;cd&lt;/span&gt; hugo-site&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Initialize git and add theme&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git init&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;3-configure-configtoml&#34;&gt;&#xA;  3. Configure &lt;code&gt;config.toml&lt;/code&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-configure-configtoml&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-toml&#34; data-lang=&#34;toml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;baseURL = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;https://your-username.github.io/&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;languageCode = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;en-us&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;title = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;My Hugo Site&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;theme = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;hugo-book&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[params]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookTheme = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;light&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookToC = &lt;span style=&#34;color:#fe640b&#34;&gt;true&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookCollapseSection = &lt;span style=&#34;color:#fe640b&#34;&gt;true&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  BookFlatSection = &lt;span style=&#34;color:#fe640b&#34;&gt;false&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[[menu.sidebar]]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Knowledge Graph&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  url = &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;/kg/&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  weight = &lt;span style=&#34;color:#fe640b&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;4-create-content-and-_indexmd-files&#34;&gt;&#xA;  4. Create Content and &lt;code&gt;_index.md&lt;/code&gt; Files&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#4-create-content-and-_indexmd-files&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Create directories and content&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p content/kg/topic1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;touch content/_index.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;touch content/kg/_index.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;touch content/kg/topic1/_index.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hugo new kg/topic1/intro.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;directory-structure&#34;&gt;&#xA;  Directory Structure&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#directory-structure&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;content/&#xA;├── _index.md&#xA;├── kg/&#xA;│   ├── _index.md&#xA;│   └── topic1/&#xA;│       ├── _index.md&#xA;│       └── intro.md&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;_indexmd-contents&#34;&gt;&#xA;  &lt;code&gt;_index.md&lt;/code&gt; contents&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#_indexmd-contents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;content/_index.md&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hugo Source Backup</title>
      <link>https://imipark.github.io/posts/hugo-source-backup/</link>
      <pubDate>Thu, 20 Mar 2025 21:23:49 -0700</pubDate>
      <guid>https://imipark.github.io/posts/hugo-source-backup/</guid>
      <description>&lt;h1 id=&#34;-hugo-source-backup&#34;&gt;&#xA;  🔒 Hugo Source Backup&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-hugo-source-backup&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide outlines how to back up your &lt;strong&gt;Hugo source files&lt;/strong&gt; (excluding the &lt;code&gt;public/&lt;/code&gt; folder) to a &lt;strong&gt;private GitHub repository&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-folder-structure&#34;&gt;&#xA;  📁 Folder Structure&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-folder-structure&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Typical Hugo project structure:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hugo-site/&#xA;├── archetypes/&#xA;├── content/&#xA;├── layouts/&#xA;├── static/&#xA;├── themes/&#xA;├── config.toml&#xA;├── public/           # &amp;lt;- This is ignored for source backup&#xA;└── backup.sh         # Backup script&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-1-create-a-private-github-repo&#34;&gt;&#xA;  ✅ 1. Create a Private GitHub Repo&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-1-create-a-private-github-repo&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Go to &lt;a href=&#34;https://github.com/new&#34;&gt;https://github.com/new&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Name it something like &lt;code&gt;hugo-source&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Set visibility to &lt;strong&gt;Private&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Don’t initialize with README or license&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-2-initialize-git-in-your-hugo-site-if-not-already&#34;&gt;&#xA;  ✅ 2. Initialize Git in Your Hugo Site (if not already)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-2-initialize-git-in-your-hugo-site-if-not-already&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git init&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git remote add origin https://github.com/&amp;lt;your-username&amp;gt;/hugo-source.git&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#04a5e5&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;public/&amp;#34;&lt;/span&gt; &amp;gt;&amp;gt; .gitignore&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-3-create-the-backup-script&#34;&gt;&#xA;  ✅ 3. Create the Backup Script&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-3-create-the-backup-script&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Create a file named &lt;code&gt;backup.sh&lt;/code&gt; in the root of your Hugo project:&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://imipark.github.io/ai-workflows/mlops/ai_cloud_comparision/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/mlops/ai_cloud_comparision/</guid>
      <description>&lt;h1 id=&#34;market-analysis-azure-vs-aws-for-aimlgenai&#34;&gt;&#xA;  Market Analysis: Azure vs AWS for AI/ML/GenAI&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#market-analysis-azure-vs-aws-for-aimlgenai&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Feature&lt;/th&gt;&#xA;          &lt;th&gt;Azure&lt;/th&gt;&#xA;          &lt;th&gt;AWS&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Market Share&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;~23%&lt;/td&gt;&#xA;          &lt;td&gt;~31% (still largest)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Enterprise Adoption&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Strong in healthcare, finance, gov (esp. with Microsoft 365/Teams/EHR ties)&lt;/td&gt;&#xA;          &lt;td&gt;Strong with startups, research, media, big tech&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;AI/ML Tools&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Azure Machine Learning, OpenAI on Azure, Synapse, Cognitive Services&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker, Bedrock, Comprehend, Rekognition&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;GenAI Integration&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🔥 Deep OpenAI partnership (GPT, Codex, DALL·E via Azure OpenAI Service)&lt;/td&gt;&#xA;          &lt;td&gt;Bedrock (Anthropic, Stability, Cohere), Titan (Amazon’s own)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Ease of Use&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;More integrated across MS ecosystem (Power BI, Excel, VS Code)&lt;/td&gt;&#xA;          &lt;td&gt;More flexible but often messier to set up&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Learning Curve&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Smoother onboarding if familiar with Microsoft tools&lt;/td&gt;&#xA;          &lt;td&gt;More customizable, but steeper learning curve&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Certifications&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Azure AI Engineer, Data Scientist, OpenAI Engineer (in preview)&lt;/td&gt;&#xA;          &lt;td&gt;AWS ML Specialty, Solutions Architect, Bedrock tracks&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://imipark.github.io/ai-workflows/mlops/clinical_nlp_genai/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/mlops/clinical_nlp_genai/</guid>
      <description>&lt;h1 id=&#34;-why-clinical-nlp--genai-are-growing-in-healthcare&#34;&gt;&#xA;  🚀 Why Clinical NLP &amp;amp; GenAI Are Growing in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-why-clinical-nlp--genai-are-growing-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Clinical NLP &amp;amp; GenAI are &lt;strong&gt;growing rapidly in healthcare&lt;/strong&gt; because they unlock massive &lt;strong&gt;untapped value in unstructured data&lt;/strong&gt; — which has historically been hard to use, yet contains the &lt;strong&gt;richest clinical context&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-1-80-of-clinical-data-is-unstructured&#34;&gt;&#xA;  🧠 1. 80% of Clinical Data is Unstructured&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-1-80-of-clinical-data-is-unstructured&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;EHRs are full of &lt;strong&gt;free-text clinical notes&lt;/strong&gt;, discharge summaries, radiology reports, operative notes, etc.&lt;/li&gt;&#xA;&lt;li&gt;Traditional models work well with structured data (ICD, labs), but &lt;strong&gt;miss context&lt;/strong&gt; like:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;“Patient denies chest pain”&lt;/li&gt;&#xA;&lt;li&gt;“Family history of diabetes”&lt;/li&gt;&#xA;&lt;li&gt;“Patient expressed concern about medication side effects”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;🧩 NLP allows us to extract &lt;strong&gt;clinical meaning&lt;/strong&gt; from this text and turn it into computable features.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day1_foundational_llm_text_generation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day1_foundational_llm_text_generation/</guid>
      <description>&lt;h1 id=&#34;day-1---foundational-llms--text-generation--cot-summary&#34;&gt;&#xA;  Day 1 - Foundational LLMs &amp;amp; Text Generation – CoT Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-1---foundational-llms--text-generation--cot-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;foundations-of-llms&#34;&gt;&#xA;  Foundations of LLMs&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#foundations-of-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-why-language-models-matter&#34;&gt;&#xA;  1. Why Language Models Matter&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-language-models-matter&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;need for understanding and generating human language&lt;/em&gt;. Traditional NLP systems were narrow, but Large Language Models (LLMs) offer general-purpose capabilities like translation, Q&amp;amp;A, and summarization—all without explicit task-specific programming.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ &lt;strong&gt;how do LLMs work under the hood?&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-what-powers-llms-the-transformer&#34;&gt;&#xA;  2. What Powers LLMs: The Transformer&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-powers-llms-the-transformer&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;The Transformer is the core architecture enabling LLMs. Unlike RNNs that process data sequentially, Transformers handle inputs in parallel using &lt;strong&gt;self-attention&lt;/strong&gt;, allowing them to model long-range dependencies more efficiently and scale training.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day1_prompt_engineering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day1_prompt_engineering/</guid>
      <description>&lt;h1 id=&#34;day-1--prompt-engineering--cot-summary&#34;&gt;&#xA;  Day 1 – Prompt Engineering – CoT Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-1--prompt-engineering--cot-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;introduction--prompting-fundamentals&#34;&gt;&#xA;  Introduction &amp;amp; Prompting Fundamentals&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction--prompting-fundamentals&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-why-prompt-engineering-matters&#34;&gt;&#xA;  1. Why Prompt Engineering Matters&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-prompt-engineering-matters&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;need for controlling LLM behavior&lt;/em&gt;. Although everyone can write prompts, crafting high-quality prompts is complex. The model, structure, tone, and context all affect the outcome. Prompt engineering is an iterative process requiring optimization and experimentation.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ &lt;strong&gt;how do we guide LLMs effectively without retraining them?&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day2_embeddings_vectordb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day2_embeddings_vectordb/</guid>
      <description>&lt;h1 id=&#34;day-2--embeddings--vector-databases--cot-summary&#34;&gt;&#xA;  Day 2 – Embeddings &amp;amp; Vector Databases – CoT Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-2--embeddings--vector-databases--cot-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-why-embeddings&#34;&gt;&#xA;  1. Why Embeddings?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We begin with the &lt;em&gt;core problem of representing diverse data types&lt;/em&gt;. Images, text, audio, and structured data all need to be compared, retrieved, and clustered. Embeddings map these into a shared vector space where similarity can be computed numerically.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ &lt;strong&gt;how can we measure and preserve semantic meaning across different data types?&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day3_generative_agents/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day3_generative_agents/</guid>
      <description>&lt;h1 id=&#34;day-3--generative-agents--cot-summary&#34;&gt;&#xA;  Day 3 – Generative Agents – CoT Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-3--generative-agents--cot-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-what-are-generative-agents&#34;&gt;&#xA;  1. What Are Generative Agents?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-what-are-generative-agents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;definition of agents&lt;/em&gt;—AI systems designed to achieve goals by perceiving their environment and taking actions using tools. Unlike static LLMs, generative agents combine models, tools, and orchestration to interact with the world dynamically.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ &lt;strong&gt;what components make these agents truly autonomous and intelligent?&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;2-agent-architecture-breakdown&#34;&gt;&#xA;  2. Agent Architecture Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-agent-architecture-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;An agent’s architecture includes:&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day4_domainspecific_llms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day4_domainspecific_llms/</guid>
      <description>&lt;h1 id=&#34;day-4--domain-specific-llms--cot-summary&#34;&gt;&#xA;  Day 4 – Domain-Specific LLMs – CoT Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-4--domain-specific-llms--cot-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-the-rise-of-specialized-llms&#34;&gt;&#xA;  1. The Rise of Specialized LLMs&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-the-rise-of-specialized-llms&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We start with the &lt;em&gt;evolution of LLMs&lt;/em&gt; from general-purpose to domain-specific tools. This shift was driven by challenges in fields like cybersecurity and medicine, where technical language and sensitive use cases demand more than general knowledge.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;→ &lt;strong&gt;why do general-purpose LLMs struggle in specialized domains?&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;seclm-and-cybersecurity&#34;&gt;&#xA;  SecLM and Cybersecurity&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#seclm-and-cybersecurity&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;2-the-challenges-in-cybersecurity&#34;&gt;&#xA;  2. The Challenges in Cybersecurity&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-the-challenges-in-cybersecurity&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Cybersecurity experts face three main issues: rapidly evolving threats, repetitive manual work (toil), and a shortage of skilled talent. These bottlenecks make it hard to keep up with modern security needs.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day5_mlops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/nlp-llm-genai/5-day-genai-google/day5_mlops/</guid>
      <description>&lt;h1 id=&#34;day-5--mlops-for-generative-ai--cot-summary&#34;&gt;&#xA;  Day 5 – MLOps for Generative AI – CoT Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#day-5--mlops-for-generative-ai--cot-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;&#xA;  1. Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The rise of &lt;strong&gt;foundation models&lt;/strong&gt; and &lt;strong&gt;generative AI (gen AI)&lt;/strong&gt; has brought a paradigm shift in how we build and deploy AI systems. From selecting architectures to managing prompts and grounding outputs in real data, traditional MLOps needs adaptation.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;So how do we evolve MLOps for this new generative world?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;2-what-are-devops-and-mlops&#34;&gt;&#xA;  2. What Are DevOps and MLOps?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-what-are-devops-and-mlops&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DevOps&lt;/strong&gt;: Automation + collaboration for software delivery (CI/CD, testing, reliability)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MLOps&lt;/strong&gt;: Adds ML-specific needs:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data validation&lt;/li&gt;&#xA;&lt;li&gt;Model evaluation&lt;/li&gt;&#xA;&lt;li&gt;Monitoring&lt;/li&gt;&#xA;&lt;li&gt;Experiment tracking&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;These core principles set the stage, but gen AI has unique needs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ch4 EHR</title>
      <link>https://imipark.github.io/healthcare-domain/learning/hands-on-healthcare-data/ch4_ehr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/learning/hands-on-healthcare-data/ch4_ehr/</guid>
      <description>&lt;h1 id=&#34;ch4-deep-dive--electronic-health-records-ehr---convsummary&#34;&gt;&#xA;  Ch4 Deep Dive – Electronic Health Records (EHR) - ConvSummary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ch4-deep-dive--electronic-health-records-ehr---convsummary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;-qa-style-logical-summary&#34;&gt;&#xA;  🔍 Q&amp;amp;A-Style Logical Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-qa-style-logical-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;q1-what-is-the-central-focus-of-chapter-4&#34;&gt;&#xA;  Q1: What is the central focus of Chapter 4?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q1-what-is-the-central-focus-of-chapter-4&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Chapter 4 focuses on working with electronic health record (EHR) data using the &lt;strong&gt;MIMIC-III&lt;/strong&gt; dataset, and explores &lt;strong&gt;medication harmonization&lt;/strong&gt; using SQL, Neo4j (property graph), and TypeDB (typed hypergraph).&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q2-what-makes-working-with-ehr-data-complex&#34;&gt;&#xA;  Q2: What makes working with EHR data complex?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q2-what-makes-working-with-ehr-data-complex&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;EHRs are &lt;strong&gt;highly structured&lt;/strong&gt; but vary between implementations.&lt;/li&gt;&#xA;&lt;li&gt;Data is often &lt;strong&gt;redundant, inconsistent, or missing&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Clinical context and domain knowledge are crucial for correct interpretation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;q3-why-was-medication-harmonization-chosen-as-the-use-case&#34;&gt;&#xA;  Q3: Why was &lt;strong&gt;medication harmonization&lt;/strong&gt; chosen as the use case?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#q3-why-was-medication-harmonization-chosen-as-the-use-case&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Because medications are objective and widely used in EHRs, but the &lt;strong&gt;same drug&lt;/strong&gt; can appear under multiple names or codes (e.g. NDCs). Harmonization is necessary to:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ch6 ML and Graph Analytics</title>
      <link>https://imipark.github.io/healthcare-domain/learning/hands-on-healthcare-data/ch6_graph_ml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/learning/hands-on-healthcare-data/ch6_graph_ml/</guid>
      <description>&lt;h1 id=&#34;ch6-machine-learning--graph-based-analytics---convsummary&#34;&gt;&#xA;  Ch6 Machine Learning &amp;amp; Graph-Based Analytics - ConvSummary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ch6-machine-learning--graph-based-analytics---convsummary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;part-1-qa-summary&#34;&gt;&#xA;  Part 1: Q&amp;amp;A Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#part-1-qa-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-what-is-the-difference-between-cleaning-harmonization-and-feature-engineering&#34;&gt;&#xA;  1. What is the difference between cleaning, harmonization, and feature engineering?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-what-is-the-difference-between-cleaning-harmonization-and-feature-engineering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cleaning&lt;/strong&gt;: Removing errors or inconsistencies in the raw data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Harmonization&lt;/strong&gt;: Mapping and aligning data semantically across datasets (e.g., converting NDC to RxNorm).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Feature Engineering&lt;/strong&gt;: Transforming data to fit the needs of specific algorithms or analysis (e.g., PCA, one-hot encoding).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-why-are-graphs-more-useful-for-harmonization-than-feature-engineering&#34;&gt;&#xA;  2. Why are graphs more useful for harmonization than feature engineering?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-why-are-graphs-more-useful-for-harmonization-than-feature-engineering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Graphs help link concepts across vocabularies, terminologies, or systems.&lt;/li&gt;&#xA;&lt;li&gt;Feature engineering tends to be model-specific and harder to generalize.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-what-are-the-downsides-of-repeating-cleaningharmonization-for-each-project&#34;&gt;&#xA;  3. What are the downsides of repeating cleaning/harmonization for each project?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-what-are-the-downsides-of-repeating-cleaningharmonization-for-each-project&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Redundancy: Same steps are repeated across projects.&lt;/li&gt;&#xA;&lt;li&gt;Inefficiency: Each team member duplicates similar work.&lt;/li&gt;&#xA;&lt;li&gt;Inconsistency: No central source of truth for processed data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;4-what-is-a-feature-store-and-how-does-it-help&#34;&gt;&#xA;  4. What is a feature store and how does it help?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#4-what-is-a-feature-store-and-how-does-it-help&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A &lt;strong&gt;feature store&lt;/strong&gt; centralizes reusable, preprocessed features.&lt;/li&gt;&#xA;&lt;li&gt;Helps reduce redundancy and promotes consistency.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;5-how-do-knowledge-graphs-improve-the-pipeline&#34;&gt;&#xA;  5. How do knowledge graphs improve the pipeline?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#5-how-do-knowledge-graphs-improve-the-pipeline&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data is cleaned and harmonized once at the graph level.&lt;/li&gt;&#xA;&lt;li&gt;All downstream users can reuse the harmonized view via queries or APIs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;6-what-assumptions-are-made-when-using-a-knowledge-graph&#34;&gt;&#xA;  6. What assumptions are made when using a knowledge graph?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#6-what-assumptions-are-made-when-using-a-knowledge-graph&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Patient-level data and terminology concepts are stored in the same graph.&lt;/li&gt;&#xA;&lt;li&gt;Nodes/edges are tagged with metadata (e.g., timestamps, source).&lt;/li&gt;&#xA;&lt;li&gt;The graph is a supergraph enabling subgraph extraction.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;7-what-are-graph-embeddings-and-why-are-they-useful&#34;&gt;&#xA;  7. What are graph embeddings and why are they useful?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#7-what-are-graph-embeddings-and-why-are-they-useful&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They convert graph structures into vectors usable in ML models.&lt;/li&gt;&#xA;&lt;li&gt;Enable pattern detection, similarity analysis, and deep learning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;8-what-is-node2vec&#34;&gt;&#xA;  8. What is &lt;code&gt;node2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#8-what-is-node2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Random walk-based graph embedding technique.&lt;/li&gt;&#xA;&lt;li&gt;Uses return (p) and in-out (q) parameters to tune graph walk.&lt;/li&gt;&#xA;&lt;li&gt;Captures homophily and structural equivalence.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;9-what-is-cui2vec&#34;&gt;&#xA;  9. What is &lt;code&gt;cui2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#9-what-is-cui2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Embeds UMLS CUIs based on co-occurrence in various RWD sources.&lt;/li&gt;&#xA;&lt;li&gt;Context-aware (claims, notes, publications).&lt;/li&gt;&#xA;&lt;li&gt;Useful for understanding concept similarity.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;10-what-is-med2vec&#34;&gt;&#xA;  10. What is &lt;code&gt;med2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#10-what-is-med2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Uses temporal sequence of medical events to create visit-based embeddings.&lt;/li&gt;&#xA;&lt;li&gt;Retains longitudinal context.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;11-what-is-snomed2vec&#34;&gt;&#xA;  11. What is &lt;code&gt;snomed2vec&lt;/code&gt;?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#11-what-is-snomed2vec&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Embeds SNOMED CT concepts using hierarchical and network-based methods.&lt;/li&gt;&#xA;&lt;li&gt;Includes alternatives like metapath2vec and Poincaré embeddings.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;12-what-are-some-challenges-with-pretrained-embeddings&#34;&gt;&#xA;  12. What are some challenges with pretrained embeddings?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#12-what-are-some-challenges-with-pretrained-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Risk of overfitting to training data domain (e.g., CMS claims).&lt;/li&gt;&#xA;&lt;li&gt;May not generalize well to other populations or use cases.&lt;/li&gt;&#xA;&lt;li&gt;Introduces extra model layer to maintain and tune.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;part-2-curriculum-style-breakdown-with-why&#34;&gt;&#xA;  Part 2: Curriculum-Style Breakdown with &amp;ldquo;Why&amp;rdquo;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#part-2-curriculum-style-breakdown-with-why&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-phase-1-understand-the-motivation&#34;&gt;&#xA;  🧭 Phase 1: Understand the Motivation&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-1-understand-the-motivation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Read and distinguish between cleaning, harmonization, and feature engineering.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Clarifies each pipeline component and prevents misuse of graphs for tasks like feature engineering.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-2-explore-pipeline-challenges&#34;&gt;&#xA;  🧱 Phase 2: Explore Pipeline Challenges&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-2-explore-pipeline-challenges&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Analyze Figures 6-6 to 6-9 on pipeline repetition and inefficiency.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Understand how lack of standardization leads to duplicated efforts.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-3-learn-about-feature-stores&#34;&gt;&#xA;  🧠 Phase 3: Learn about Feature Stores&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-3-learn-about-feature-stores&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Study how feature stores centralize and reuse engineered features.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Saves time, increases reproducibility, and reduces tech debt.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-4-integrate-knowledge-graphs&#34;&gt;&#xA;  🌐 Phase 4: Integrate Knowledge Graphs&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-4-integrate-knowledge-graphs&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Understand what goes into a knowledge graph (patient data + ontologies).&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Enables one-time harmonization per data source, allowing scalable reuse.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-5-explore-graph-embedding-techniques&#34;&gt;&#xA;  🧩 Phase 5: Explore Graph Embedding Techniques&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-5-explore-graph-embedding-techniques&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Implement &lt;code&gt;node2vec&lt;/code&gt; on a small graph.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Learn homophily vs structural equivalence, key for biomedical graph reasoning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-6-biomedical-concept-embeddings&#34;&gt;&#xA;  🧬 Phase 6: Biomedical Concept Embeddings&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-6-biomedical-concept-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Compare and contrast &lt;code&gt;cui2vec&lt;/code&gt;, &lt;code&gt;med2vec&lt;/code&gt;, and &lt;code&gt;snomed2vec&lt;/code&gt;.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Appreciate how embeddings differ by data type (temporal, co-occurrence, hierarchical).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-7-real-world-concerns-with-embeddings&#34;&gt;&#xA;  ⚠️ Phase 7: Real-World Concerns with Embeddings&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-7-real-world-concerns-with-embeddings&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Evaluate pretrained embeddings and consider limitations (overfitting, generalizability).&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Embeddings may look good on paper but can fail in new domains.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-phase-8-apply-to-your-use-case&#34;&gt;&#xA;  🔁 Phase 8: Apply to Your Use Case&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-phase-8-apply-to-your-use-case&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Pick a small real-world use case and simulate a pipeline using a knowledge graph and embedding.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Reinforces learning and identifies operational gaps in pipeline design.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Clinical Text Feature Extraction Using Dictionary-Based Filtering</title>
      <link>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/nlp_clinical_text/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/nlp_clinical_text/</guid>
      <description>&lt;h1 id=&#34;-clinical-text-feature-extraction-using-dictionary-based-filtering&#34;&gt;&#xA;  🧬 Clinical Text Feature Extraction Using Dictionary-Based Filtering&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-clinical-text-feature-extraction-using-dictionary-based-filtering&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide demonstrates a simplified approach for processing clinical text &lt;strong&gt;without removing PHI directly&lt;/strong&gt;. Instead, it &lt;strong&gt;extracts only medical terms&lt;/strong&gt; from a predefined dictionary (simulated knowledge graph), which &lt;strong&gt;passively excludes PHI&lt;/strong&gt; and enables downstream analyses.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-objective&#34;&gt;&#xA;  ✅ Objective&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-objective&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Extract &lt;strong&gt;present, positive mentions&lt;/strong&gt; of clinical concepts (e.g., diseases, symptoms, drugs).&lt;/li&gt;&#xA;&lt;li&gt;Avoid mentions that are &lt;strong&gt;negated&lt;/strong&gt; or refer to &lt;strong&gt;historical/family context&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Demonstrate the principle: &lt;strong&gt;&amp;ldquo;Keep only medical terms&amp;rdquo;&lt;/strong&gt; as an alternative to direct PHI removal.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-input-example&#34;&gt;&#xA;  🧾 Input Example&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-input-example&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Patient complains of chest pain. No signs of pneumonia. History of diabetes mellitus.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Prescribed metformin. Mother had breast cancer.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-procedure-overview&#34;&gt;&#xA;  🧠 Procedure Overview&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-procedure-overview&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Define a &lt;strong&gt;medical term dictionary&lt;/strong&gt; (simulating a knowledge graph).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Split the clinical note&lt;/strong&gt; into sentences.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ignore sentences&lt;/strong&gt; with negation or irrelevant context.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Match and extract terms&lt;/strong&gt; from the dictionary.&lt;/li&gt;&#xA;&lt;li&gt;Output &lt;strong&gt;structured features&lt;/strong&gt; for downstream use.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-code-implementation-python&#34;&gt;&#xA;  🧪 Code Implementation (Python)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-code-implementation-python&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#179299&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#fe640b&#34;&gt;re&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 1. Simulated clinical note&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clinical_note &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;Patient complains of chest pain. No signs of pneumonia. History of diabetes mellitus.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;Prescribed metformin. Mother had breast cancer.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 2. Simulated knowledge graph (medical term dictionary)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;medical_terms &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;chest pain&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;symptom&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;pneumonia&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;disease&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;diabetes mellitus&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;disease&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;metformin&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;drug&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;breast cancer&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;disease&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 3. Split into sentences&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sentences &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#d20f39&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;\.\s*&amp;#39;&lt;/span&gt;, clinical_note&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;strip())&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;features &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; []&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 4. Process each sentence&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8839ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentences:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sentence_lower &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; sentence&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;lower()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 5. Skip negated or historical context&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#8839ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;no &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;history of&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;mother had&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#8839ef&#34;&gt;continue&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 6. Match medical terms&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#8839ef&#34;&gt;for&lt;/span&gt; term &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; medical_terms:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#8839ef&#34;&gt;if&lt;/span&gt; term &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; sentence_lower:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            features&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;append({&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;term&amp;#34;&lt;/span&gt;: term,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;: medical_terms[term],&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;sentence&amp;#34;&lt;/span&gt;: sentence&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;strip()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            })&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# 7. Output extracted features&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8839ef&#34;&gt;for&lt;/span&gt; feature &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;in&lt;/span&gt; features:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#04a5e5&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#d20f39&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Found &lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;{&lt;/span&gt;feature[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#40a02b&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt; → &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;{&lt;/span&gt;feature[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;term&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#40a02b&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39; in: &lt;/span&gt;&lt;span style=&#34;color:#1e66f5&#34;&gt;\&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;{&lt;/span&gt;feature[&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;sentence&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#40a02b&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#1e66f5&#34;&gt;\&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-sample-output&#34;&gt;&#xA;  📤 Sample Output&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-sample-output&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Found symptom → &amp;#39;chest pain&amp;#39; in: &amp;#34;Patient complains of chest pain&amp;#34;&#xA;Found drug → &amp;#39;metformin&amp;#39; in: &amp;#34;Prescribed metformin&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary&#34;&gt;&#xA;  📌 Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;This method:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clinical Text Mining Pipeline (Steps 1–5)</title>
      <link>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/clinical_text_mining_pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/clinical_text_mining_pipeline/</guid>
      <description>&lt;h1 id=&#34;-clinical-text-mining-pipeline-steps-15&#34;&gt;&#xA;  🏥 Clinical Text Mining Pipeline (Steps 1–5)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-clinical-text-mining-pipeline-steps-15&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document outlines a high-level clinical text mining pipeline using knowledge graphs, NLP, and structured indexing. The goal is to extract, enrich, and analyze clinical concepts from raw EMR text.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-1-preprocessing-clinical-documents&#34;&gt;&#xA;  🧾 &lt;strong&gt;Step 1: Preprocessing Clinical Documents&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-1-preprocessing-clinical-documents&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; Prepare and normalize clinical notes for processing.&lt;br&gt;&#xA;&lt;strong&gt;Tools:&lt;/strong&gt; Text cleaning, sentence segmentation, tokenizer.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Example: Clean and split into sentences&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#179299&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#fe640b&#34;&gt;re&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clinical_note &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;Pt c/o chest pain. No signs of pneumonia. History of stroke. Prescribed metformin.&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sentences &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#d20f39&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#39;\.\s*&amp;#39;&lt;/span&gt;, clinical_note&lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;.&lt;/span&gt;lower())&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-2-extract-terms-using-knowledge-graph--nlp&#34;&gt;&#xA;  🧠 &lt;strong&gt;Step 2: Extract Terms Using Knowledge Graph + NLP&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-2-extract-terms-using-knowledge-graph--nlp&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; Identify medical terms using a knowledge graph and remove ambiguous, negated, or contextual mentions.&lt;br&gt;&#xA;&lt;strong&gt;Tools:&lt;/strong&gt; Knowledge Graph (e.g., UMLS), NegEx, ConText&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ethics in AI for Healthcare</title>
      <link>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/ethics_in_ai_healthcare_qna/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/ethics_in_ai_healthcare_qna/</guid>
      <description>&lt;h1 id=&#34;ethics-in-ai-for-healthcare-a-guided-qa-framework&#34;&gt;&#xA;  Ethics in AI for Healthcare: A Guided Q&amp;amp;A Framework&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ethics-in-ai-for-healthcare-a-guided-qa-framework&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document presents a structured chain-of-thought (CoT) using guiding questions and answers to understand ethical considerations in the development and deployment of AI in healthcare, based on Module 7 from the Stanford &amp;ldquo;Introduction to Clinical Data&amp;rdquo; course.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-why-is-ethics-important-in-the-context-of-ai-in-healthcare&#34;&gt;&#xA;  1. Why is ethics important in the context of AI in healthcare?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-why-is-ethics-important-in-the-context-of-ai-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Answer:&lt;/strong&gt;&lt;br&gt;&#xA;AI tools impact patients directly or indirectly, whether through their development (research) or their deployment (clinical practice). Each of these domains carries different ethical responsibilities that must be considered and governed carefully.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Healthcare Data Layers</title>
      <link>https://imipark.github.io/healthcare-domain/data/healthcare_layers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/data/healthcare_layers/</guid>
      <description>&lt;h1 id=&#34;healthcare-data-layers&#34;&gt;&#xA;  Healthcare Data Layers&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#healthcare-data-layers&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;1️⃣ Data Sources (Raw Data &amp;amp; Collection Level)&#xA;These are the foundational data sources used in healthcare analysis, originating from clinical trials, hospitals, insurance claims, and patient records.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Clinical Data (RCTs, EHR, OMOP, CDM)&lt;/strong&gt; – Structured, controlled, and often randomized data used for regulatory and research applications.&#xA;&lt;strong&gt;Real-World Data (RWD: EHR, Claims, Registries)&lt;/strong&gt; – Observational and confounded, requiring advanced causal inference methods to extract meaningful insights.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Healthcare Data Sources</title>
      <link>https://imipark.github.io/healthcare-domain/data/healthcare_sources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/data/healthcare_sources/</guid>
      <description>&lt;h1 id=&#34;healthcare-data-sources&#34;&gt;&#xA;  Healthcare Data Sources&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#healthcare-data-sources&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;phenotype-knowledgebase-phekb&#34;&gt;&#xA;  &lt;a href=&#34;https://www.phekb.org/&#34;&gt;Phenotype KnowledgeBase (PheKB)&lt;/a&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#phenotype-knowledgebase-phekb&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;:&lt;br&gt;&#xA;A collaborative portal for sharing and validating electronic phenotype definitions used in observational health research.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Tags&lt;/strong&gt;: &lt;code&gt;phenotyping&lt;/code&gt;, &lt;code&gt;EHR&lt;/code&gt;, &lt;code&gt;cohort definitions&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Standardized phenotype definitions for conditions like diabetes, asthma, etc.&lt;/li&gt;&#xA;&lt;li&gt;Sharing phenotype algorithms across institutions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;mimic-iv-medical-information-mart-for-intensive-care&#34;&gt;&#xA;  &lt;a href=&#34;https://physionet.org/content/mimiciv/&#34;&gt;MIMIC-IV (Medical Information Mart for Intensive Care)&lt;/a&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mimic-iv-medical-information-mart-for-intensive-care&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;:&lt;br&gt;&#xA;A large, publicly available critical care database containing de-identified health data from ICU patients at the Beth Israel Deaconess Medical Center.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Missing Data Scenarios in Healthcare Modeling</title>
      <link>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/missing_values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/missing_values/</guid>
      <description>&lt;h1 id=&#34;missing-data-scenarios-in-healthcare-modeling&#34;&gt;&#xA;  Missing Data Scenarios in Healthcare Modeling&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#missing-data-scenarios-in-healthcare-modeling&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-should-be-measured-but-wasnt&#34;&gt;&#xA;  1. Should Be Measured But Wasn’t&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-should-be-measured-but-wasnt&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: The value is expected but is missing due to random or procedural issues (e.g., lab error, missed test).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Technical Term&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;MCAR&lt;/strong&gt;: Missing Completely At Random&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MAR&lt;/strong&gt;: Missing At Random&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: A routine blood test wasn&amp;rsquo;t recorded because the sample was lost.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Impute (mean, median, or model-based).&lt;/li&gt;&#xA;&lt;li&gt;Add a missingness indicator variable (e.g., &lt;code&gt;var_missing = 1&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: The missingness is unrelated to the value itself, so estimation is relatively safe.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-mostly-zero-due-to-rare-occurrence&#34;&gt;&#xA;  2. Mostly Zero Due to Rare Occurrence&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-mostly-zero-due-to-rare-occurrence&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: Not truly missing — the value is &lt;strong&gt;zero or absent&lt;/strong&gt; for most patients because the condition/event is rare.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Technical Term&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Not Missing (No abbreviation needed)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: HIV diagnosis column is &lt;code&gt;0&lt;/code&gt; for most patients.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Do not impute&lt;/strong&gt; — the 0s are meaningful and reflect true absence.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: These are real values, and zeros carry clinical meaning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;3-deliberately-not-recorded&#34;&gt;&#xA;  3. Deliberately Not Recorded&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-deliberately-not-recorded&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: Clinician or system &lt;strong&gt;chooses not to record&lt;/strong&gt; a value based on context (e.g., patient clearly stable or too ill).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Technical Term&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;MNAR&lt;/strong&gt;: Missing Not At Random&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: Sodium level not tested because the patient was clearly stable.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Avoid imputation if possible — it may introduce bias.&lt;/li&gt;&#xA;&lt;li&gt;Use models that handle missingness natively (e.g., decision trees, XGBoost, LightGBM).&lt;/li&gt;&#xA;&lt;li&gt;Consider adding a missingness indicator.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: The missingness &lt;em&gt;depends on the unobserved value&lt;/em&gt; and may carry predictive signal.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;summary-table&#34;&gt;&#xA;  Summary Table&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#summary-table&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Case&lt;/th&gt;&#xA;          &lt;th&gt;Description&lt;/th&gt;&#xA;          &lt;th&gt;Abbreviation&lt;/th&gt;&#xA;          &lt;th&gt;Impute?&lt;/th&gt;&#xA;          &lt;th&gt;Extra Notes&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;Should be measured but wasn’t&lt;/td&gt;&#xA;          &lt;td&gt;MCAR / MAR&lt;/td&gt;&#xA;          &lt;td&gt;✅ Yes&lt;/td&gt;&#xA;          &lt;td&gt;Add indicator if signal is likely&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;Mostly zero (rare condition)&lt;/td&gt;&#xA;          &lt;td&gt;Not Missing&lt;/td&gt;&#xA;          &lt;td&gt;🚫 No&lt;/td&gt;&#xA;          &lt;td&gt;Keep as is — zeros are informative&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;          &lt;td&gt;Deliberately not recorded&lt;/td&gt;&#xA;          &lt;td&gt;MNAR&lt;/td&gt;&#xA;          &lt;td&gt;⚠️ Caution&lt;/td&gt;&#xA;          &lt;td&gt;Use native handling + possible indicator&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>OMOP vs. RLHF</title>
      <link>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/omop_vs_rlhf_comparison/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/omop_vs_rlhf_comparison/</guid>
      <description>&lt;h1 id=&#34;omop-vs-rlhf-a-side-by-side-comparison&#34;&gt;&#xA;  OMOP vs. RLHF: A Side-by-Side Comparison&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#omop-vs-rlhf-a-side-by-side-comparison&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document compares &lt;strong&gt;OMOP (Observational Medical Outcomes Partnership)&lt;/strong&gt; in healthcare with &lt;strong&gt;RLHF (Reinforcement Learning from Human Feedback)&lt;/strong&gt; in generative AI, focusing on their structures, purposes, and alignment with Learning Health System (LHS) principles.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary-table&#34;&gt;&#xA;  🔍 Summary Table&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary-table&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Aspect&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;OMOP (Healthcare)&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;RLHF (GenAI)&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Domain&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Clinical/healthcare data&lt;/td&gt;&#xA;          &lt;td&gt;Natural language modeling&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Purpose&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Standardize and structure real-world patient data for learning, analytics, and AI&lt;/td&gt;&#xA;          &lt;td&gt;Align AI model behavior with human preferences and values&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Core Process&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;ETL (Extract-Transform-Load) clinical data into a common format for analysis&lt;/td&gt;&#xA;          &lt;td&gt;Fine-tune a pretrained LLM using human-labeled preferences or rewards&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Data Source&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;EHRs, claims, labs, devices&lt;/td&gt;&#xA;          &lt;td&gt;Human judgments on AI-generated outputs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Feedback Type&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Structured medical events (diagnoses, drugs, labs, etc.)&lt;/td&gt;&#xA;          &lt;td&gt;Human preference signals on outputs (better/worse answers)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Learning Method&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Enables observational &amp;amp; causal learning from patient data&lt;/td&gt;&#xA;          &lt;td&gt;Reinforcement learning from ranked or scored examples&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Governance Layer&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Ethics via IRB, consent, privacy laws&lt;/td&gt;&#xA;          &lt;td&gt;Ethics via safety research, alignment goals, red-teaming&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Use in Feedback Loops&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;LHS uses OMOP to “learn from care to improve care”&lt;/td&gt;&#xA;          &lt;td&gt;RLHF uses feedback to “teach the model to behave better”&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-conceptual-analogy&#34;&gt;&#xA;  🔁 Conceptual Analogy&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-conceptual-analogy&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;OMOP + Learning Health System (LHS)&lt;/strong&gt; is to the health system&lt;br&gt;&#xA;as&lt;br&gt;&#xA;&lt;strong&gt;RLHF&lt;/strong&gt; is to a generative AI model.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Output-Action Pairing (OAP) Framework in Healthcare</title>
      <link>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/oap_framework_healthcare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/oap_framework_healthcare/</guid>
      <description>&lt;h1 id=&#34;-output-action-pairing-oap-framework-in-healthcare&#34;&gt;&#xA;  🧠 Output-Action Pairing (OAP) Framework in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-output-action-pairing-oap-framework-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide provides real-world examples of the Output-Action Pairing (OAP) framework: aligning machine learning model &lt;strong&gt;outputs&lt;/strong&gt; with &lt;strong&gt;concrete clinical actions&lt;/strong&gt; to improve care.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-oap-template&#34;&gt;&#xA;  📋 OAP Template&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-oap-template&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Output (Prediction)&lt;/th&gt;&#xA;          &lt;th&gt;Action Taken&lt;/th&gt;&#xA;          &lt;th&gt;Who Acts&lt;/th&gt;&#xA;          &lt;th&gt;Why It Helps&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;What the model predicts&lt;/td&gt;&#xA;          &lt;td&gt;The clinical step or decision triggered&lt;/td&gt;&#xA;          &lt;td&gt;The role/team responsible&lt;/td&gt;&#xA;          &lt;td&gt;How it improves outcomes or safety&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-real-world-examples&#34;&gt;&#xA;  ✅ Real-World Examples&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-real-world-examples&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-sepsis-prediction&#34;&gt;&#xA;  1. Sepsis Prediction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-sepsis-prediction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; High risk of sepsis in next 6 hours&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Alert care team, initiate fluids/labs/antibiotics&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Rapid response team (nurses + physicians)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Early treatment improves survival&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2-readmission-risk-score&#34;&gt;&#xA;  2. Readmission Risk Score&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-readmission-risk-score&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; 30% chance of readmission within 30 days&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Extra discharge planning, follow-up calls, medication check&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Care coordinator + pharmacist&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Reduces avoidable readmissions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;3-pneumothorax-detection-on-chest-x-ray&#34;&gt;&#xA;  3. Pneumothorax Detection on Chest X-ray&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-pneumothorax-detection-on-chest-x-ray&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; Pneumothorax detected&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Immediate flag to radiologist and ER for review&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Radiologist + ER team&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Enables life-saving chest tube intervention&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;4-covid-19-triage&#34;&gt;&#xA;  4. COVID-19 Triage&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#4-covid-19-triage&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; High risk of severe COVID progression&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; ICU evaluation, enhanced monitoring, begin treatment&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Hospitalist or ICU triage physician&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Allocates ICU resources effectively&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;5-fall-risk-in-hospital&#34;&gt;&#xA;  5. Fall Risk in Hospital&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#5-fall-risk-in-hospital&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; High fall risk during admission&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Enable fall precautions (alarms, sitter, etc.)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Nursing team&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Prevents injury and hospital complications&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;6-stroke-detection-via-ct&#34;&gt;&#xA;  6. Stroke Detection via CT&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#6-stroke-detection-via-ct&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output:&lt;/strong&gt; Acute stroke suspected on scan&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; Notify neurologist, activate stroke protocol (tPA window)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Who acts:&lt;/strong&gt; Radiologist + Stroke Response Team&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it helps:&lt;/strong&gt; Reduces time to brain-saving treatment&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary&#34;&gt;&#xA;  🔄 Summary&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The OAP framework ensures that ML predictions &lt;strong&gt;translate to action&lt;/strong&gt;, improving &lt;strong&gt;clinical relevance&lt;/strong&gt; and &lt;strong&gt;patient safety&lt;/strong&gt;. Every model in healthcare should answer:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Rule-Based Electronic Phenotyping Example: Type 2 Diabetes</title>
      <link>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/diabetes_phenotype_pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c2_clinical_data/diabetes_phenotype_pipeline/</guid>
      <description>&lt;h1 id=&#34;rule-based-electronic-phenotyping-example-type-2-diabetes&#34;&gt;&#xA;  Rule-Based Electronic Phenotyping Example: Type 2 Diabetes&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#rule-based-electronic-phenotyping-example-type-2-diabetes&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This notebook walks through the process of defining an &lt;strong&gt;electronic phenotype&lt;/strong&gt; using a &lt;strong&gt;rule-based&lt;/strong&gt; approach, with a focus on &lt;strong&gt;Type 2 Diabetes&lt;/strong&gt;. The pipeline includes concept mapping, multi-patient evaluation, and phenotype logic visualization.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-1-simulated-vocabulary-lookup-umls--omop&#34;&gt;&#xA;  🔹 Step 1: Simulated Vocabulary Lookup (UMLS / OMOP)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-1-simulated-vocabulary-lookup-umls--omop&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;We define the clinical concept (Type 2 Diabetes) using relevant ICD-10 and RxNorm codes.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#9ca0b0;font-style:italic&#34;&gt;# Simulated UMLS/OMOP vocab mapping&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;UMLS_LOOKUP &lt;span style=&#34;color:#04a5e5;font-weight:bold&#34;&gt;=&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;type2_diabetes&amp;#34;&lt;/span&gt;: {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;icd10&amp;#34;&lt;/span&gt;: {&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;E11.9&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;E11.65&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;E11.00&amp;#34;&lt;/span&gt;},&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;rxnorm&amp;#34;&lt;/span&gt;: {&lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;metformin&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#40a02b&#34;&gt;&amp;#34;insulin&amp;#34;&lt;/span&gt;},&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-step-2-multi-patient-phenotyping-logic&#34;&gt;&#xA;  🔹 Step 2: Multi-Patient Phenotyping Logic&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-step-2-multi-patient-phenotyping-logic&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Each patient is checked for:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tradeoffs in Machine Learning: Precision vs. Recall in Healthcare</title>
      <link>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/precision_vs_recall_in_healthcare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/healthcare-domain/learning/ai-in-healthcare/c3_ml_healthcare/precision_vs_recall_in_healthcare/</guid>
      <description>&lt;h1 id=&#34;tradeoffs-in-machine-learning-precision-vs-recall-in-healthcare&#34;&gt;&#xA;  Tradeoffs in Machine Learning: Precision vs. Recall in Healthcare&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#tradeoffs-in-machine-learning-precision-vs-recall-in-healthcare&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This guide summarizes two key scenarios in healthcare where we might prefer:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;High Precision but Lower Recall&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;High Recall but Lower Precision&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-high-precision-lower-recall&#34;&gt;&#xA;  (1) High Precision, Lower Recall&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-high-precision-lower-recall&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-when-to-use&#34;&gt;&#xA;  ✅ When to Use:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-when-to-use&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When &lt;strong&gt;false positives are costly or harmful&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;When &lt;strong&gt;resources are limited&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;In &lt;strong&gt;early screening/filtering stages&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-justification&#34;&gt;&#xA;  📌 Justification:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-justification&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You want to be &lt;strong&gt;very confident&lt;/strong&gt; before taking action.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Missing some real cases&lt;/strong&gt; is acceptable if &lt;strong&gt;wrongly flagging someone&lt;/strong&gt; leads to &lt;strong&gt;emotional, financial, or clinical harm&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-examples&#34;&gt;&#xA;  💡 Examples:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-examples&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Genetic Testing for Rare Diseases&lt;/strong&gt;: Only flag patients when you&amp;rsquo;re very sure. A false positive could cause unnecessary panic or life changes.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;ICU Bed Allocation&lt;/strong&gt;: If you only have 5 beds, you’d want to use them for patients who are most certainly critical.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Drug Discovery Pre-Screening&lt;/strong&gt;: Select molecules that are most likely to work, even if some potential candidates are missed.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2-high-recall-lower-precision&#34;&gt;&#xA;  (2) High Recall, Lower Precision&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-high-recall-lower-precision&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-when-to-use-1&#34;&gt;&#xA;  ✅ When to Use:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-when-to-use-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When &lt;strong&gt;missing a real case is dangerous&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;When &lt;strong&gt;early detection can improve outcomes&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;When &lt;strong&gt;follow-up tests or actions are safe and cheap&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-justification-1&#34;&gt;&#xA;  📌 Justification:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-justification-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It&amp;rsquo;s better to &lt;strong&gt;catch every possible case&lt;/strong&gt;, even if you have some false alarms.&lt;/li&gt;&#xA;&lt;li&gt;Especially important in &lt;strong&gt;serious or rapidly progressing conditions&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;-examples-1&#34;&gt;&#xA;  💡 Examples:&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-examples-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cancer Screening&lt;/strong&gt;: Better to flag more patients for follow-up than miss someone with early-stage cancer.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sepsis Prediction in ER&lt;/strong&gt;: Alerting the care team early—even with some false alarms—can save lives.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;COVID-19 Testing in High-Risk Areas&lt;/strong&gt;: Broad detection to prevent spread, even if some healthy people test positive.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-summary-table&#34;&gt;&#xA;  🧠 Summary Table&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-summary-table&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Scenario&lt;/th&gt;&#xA;          &lt;th&gt;Priority&lt;/th&gt;&#xA;          &lt;th&gt;Justification&lt;/th&gt;&#xA;          &lt;th&gt;Example&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;High Precision, Lower Recall&lt;/td&gt;&#xA;          &lt;td&gt;Precision 🟢&lt;/td&gt;&#xA;          &lt;td&gt;Avoid harm/cost from false positives&lt;/td&gt;&#xA;          &lt;td&gt;Genetic testing, ICU triage&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;High Recall, Lower Precision&lt;/td&gt;&#xA;          &lt;td&gt;Recall 🟢&lt;/td&gt;&#xA;          &lt;td&gt;Avoid missing critical or contagious conditions&lt;/td&gt;&#xA;          &lt;td&gt;Cancer screening, sepsis alert&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Transformer Attention: Full Conceptual Breakdown</title>
      <link>https://imipark.github.io/ai-workflows/nlp-llm-genai/transformer_attention_concepts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/nlp-llm-genai/transformer_attention_concepts/</guid>
      <description>&lt;h1 id=&#34;-transformer-attention-full-conceptual-breakdown&#34;&gt;&#xA;  🧠 Transformer Attention: Full Conceptual Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-transformer-attention-full-conceptual-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document summarizes an in-depth discussion on attention mechanisms in Transformers, with a special focus on vocabulary embeddings, Q/K/V matrices, and multi-head attention.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-1-understanding-the-self-attention-image&#34;&gt;&#xA;  📌 1. Understanding the Self-Attention Image&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-1-understanding-the-self-attention-image&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The image shows a &lt;strong&gt;single-head self-attention&lt;/strong&gt; computation.&lt;/li&gt;&#xA;&lt;li&gt;Each &lt;strong&gt;row&lt;/strong&gt; is a token (element) at a &lt;strong&gt;position&lt;/strong&gt;, with a feature vector (embedding).&lt;/li&gt;&#xA;&lt;li&gt;The &lt;strong&gt;attention weights&lt;/strong&gt; (left column) are used to compute a &lt;strong&gt;weighted sum&lt;/strong&gt; over these vectors.&lt;/li&gt;&#xA;&lt;li&gt;The final output vector is shown at the bottom — this is the attention output for one token.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-2-element-vs-position&#34;&gt;&#xA;  🔍 2. Element vs. Position&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-2-element-vs-position&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Element&lt;/strong&gt;: the actual word or token in the input sequence.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Position&lt;/strong&gt;: the index of the element in the sequence.&lt;/li&gt;&#xA;&lt;li&gt;Though tightly coupled (1:1), they are conceptually different.&lt;/li&gt;&#xA;&lt;li&gt;Transformers rely on &lt;strong&gt;positional encoding&lt;/strong&gt; to retain order, since attention alone is orderless.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-3-how-attention-scores-are-computed&#34;&gt;&#xA;  🤖 3. How Attention Scores Are Computed&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-3-how-attention-scores-are-computed&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Input embeddings X&lt;/strong&gt; are projected into:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding How to Use BERT&#39;s CLS Token for Classification</title>
      <link>https://imipark.github.io/ai-workflows/nlp-llm-genai/bert_cls_classification_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/nlp-llm-genai/bert_cls_classification_summary/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Date:&lt;/strong&gt; 2025-03-31&lt;/p&gt;&#xA;&lt;h2 id=&#34;-question&#34;&gt;&#xA;  ❓ Question&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-question&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;How can we use the &lt;code&gt;[CLS]&lt;/code&gt; token (i.e., &lt;code&gt;h_cls&lt;/code&gt;) from the last layer of BERT for classification tasks? Given that the BERT output has shape &lt;code&gt;[batch_size, sequence_length, hidden_size]&lt;/code&gt;, how is it valid to pass only &lt;code&gt;[batch_size, hidden_size]&lt;/code&gt; to a &lt;code&gt;nn.Linear(hidden_size, num_classes)&lt;/code&gt; without flattening the sequence? And why don&amp;rsquo;t we flatten the whole sequence — wouldn&amp;rsquo;t that destroy order?&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-answer&#34;&gt;&#xA;  ✅ Answer&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-answer&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-bert-output-and-the-cls-token&#34;&gt;&#xA;  🔹 BERT Output and the &lt;code&gt;[CLS]&lt;/code&gt; Token&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-bert-output-and-the-cls-token&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;BERT outputs a tensor of shape:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Self-Attention in Transformers: A Visual Breakdown</title>
      <link>https://imipark.github.io/ai-workflows/nlp-llm-genai/self_attention_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://imipark.github.io/ai-workflows/nlp-llm-genai/self_attention_summary/</guid>
      <description>&lt;h1 id=&#34;-understanding-self-attention-in-transformers-a-visual-breakdown&#34;&gt;&#xA;  🔍 Understanding Self-Attention in Transformers: A Visual Breakdown&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-understanding-self-attention-in-transformers-a-visual-breakdown&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This document summarizes key questions about self-attention, embedding vectors, positions, and the input matrix in Transformers — using the image you provided as the foundation.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-what-is-happening-in-the-diagram&#34;&gt;&#xA;  🧠 What Is Happening in the Diagram?&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-what-is-happening-in-the-diagram&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The figure shows how &lt;strong&gt;self-attention&lt;/strong&gt; computes the output for a specific position (&amp;ldquo;detection&amp;rdquo;) by:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Generating &lt;strong&gt;attention weights&lt;/strong&gt; between that position and &lt;strong&gt;all other positions&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Using those weights to compute a &lt;strong&gt;weighted sum&lt;/strong&gt; of the input feature vectors.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://imipark.github.io/images/attention.png&#34; alt=&#34;Self-Attention Diagram&#34; /&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
