[{"id":0,"href":"/healthcare_data/","title":"Healthcare Data","section":"","content":" 🔗 Healthcare Data Layers 📚 Healthcare Data Sources "},{"id":1,"href":"/healthcare_glossary/","title":"Healthcare Glossary","section":"","content":" Healthcare Glossary # Welcome to the Healthcare Glossary, a reference list of essential terms across clinical, regulatory, and AI healthcare domains.\nA # Adverse Event # An adverse event is any undesirable experience associated with the use of a medical product in a patient. These can be mild, moderate, or severe, and may or may not be caused by the product itself.\nTags: clinical, patient safety\nRelated: Side Effect, Complication\nI # Interoperability # The ability of different healthcare systems and software to exchange, interpret, and use data effectively. It is essential for integrated care across hospitals, labs, payers, and providers. Interoperability exists on multiple levels—foundational (basic exchange), structural (common formats like HL7, FHIR), semantic (shared vocabularies like SNOMED, LOINC), and organizational (policies and workflows that support smooth sharing).\n*Tags: data standards, health IT\n*Related: HL7, FHIR, SNOMED CT, Health Information Exchange\nT # Time of Event # Time of event refers to the specific point in time at which a defined event occurs in a clinical, observational, or healthcare setting.\nTags: temporal, clinical trials, causal inference *Related: Event Onset, Timestamp, Exposure Time\nS # Side Effect # A side effect is a secondary, typically undesirable effect of a drug or medical treatment that occurs along with the desired therapeutic effect.\nTags: pharmacology, patient safety\nRelated: Adverse Event, Drug Reaction\n"},{"id":2,"href":"/causal_reasoning/","title":"Causal Reasoning","section":"","content":" 🧠 Causal Inference (CI) = Statistical Science for Understanding Cause-Effect # 🔍 Core Goal: # To estimate the causal effect of one variable on another from data (e.g., does a treatment cause better outcomes?).\n🛠️ Key Characteristics: # Criteria Description 🔬 Scope Primarily focuses on estimating causal effects from observational or experimental data 📐 Typical Methods Propensity scores, matching, inverse probability weighting, instrumental variables, difference-in-differences, DAGs 📊 Data Tabular, typically structured (e.g., clinical trials, EHRs, economic datasets) 📦 Toolkits DoWhy, EconML, CausalML, R, Stata, Stan 🧠 Theoretical Backbone Judea Pearl’s framework (do-calculus, SCMs), Rubin\u0026rsquo;s Potential Outcomes 🎯 Common Use Cases Healthcare policy evaluation, drug effect estimation, A/B testing, economic policy modeling 🧑‍🔬 Audience Statisticians, epidemiologists, health economists, applied researchers 🤖 Causal AI = Intelligent Systems that Reason About and Use Causality # 🔍 Core Goal: # To build AI systems that can reason, plan, and generalize using causal understanding — beyond pure prediction.\n🛠️ Key Characteristics: # Criteria Description 🚀 Scope Broader — includes CI and building causal reasoning into AI agents, decision systems, simulations 🧰 Typical Methods Causal discovery, SCMs, counterfactual reasoning, causal reinforcement learning, causal representation learning 🌐 Data Includes structured, unstructured, time-series, multi-modal, even simulators 🧠 AI Tools Combines causal inference + ML + planning: Pyro, DoWhy, NeurIPS CausalBench, Causal Transformers 🧠 Emerging Work Counterfactual explanation for LLMs, causal structure in generative models, agent-based causal decision making 🌍 Common Use Cases Building agents that can plan, explain decisions, simulate alternate futures (e.g., clinical decision AI, industrial control) 🧑‍💻 Audience ML researchers, AI engineers, decision scientists, healthcare AI innovators 🧩 Summary Table # Feature Causal Inference Causal AI Focus Estimating causal effects Building AI systems that use causality Scope Narrower (effect estimation) Broader (reasoning, decision-making) Foundation Statistics, econometrics ML + CI + decision theory Tools R, DoWhy, EconML Pyro, causal RL, causal discovery Data Mostly structured Structured + unstructured + simulated Stage of maturity Established Emerging and research-heavy Example Estimating drug effect from EHRs Agent that plans treatment strategy 🔥 TL;DR # Causal Inference = rigorous estimation of causal effects (what happens if X → Y). Causal AI = systems that use causal knowledge to reason, plan, and act, often learning causality from data. "},{"id":3,"href":"/posts/","title":"Blog","section":"","content":"This is the blog index page. Here you\u0026rsquo;ll find all posts.\n"},{"id":4,"href":"/posts/ai_engineer_path_toc/","title":"The AI Engineer Path – Scrimba","section":"Blog","content":" The AI Engineer Path – Scrimba # https://www.coursera.org/specializations/ai-engineering#courses\nIntro to AI Engineering (104 min) # Welcome to The AI Engineer Path! AI Engineering basics The code so far Polygon API sign-up \u0026amp; key Get an OpenAI API Key Overview of how the API works An API call: OpenAI dependency An API call: Instance and model An API call: The messages array A quick word about models Prompt Engineering and a challenge Adding AI to the App Tokens The OpenAI Playground Temperature The \u0026ldquo;Few Shot\u0026rdquo; Approach Adding Examples Stop Sequence Frequency and Presence Penalties Fine-tuning Creating Images with the DALL·E 3 API Intro to AI Safety Safety Best Practices Solo Project - PollyGlot You made it! Deployment (50 min) # Learn secure \u0026amp; robust deployment strategies Create a Cloudflare worker Connect your worker to OpenAI Update client side data fetching Handle CORS and preflight requests OpenAI API requests \u0026amp; responses Create an AI Gateway Error handling Create \u0026amp; deploy the Polygon API worker Fetch the stock data Download files and push to GitHub Deploy your site with Cloudflare Pages Custom domains with Cloudflare Recap \u0026amp; next steps Open-source Models (33 min) # Open source vs closed source Intro To HuggingFace.js Inference Text To Speech With HuggingFace.js Inference Transforming Images with HuggingFace.js Inference AI Models In The Browser With Transformers.js Download and Run AI Models on Your Computer with Ollama Section Recap Embeddings and Vector Databases (94 min) # Your next big step in AI engineering What are embeddings? Set up environment variables Create an embedding Challenge: Pair text with embedding Vector databases Set up your vector database Store vector embeddings Semantic search Query embeddings using similarity search Create a conversational response using OpenAI Chunking text from documents Challenge: Split text, get vectors, insert into Supabase Error handling Query database and manage multiple matches AI chatbot proof of concept Retrieval-augmented generation (RAG) Solo Project: PopChoice Agents (117 min) # AI Agent Intro Prompt Engineering 101 Control Response Formats Zooming Out Agent Setup Introduction to ReAct prompting Build action functions Write ReAct prompt - part 1 - planning ReAct Agent - part 2 - ReAct prompt ReAct Agent - part 3 - how does the \u0026ldquo;loop\u0026rdquo; work? ReAct Agent - part 4 - code setup ReAct Agent - part 5 - Plan for parsing the response ReAct Agent - part 6 - Parsing the Action ReAct Agent - part 7 - Calling the function ReAct Agent - part 8 - Housekeeping ReAct Agent - part 9 - Finally! The loop! OpenAI Functions Agent - part 1 - Intro OpenAI Functions Agent - part 2 - Demo day OpenAI Functions Agent - part 3 - Tools OpenAI Functions Agent - Part 4 - Loop Logic OpenAI Functions Agent - Part 5 - Setup Challenge OpenAI Functions Agent - Part 6 - Tool Calls OpenAI Functions Agent - Part 7 - Pushing to messages OpenAI Functions Agent - Part 8 - Adding arguments OpenAI Functions Agent - Part 9 - Automatic function calls Adding UI to agent - proof of concept Solo Project - AI Travel Agent Nice work! Multimodality (62 min) # Introduction Generate original images from a text prompt Response formats Prompting for image generation Size, quality and style Editing images Image generation challenge Image generation challenge solution GPT-4 with Vision - Part 1 GPT-4 with Vision - Part 2 Image generation \u0026amp; Vision recap OpenAI\u0026rsquo;s Assistants API (30 min) # Introducing the Assistants API How OpenAI Assistants work Create an Assistant Create a thread and messages Running an Assistant Bring it all together More to explore "},{"id":5,"href":"/posts/5_steps_learning_template/","title":"5 Steps Learning Template","section":"Blog","content":" What\u0026rsquo;s the Problem? What is the issue, gap, or challenge this module/concept is trying to address? → Transition: “So what if this problem exists?”\nWhy Does It Matter? What are the real-world stakes or consequences of not solving this problem? Who or what is affected? → Transition: “Given this urgency, what’s the smart way to tackle it?”\nWhat’s the Core Idea? What is the central concept, structure, or strategy introduced to solve the problem? → Transition: “Okay, so how would I actually apply or build this?”\nHow Does It Work? How is the idea implemented in practice? What are the steps, inputs, mechanics, or workflows? Transition: “Where does this take us next? What does it enable?”\nWhat’s Next? How does this fit into the bigger picture? What future task, analysis, or module does it support or prepare for?\n"},{"id":6,"href":"/posts/hugo-setup/","title":"Hugo Setup and Deploy","section":"Blog","content":" 🚀 Hugo + GitHub Pages Setup (User Site) # Minimal setup using hugo-book theme inside a Conda environment, with GitHub Pages deployment.\n1. Create and Activate Conda Environment # conda create -n hugo-env conda activate hugo-env 2. Install Hugo \u0026amp; Create Hugo Site with hugo-book Theme # # Install Hugo sudo apt install hugo # Or: brew install hugo # Create Hugo site hugo new site hugo-site cd hugo-site # Initialize git and add theme git init git submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book 3. Configure config.toml # baseURL = \u0026#39;https://your-username.github.io/\u0026#39; languageCode = \u0026#39;en-us\u0026#39; title = \u0026#39;My Hugo Site\u0026#39; theme = \u0026#39;hugo-book\u0026#39; [params] BookTheme = \u0026#39;light\u0026#39; BookToC = true BookCollapseSection = true BookFlatSection = false [[menu.sidebar]] name = \u0026#34;Knowledge Graph\u0026#34; url = \u0026#34;/kg/\u0026#34; weight = 1 4. Create Content and _index.md Files # # Create directories and content mkdir -p content/kg/topic1 touch content/_index.md touch content/kg/_index.md touch content/kg/topic1/_index.md hugo new kg/topic1/intro.md Directory Structure # content/ ├── _index.md ├── kg/ │ ├── _index.md │ └── topic1/ │ ├── _index.md │ └── intro.md _index.md contents # content/_index.md\n--- title: \u0026#34;Home\u0026#34; --- content/kg/_index.md\n--- title: \u0026#34;Knowledge Graph\u0026#34; bookFlatSection: false bookCollapseSection: true --- content/kg/topic1/_index.md\n--- title: \u0026#34;Topic 1\u0026#34; --- 5. Create GitHub Repository # Create repo: your-username.github.io\n(Required for GitHub User Pages) 6. GitHub Deployment # a. Generate a Personal Access Token (PAT) # Visit: https://github.com/settings/tokens Create a classic token with repo scope b. Initial Deployment (One-Time) # hugo cd public git init git checkout -b main git remote add origin https://github.com/your-username/your-username.github.io.git git add . git commit -m \u0026#34;Initial deploy\u0026#34; git push -u origin main cd .. c. Create Auto Deploy Script # deploy.sh\n#!/bin/bash hugo -D \u0026amp;\u0026amp; cd public \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m \u0026#34;Updated site\u0026#34; \u0026amp;\u0026amp; git push origin main \u0026amp;\u0026amp; cd .. echo \u0026#34;✅ Deployment Complete!\u0026#34; Make executable:\nchmod +x deploy.sh Run anytime:\n./deploy.sh 7. Check Deployment # GitHub → Repository → Settings → Pages Source: main Folder: / (root) Live Site: https://your-username.github.io/ 8. Notes # _index.md files define sections and sidebar headings bookFlatSection = false preserves folder hierarchy bookCollapseSection = true enables collapsible sidebar hugo -D includes drafts when building "},{"id":7,"href":"/posts/hugo-source-backup/","title":"Hugo Source Backup","section":"Blog","content":" 🔒 Hugo Source Backup # This guide outlines how to back up your Hugo source files (excluding the public/ folder) to a private GitHub repository.\n📁 Folder Structure # Typical Hugo project structure:\nhugo-site/ ├── archetypes/ ├── content/ ├── layouts/ ├── static/ ├── themes/ ├── config.toml ├── public/ # \u0026lt;- This is ignored for source backup └── backup.sh # Backup script ✅ 1. Create a Private GitHub Repo # Go to https://github.com/new Name it something like hugo-source Set visibility to Private Don’t initialize with README or license ✅ 2. Initialize Git in Your Hugo Site (if not already) # git init git remote add origin https://github.com/\u0026lt;your-username\u0026gt;/hugo-source.git echo \u0026#34;public/\u0026#34; \u0026gt;\u0026gt; .gitignore ✅ 3. Create the Backup Script # Create a file named backup.sh in the root of your Hugo project:\n#!/bin/bash git add . git commit -m \u0026#34;🔒 Backup: $(date +\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;)\u0026#34; git push origin main echo \u0026#34;✅ Backup Complete!\u0026#34; Make it executable:\nchmod +x backup.sh ✅ 4. Use It! # To back up your source files:\n./backup.sh 📝 Notes # Only your source files are backed up. The public/ folder is excluded (it’s where the generated site lives). Combine with deploy.sh for full workflow automation. "},{"id":8,"href":"/ai_engineering/ai_cloud_comparision/","title":"Ai Cloud Comparision","section":"AI Engineering for Healthcare","content":" Market Analysis: Azure vs AWS for AI/ML/GenAI # Feature Azure AWS Market Share ~23% ~31% (still largest) Enterprise Adoption Strong in healthcare, finance, gov (esp. with Microsoft 365/Teams/EHR ties) Strong with startups, research, media, big tech AI/ML Tools Azure Machine Learning, OpenAI on Azure, Synapse, Cognitive Services SageMaker, Bedrock, Comprehend, Rekognition GenAI Integration 🔥 Deep OpenAI partnership (GPT, Codex, DALL·E via Azure OpenAI Service) Bedrock (Anthropic, Stability, Cohere), Titan (Amazon’s own) Ease of Use More integrated across MS ecosystem (Power BI, Excel, VS Code) More flexible but often messier to set up Learning Curve Smoother onboarding if familiar with Microsoft tools More customizable, but steeper learning curve Certifications Azure AI Engineer, Data Scientist, OpenAI Engineer (in preview) AWS ML Specialty, Solutions Architect, Bedrock tracks "},{"id":9,"href":"/healthcare_courses/course2_clinical_data/","title":"Course2 Clinical Data","section":"Healthcare Courses","content":" Course 2: Clinical Data \u0026ndash; 7 Modules # 🧭 Module 1: Asking and Answering Questions via Clinical Data Mining # 1. What\u0026rsquo;s the Problem?\nClinicians and researchers have important questions but lack a structured approach to answering them using clinical data.\n2. Why Does It Matter?\nWithout a systematic workflow, decisions may rely on anecdotal evidence or outdated knowledge, leading to suboptimal care.\n3. What\u0026rsquo;s the Core Idea?\nThe 4-step clinical data mining workflow: (1) Ask the right question → (2) Find suitable data → (3) Extract/transform data → (4) Analyze and iterate.\n4. How Does It Work?\nStart with a real clinical scenario, define inclusion/exclusion criteria, search EMRs using codes/tests, and compute outcomes. Use a timeline and patient-feature matrix to support decisions.\n5. What\u0026rsquo;s Next?\nThis foundation enables accurate data selection (Module 2), temporal modeling (Module 3), and building datasets (Module 4).\n🏥 Module 2: Data Available from Healthcare Systems # 1. What\u0026rsquo;s the Problem?\nHealthcare data is fragmented, inconsistently coded, and filled with biases and errors.\n2. Why Does It Matter?\nUsing flawed or incomplete data without understanding its origin can lead to misleading conclusions or unsafe decisions.\n3. What\u0026rsquo;s the Core Idea?\nCategorize and understand different healthcare data types, sources, and their limitations, including EMR, claims, registries, and patient-generated data.\n4. How Does It Work?\nStudy the roles of key actors (patients, providers, payers), structured vs. unstructured data types, and typical biases (selection, misclassification, incentives).\n5. What\u0026rsquo;s Next?\nProvides the context for building timelines (Module 3) and feature matrices (Module 4) while recognizing biases that need correction.\n🕰️ Module 3: Representing Time in Clinical Data # 1. What\u0026rsquo;s the Problem?\nMost databases don\u0026rsquo;t represent or reason well about time, yet clinical reasoning depends heavily on event timing.\n2. Why Does It Matter?\nIncorrect ordering or missing timestamps can invalidate exposure-outcome relationships and confuse chronic vs. acute processes.\n3. What\u0026rsquo;s the Core Idea?\nUse patient timelines and time-aware logic to represent, bin, and reason about clinical events over time.\n4. How Does It Work?\nDefine index times, use bins to aggregate events, calculate time-to-event, handle censoring, and test for non-stationarity.\n5. What\u0026rsquo;s Next?\nEstablishes the temporal framework needed for building structured datasets (Module 4) and modeling disease progression (Module 6).\n🧱 Module 4: Creating Analysis-Ready Datasets # 1. What\u0026rsquo;s the Problem?\nRaw timelines are complex and inconsistent — they can\u0026rsquo;t be directly used in analysis or machine learning.\n2. Why Does It Matter?\nPoor feature engineering or ignoring missingness leads to weak, biased, or uninterpretable models.\n3. What\u0026rsquo;s the Core Idea?\nBuild a patient-feature matrix by selecting, cleaning, imputing, and engineering features from structured/unstructured data.\n4. How Does It Work?\nStandardize features, reduce dimensionality, handle missingness with imputation or removal, and use domain knowledge or PCA to create meaningful features.\n5. What\u0026rsquo;s Next?\nFeeds directly into downstream modeling, classification (Module 6), and cohort identification with better interpretability.\n📄 Module 5: Handling Unstructured Data # 1. What\u0026rsquo;s the Problem?\nValuable clinical information is trapped in unstructured formats like notes, images, and signals.\n2. Why Does It Matter?\nFailing to extract this information limits your ability to detect key conditions, traits, or outcomes that are not coded elsewhere.\n3. What\u0026rsquo;s the Core Idea?\nUse text mining, signal processing, and image interpretation to turn unstructured data into usable features.\n4. How Does It Work?\nApply NLP (e.g., negation/context detection), use knowledge graphs for term recognition, and process signals/images with appropriate tools.\n5. What\u0026rsquo;s Next?\nEnhances the patient-feature matrix (Module 4) and improves phenotyping accuracy and completeness (Module 6).\n🧬 Module 6: Electronic Phenotyping # 1. What\u0026rsquo;s the Problem?\nIdentifying who truly has a disease or condition is challenging using only raw or coded data.\n2. Why Does It Matter?\nMisclassified patients lead to invalid cohorts, incorrect inferences, and flawed clinical decisions or model training.\n3. What\u0026rsquo;s the Core Idea?\nDefine phenotypes using rule-based or probabilistic methods to accurately identify conditions of interest.\n4. How Does It Work?\nUse inclusion/exclusion criteria (rule-based) or train classifiers (probabilistic) with anchors, weak labels, and features from Modules 4–5.\n5. What\u0026rsquo;s Next?\nEnables reliable cohort creation for clinical trials, observational studies, and AI/ML applications.\n⚖️ Module 7: Clinical Data Ethics # 1. What\u0026rsquo;s the Problem?\nUsing patient data without safeguards risks violating privacy, losing trust, and causing harm.\n2. Why Does It Matter?\nUnethical data use can lead to legal issues, exclusion of vulnerable groups, and poor public perception of healthcare AI.\n3. What\u0026rsquo;s the Core Idea?\nApply ethical frameworks like the Belmont Report and Learning Health System to govern data use, consent, and fairness.\n4. How Does It Work?\nEnsure de-identification, obtain proper consent (or waiver), handle return of results thoughtfully, and consider justice in access and outcomes.\n5. What\u0026rsquo;s Next?\nProvides ethical boundaries and practices for applying all previous modules responsibly in real-world systems.\n"},{"id":10,"href":"/healthcare_courses/course2_clinical_data/clinical_text_mining_pipeline/","title":"Clinical Text Mining Pipeline","section":"Course2 Clinical Data","content":" 🏥 Clinical Text Mining Pipeline (Steps 1–5) # This document outlines a high-level clinical text mining pipeline using knowledge graphs, NLP, and structured indexing. The goal is to extract, enrich, and analyze clinical concepts from raw EMR text.\n🧾 Step 1: Preprocessing Clinical Documents # Goal: Prepare and normalize clinical notes for processing.\nTools: Text cleaning, sentence segmentation, tokenizer.\n# Example: Clean and split into sentences import re clinical_note = \u0026#34;Pt c/o chest pain. No signs of pneumonia. History of stroke. Prescribed metformin.\u0026#34; sentences = re.split(r\u0026#39;\\.\\s*\u0026#39;, clinical_note.lower()) 🧠 Step 2: Extract Terms Using Knowledge Graph + NLP # Goal: Identify medical terms using a knowledge graph and remove ambiguous, negated, or contextual mentions.\nTools: Knowledge Graph (e.g., UMLS), NegEx, ConText\n# Simulated medical term dictionary (knowledge graph-based) medical_terms = {\u0026#34;chest pain\u0026#34;: \u0026#34;symptom\u0026#34;, \u0026#34;pneumonia\u0026#34;: \u0026#34;disease\u0026#34;, \u0026#34;stroke\u0026#34;: \u0026#34;disease\u0026#34;, \u0026#34;metformin\u0026#34;: \u0026#34;drug\u0026#34;} # Filtered sentences (simulate negation/context removal) filtered_mentions = [] for s in sentences: if \u0026#34;no \u0026#34; in s or \u0026#34;history of\u0026#34; in s: continue for term in medical_terms: if term in s: filtered_mentions.append(term) 🗂️ Step 3: Index Positive, Present Mentions # Goal: Store structured, filtered term mentions for later search.\nTools: JSON/DB-based indexing, storing patient-term mappings.\nindexed_mentions = [ {\u0026#34;patient_id\u0026#34;: 1, \u0026#34;term\u0026#34;: \u0026#34;chest pain\u0026#34;}, {\u0026#34;patient_id\u0026#34;: 1, \u0026#34;term\u0026#34;: \u0026#34;metformin\u0026#34;}, ] 🧭 Step 4: Query-Time Semantic Expansion # Goal: Expand the user’s query using KG (synonyms, variants, etc.) and disambiguate based on context.\nTools: Knowledge Graph (UMLS), synonym/semantic type lookup, optional filters\nquery = \u0026#34;stroke\u0026#34; expanded_terms = [\u0026#34;stroke\u0026#34;, \u0026#34;cva\u0026#34;, \u0026#34;cerebrovascular accident\u0026#34;] # Disambiguate (simplified) def is_valid(term, patient_age, season): return not (term == \u0026#34;heatstroke\u0026#34; and patient_age \u0026lt; 18 and season == \u0026#34;summer\u0026#34;) 📊 Step 5: Build Patient-Feature Matrix for Analysis # Goal: Aggregate term mentions per patient for cohort selection and modeling.\nTools: Pandas, matrix construction, temporal tagging\nfrom collections import defaultdict feature_matrix = defaultdict(lambda: {\u0026#34;stroke_mention\u0026#34;: 0}) patient_metadata = {1: {\u0026#34;age\u0026#34;: 65, \u0026#34;season\u0026#34;: \u0026#34;spring\u0026#34;}} for mention in indexed_mentions: pid = mention[\u0026#34;patient_id\u0026#34;] term = mention[\u0026#34;term\u0026#34;] if term in expanded_terms and is_valid(term, patient_metadata[pid][\u0026#34;age\u0026#34;], patient_metadata[pid][\u0026#34;season\u0026#34;]): feature_matrix[pid][\u0026#34;stroke_mention\u0026#34;] += 1 print(dict(feature_matrix)) ✅ Summary # Step Goal Tools 1 Clean \u0026amp; tokenize notes Regex, NLP 2 Extract clean medical terms KG, NegEx, filtering 3 Store structured mentions JSON, DB 4 Expand/interpret queries KG, synonyms, disambiguation 5 Analyze for research Patient-feature matrix, Pandas This modular pipeline separates data preparation from query-time flexibility, making it robust and reusable.\n"},{"id":11,"href":"/healthcare_courses/course2_clinical_data/diabetes_phenotype_pipeline/","title":"Diabetes Phenotype Pipeline","section":"Course2 Clinical Data","content":" Rule-Based Electronic Phenotyping Example: Type 2 Diabetes # This notebook walks through the process of defining an electronic phenotype using a rule-based approach, with a focus on Type 2 Diabetes. The pipeline includes concept mapping, multi-patient evaluation, and phenotype logic visualization.\n🔹 Step 1: Simulated Vocabulary Lookup (UMLS / OMOP) # We define the clinical concept (Type 2 Diabetes) using relevant ICD-10 and RxNorm codes.\n# Simulated UMLS/OMOP vocab mapping UMLS_LOOKUP = { \u0026#34;type2_diabetes\u0026#34;: { \u0026#34;icd10\u0026#34;: {\u0026#34;E11.9\u0026#34;, \u0026#34;E11.65\u0026#34;, \u0026#34;E11.00\u0026#34;}, \u0026#34;rxnorm\u0026#34;: {\u0026#34;metformin\u0026#34;, \u0026#34;insulin\u0026#34;}, } } 🔹 Step 2: Multi-Patient Phenotyping Logic # Each patient is checked for:\nPresence of ≥2 relevant ICD-10 codes Any matching diabetes-related medication (RxNorm) Start date of phenotype based on first matching code from typing import List, Dict, Set from datetime import datetime def has_required_codes(patient, valid_codes: Set[str], source_field: str, min_count=1) -\u0026gt; bool: return len([code for code in patient[source_field] if code in valid_codes]) \u0026gt;= min_count def find_start_date(patient, valid_codes: Set[str], code_dates: Dict[str, List[str]]) -\u0026gt; str: dates = [] for code in valid_codes: if code in code_dates: dates.extend(code_dates[code]) return min(dates) if dates else None def apply_phenotype_definition(patient, concept_map) -\u0026gt; Dict: icd_match = has_required_codes(patient, concept_map[\u0026#34;icd10\u0026#34;], \u0026#34;icd10_codes\u0026#34;, min_count=2) med_match = has_required_codes(patient, concept_map[\u0026#34;rxnorm\u0026#34;], \u0026#34;medications\u0026#34;) start_date = find_start_date(patient, concept_map[\u0026#34;icd10\u0026#34;] | concept_map[\u0026#34;rxnorm\u0026#34;], patient[\u0026#34;code_dates\u0026#34;]) return { \u0026#34;phenotype_positive\u0026#34;: icd_match and med_match, \u0026#34;has_diabetes_codes\u0026#34;: icd_match, \u0026#34;has_diabetes_med\u0026#34;: med_match, \u0026#34;start_date\u0026#34;: start_date } # Sample patient data (multiple patients) patients = [ { \u0026#34;id\u0026#34;: \u0026#34;P001\u0026#34;, \u0026#34;icd10_codes\u0026#34;: [\u0026#34;E11.9\u0026#34;, \u0026#34;E11.9\u0026#34;], \u0026#34;medications\u0026#34;: [\u0026#34;metformin\u0026#34;], \u0026#34;code_dates\u0026#34;: { \u0026#34;E11.9\u0026#34;: [\u0026#34;2023-01-01\u0026#34;, \u0026#34;2023-03-01\u0026#34;], \u0026#34;metformin\u0026#34;: [\u0026#34;2023-01-05\u0026#34;] } }, { \u0026#34;id\u0026#34;: \u0026#34;P002\u0026#34;, \u0026#34;icd10_codes\u0026#34;: [\u0026#34;I10\u0026#34;], # Hypertension only \u0026#34;medications\u0026#34;: [\u0026#34;lisinopril\u0026#34;], \u0026#34;code_dates\u0026#34;: { \u0026#34;I10\u0026#34;: [\u0026#34;2023-04-01\u0026#34;], \u0026#34;lisinopril\u0026#34;: [\u0026#34;2023-04-05\u0026#34;] } } ] # Apply phenotype to all results = {} for patient in patients: result = apply_phenotype_definition(patient, UMLS_LOOKUP[\u0026#34;type2_diabetes\u0026#34;]) results[patient[\u0026#34;id\u0026#34;]] = result # Show results for pid, res in results.items(): print(f\u0026#34;{pid}: {res}\u0026#34;) 🔹 Step 3: Phenotype Logic Flowchart # Below is a visual flowchart that shows the phenotype logic step-by-step.\nAlt text ✅ Summary # This markdown covers:\nRule-based phenotyping using ICD and RxNorm codes Handling multiple patients Simulated code-date structure Logical combination of conditions (AND logic) A visual diagram of the rule logic This framework can be expanded to:\nInclude real UMLS/OMOP lookups via API Support more complex logic (time gaps, lab thresholds) Incorporate chart-reviewed gold standards "},{"id":12,"href":"/healthcare_courses/course2_clinical_data/ethics_in_ai_healthcare_qna/","title":"Ethics in Ai Healthcare Qn A","section":"Course2 Clinical Data","content":" Ethics in AI for Healthcare: A Guided Q\u0026amp;A Framework # This document presents a structured chain-of-thought (CoT) using guiding questions and answers to understand ethical considerations in the development and deployment of AI in healthcare, based on Module 7 from the Stanford \u0026ldquo;Introduction to Clinical Data\u0026rdquo; course.\n1. Why is ethics important in the context of AI in healthcare? # Answer:\nAI tools impact patients directly or indirectly, whether through their development (research) or their deployment (clinical practice). Each of these domains carries different ethical responsibilities that must be considered and governed carefully.\n➡️ Leads to: Understanding the foundations of research ethics.\n2. How has the field of research ethics developed over time? # Answer:\nThrough responses to unethical practices (e.g., Tuskegee Study, Nazi experiments), a series of ethical frameworks and regulations emerged, including the Nuremberg Code, the Declaration of Helsinki, and most notably, the Belmont Report.\n➡️ Leads to: A deeper look into the Belmont Report and its enduring impact.\n3. What does the Belmont Report contribute to research ethics? # Answer:\nIt introduces three core principles:\nRespect for Persons: Informed consent and autonomy Beneficence: Minimize harm, maximize benefit Justice: Fair distribution of research benefits and burdens ➡️ Leads to: Applying these principles to modern AI data sources.\n4. Where does AI get its data, and what ethical concerns arise? # Answer:\nAI uses data from research repositories, clinical records, and even consumer devices. Ethical concerns include consent validity, privacy, data security, and the risk of underrepresenting vulnerable populations.\n➡️ Leads to: Addressing secondary uses of data and consent workarounds.\n5. How can researchers ethically use data collected for other purposes? # Answer:\nVia:\nQA exemptions Use of de-identified data IRB-approved waiver of consent\nThese methods are sometimes necessary but ethically controversial due to risks of eroding public trust. ➡️ Leads to: The ethical dilemma of returning individual results.\n6. Should researchers return results to participants? # Answer:\nIt depends. Options range from never returning results (to avoid harm/confusion) to always returning them (to respect autonomy). Most agree on a middle ground: only return results that are valid and actionable.\n➡️ Leads to: Examining systems where research and practice are merged—like a Learning Health System.\n7. What is a Learning Health System (LHS), and how does it relate to AI? # Answer:\nAn LHS continuously learns from clinical care data to improve outcomes. AI is central to this feedback loop, but it blurs the line between research and care, making traditional ethical boundaries harder to apply.\n➡️ Leads to: Rethinking ethical frameworks for hybrid systems like LHS.\n8. Is there an ethical model better suited for a Learning Health System? # Answer:\nYes. A proposed model includes duties to:\nRespect patients (via transparency, not just consent) Improve care (beneficence) Reduce inequality (justice) Engage both clinicians and patients in the learning process\nHowever, it lacks strict rules for handling trade-offs between these duties. Summary:\nEach principle in the Belmont Report supports the others. Respect enables informed choice, beneficence ensures that choice isn\u0026rsquo;t harmful, and justice guarantees fairness across all participants. As AI transforms healthcare, our ethical thinking must evolve accordingly.\n"},{"id":13,"href":"/healthcare_courses/course2_clinical_data/missing_values/","title":"Missing Values","section":"Course2 Clinical Data","content":" Missing Data Scenarios in Healthcare Modeling # 1. Should Be Measured But Wasn’t # Description: The value is expected but is missing due to random or procedural issues (e.g., lab error, missed test). Technical Term: MCAR: Missing Completely At Random MAR: Missing At Random Example: A routine blood test wasn\u0026rsquo;t recorded because the sample was lost. Strategy: Impute (mean, median, or model-based). Add a missingness indicator variable (e.g., var_missing = 1). Rationale: The missingness is unrelated to the value itself, so estimation is relatively safe. 2. Mostly Zero Due to Rare Occurrence # Description: Not truly missing — the value is zero or absent for most patients because the condition/event is rare. Technical Term: Not Missing (No abbreviation needed) Example: HIV diagnosis column is 0 for most patients. Strategy: Do not impute — the 0s are meaningful and reflect true absence. Rationale: These are real values, and zeros carry clinical meaning. 3. Deliberately Not Recorded # Description: Clinician or system chooses not to record a value based on context (e.g., patient clearly stable or too ill). Technical Term: MNAR: Missing Not At Random Example: Sodium level not tested because the patient was clearly stable. Strategy: Avoid imputation if possible — it may introduce bias. Use models that handle missingness natively (e.g., decision trees, XGBoost, LightGBM). Consider adding a missingness indicator. Rationale: The missingness depends on the unobserved value and may carry predictive signal. Summary Table # Case Description Abbreviation Impute? Extra Notes 1 Should be measured but wasn’t MCAR / MAR ✅ Yes Add indicator if signal is likely 2 Mostly zero (rare condition) Not Missing 🚫 No Keep as is — zeros are informative 3 Deliberately not recorded MNAR ⚠️ Caution Use native handling + possible indicator "},{"id":14,"href":"/healthcare_courses/course2_clinical_data/nlp_clinical_text/","title":"Nlp Clinical Text","section":"Course2 Clinical Data","content":" 🧬 Clinical Text Feature Extraction Using Dictionary-Based Filtering # This guide demonstrates a simplified approach for processing clinical text without removing PHI directly. Instead, it extracts only medical terms from a predefined dictionary (simulated knowledge graph), which passively excludes PHI and enables downstream analyses.\n✅ Objective # Extract present, positive mentions of clinical concepts (e.g., diseases, symptoms, drugs). Avoid mentions that are negated or refer to historical/family context. Demonstrate the principle: \u0026ldquo;Keep only medical terms\u0026rdquo; as an alternative to direct PHI removal. 🧾 Input Example # Patient complains of chest pain. No signs of pneumonia. History of diabetes mellitus. Prescribed metformin. Mother had breast cancer. 🧠 Procedure Overview # Define a medical term dictionary (simulating a knowledge graph). Split the clinical note into sentences. Ignore sentences with negation or irrelevant context. Match and extract terms from the dictionary. Output structured features for downstream use. 🧪 Code Implementation (Python) # import re # 1. Simulated clinical note clinical_note = \u0026#39;\u0026#39;\u0026#39; Patient complains of chest pain. No signs of pneumonia. History of diabetes mellitus. Prescribed metformin. Mother had breast cancer. \u0026#39;\u0026#39;\u0026#39; # 2. Simulated knowledge graph (medical term dictionary) medical_terms = { \u0026#34;chest pain\u0026#34;: \u0026#34;symptom\u0026#34;, \u0026#34;pneumonia\u0026#34;: \u0026#34;disease\u0026#34;, \u0026#34;diabetes mellitus\u0026#34;: \u0026#34;disease\u0026#34;, \u0026#34;metformin\u0026#34;: \u0026#34;drug\u0026#34;, \u0026#34;breast cancer\u0026#34;: \u0026#34;disease\u0026#34; } # 3. Split into sentences sentences = re.split(r\u0026#39;\\.\\s*\u0026#39;, clinical_note.strip()) features = [] # 4. Process each sentence for sentence in sentences: sentence_lower = sentence.lower() # 5. Skip negated or historical context if \u0026#34;no \u0026#34; in sentence_lower or \u0026#34;history of\u0026#34; in sentence_lower or \u0026#34;mother had\u0026#34; in sentence_lower: continue # 6. Match medical terms for term in medical_terms: if term in sentence_lower: features.append({ \u0026#34;term\u0026#34;: term, \u0026#34;type\u0026#34;: medical_terms[term], \u0026#34;sentence\u0026#34;: sentence.strip() }) # 7. Output extracted features for feature in features: print(f\u0026#34;Found {feature[\u0026#39;type\u0026#39;]} → \u0026#39;{feature[\u0026#39;term\u0026#39;]}\u0026#39; in: \\\u0026#34;{feature[\u0026#39;sentence\u0026#39;]}\\\u0026#34;\u0026#34;) 📤 Sample Output # Found symptom → \u0026#39;chest pain\u0026#39; in: \u0026#34;Patient complains of chest pain\u0026#34; Found drug → \u0026#39;metformin\u0026#39; in: \u0026#34;Prescribed metformin\u0026#34; 📌 Summary # This method:\nAvoids direct PHI detection Extracts useful clinical concepts only Can be adapted to larger vocabularies and real NLP tools (e.g., spaCy, scispaCy, NegEx) Perfect for research scenarios where structured clinical features are needed but full de-identification is too complex.\n"},{"id":15,"href":"/healthcare_courses/course2_clinical_data/omop_vs_rlhf_comparison/","title":"Omop vs Rlhf Comparison","section":"Course2 Clinical Data","content":" OMOP vs. RLHF: A Side-by-Side Comparison # This document compares OMOP (Observational Medical Outcomes Partnership) in healthcare with RLHF (Reinforcement Learning from Human Feedback) in generative AI, focusing on their structures, purposes, and alignment with Learning Health System (LHS) principles.\n🔍 Summary Table # Aspect OMOP (Healthcare) RLHF (GenAI) Domain Clinical/healthcare data Natural language modeling Purpose Standardize and structure real-world patient data for learning, analytics, and AI Align AI model behavior with human preferences and values Core Process ETL (Extract-Transform-Load) clinical data into a common format for analysis Fine-tune a pretrained LLM using human-labeled preferences or rewards Data Source EHRs, claims, labs, devices Human judgments on AI-generated outputs Feedback Type Structured medical events (diagnoses, drugs, labs, etc.) Human preference signals on outputs (better/worse answers) Learning Method Enables observational \u0026amp; causal learning from patient data Reinforcement learning from ranked or scored examples Governance Layer Ethics via IRB, consent, privacy laws Ethics via safety research, alignment goals, red-teaming Use in Feedback Loops LHS uses OMOP to “learn from care to improve care” RLHF uses feedback to “teach the model to behave better” 🔁 Conceptual Analogy # OMOP + Learning Health System (LHS) is to the health system\nas\nRLHF is to a generative AI model.\nIn both cases:\nData flows through a system Human-derived feedback loops guide improvement The system continuously adapts and aligns with user or patient needs 🧠 Key Takeaways # Both OMOP and RLHF are feedback-driven learning architectures grounded in human data. OMOP is part of an ecosystem (LHS) that feeds learning back into medical care. RLHF aligns generative models with human preferences through iterative fine-tuning. Each reflects a shift toward real-time, adaptive, ethically grounded learning. Would you like to extend this comparison with diagrams, code examples, or regulatory implications?\n"},{"id":16,"href":"/healthcare_courses/course3_ml_healthcare/","title":"Course3 Ml Healthcare","section":"Healthcare Courses","content":" 📘 Course 3: Fundamentals of Machine Learning for Healthcare # This course provides a foundational understanding of how machine learning (ML) is applied in the healthcare setting — from basic concepts to real-world considerations.\nModule 1: Why Machine Learning in Healthcare? # 📌 Motivation Explosion of digital health data Need for scalable decision support 🧠 Key Concepts ML can improve diagnostics, predictions, efficiency Everyone in healthcare should understand ML basics Module 2: ML Concepts and Principles # 🔍 Learning Types Supervised, Unsupervised, Reinforcement Learning 🧪 Model Training Input: Features and Labels Output: Predictions ⚖️ Overfitting vs. Underfitting Underfit = too simple Overfit = too specific Module 3: Deep Learning # 🧠 Neural Networks Layers of learning units (neurons) 🖼️ CNNs for Imaging Used in radiology and dermatology 📄 NLP in Healthcare Use of RNNs and Transformers for text like clinical notes Module 4: Evaluation Metrics # 📊 Key Metrics Accuracy, Precision, Recall, ROC-AUC, PR-AUC ⚠️ Confusion Matrix True/False Positives/Negatives 🔁 Class Imbalance Handling Resampling, stratified sampling, alternate metrics Module 5: Challenges in ML for Healthcare # ❗ Limitations Data quality issues Label noise Distribution shift ⚠️ Causation vs. Correlation ML finds patterns, not causes Module 6: Clinical Impact and Teamwork # 💡 OAP Framework Link model output to real clinical action 👥 Multidisciplinary Teams Clinicians, ML experts, ethicists, IT 🛠️ Deployment Considerations Interpretability, ethics, workflow integration "},{"id":17,"href":"/healthcare_courses/course3_ml_healthcare/precision_vs_recall_in_healthcare/","title":"Precision vs Recall in Healthcare","section":"Course3 Ml Healthcare","content":" Tradeoffs in Machine Learning: Precision vs. Recall in Healthcare # This guide summarizes two key scenarios in healthcare where we might prefer:\nHigh Precision but Lower Recall High Recall but Lower Precision (1) High Precision, Lower Recall # ✅ When to Use: # When false positives are costly or harmful When resources are limited In early screening/filtering stages 📌 Justification: # You want to be very confident before taking action. Missing some real cases is acceptable if wrongly flagging someone leads to emotional, financial, or clinical harm. 💡 Examples: # Genetic Testing for Rare Diseases: Only flag patients when you\u0026rsquo;re very sure. A false positive could cause unnecessary panic or life changes. ICU Bed Allocation: If you only have 5 beds, you’d want to use them for patients who are most certainly critical. Drug Discovery Pre-Screening: Select molecules that are most likely to work, even if some potential candidates are missed. (2) High Recall, Lower Precision # ✅ When to Use: # When missing a real case is dangerous When early detection can improve outcomes When follow-up tests or actions are safe and cheap 📌 Justification: # It\u0026rsquo;s better to catch every possible case, even if you have some false alarms. Especially important in serious or rapidly progressing conditions. 💡 Examples: # Cancer Screening: Better to flag more patients for follow-up than miss someone with early-stage cancer. Sepsis Prediction in ER: Alerting the care team early—even with some false alarms—can save lives. COVID-19 Testing in High-Risk Areas: Broad detection to prevent spread, even if some healthy people test positive. 🧠 Summary Table # Scenario Priority Justification Example High Precision, Lower Recall Precision 🟢 Avoid harm/cost from false positives Genetic testing, ICU triage High Recall, Lower Precision Recall 🟢 Avoid missing critical or contagious conditions Cancer screening, sepsis alert "},{"id":18,"href":"/healthcare_courses/course4_ai_evalulation/","title":"Course4 Ai Evalulation","section":"Healthcare Courses","content":" 📘 Course 4: Evaluations of AI Applications in Healthcare # This course teaches how to critically evaluate AI systems in healthcare — beyond technical metrics, with attention to clinical, ethical, and real-world dimensions.\nModule 1: AI in Healthcare # 🚀 Why AI Matters Enhances research, diagnosis, operations 📉 Current Gaps AI often evaluated on accuracy alone 🔗 Outcome-Action Pairing (OAP) Match model predictions with actionable steps Module 2: Evaluation Frameworks # ⚖️ Beyond Accuracy Clinical utility, feasibility, net benefit 🧩 OAP in Detail Who acts? What is the benefit? How soon? 🧼 Data Quality Bias, missingness, outdated practices Module 3: Deployment Pathways # 🧭 Four Phases Design \u0026amp; Development Evaluate \u0026amp; Validate Diffuse \u0026amp; Scale Monitor \u0026amp; Maintain 🛠️ Challenges Workflow fit, interoperability, performance drift Module 4: Bias and Fairness # ⚠️ Bias Types Historical, representation, measurement, aggregation ✅ Fairness Metrics Calibration, classification parity, anti-classification 🔍 Auditing and Reporting Use tools like MINIMAR and perform external validation Module 5: Regulatory and Ethical Landscape # 🧑‍⚖️ Regulatory Pathways FDA SaMD framework (Valid Association, Analytical, Clinical Validation) 🔁 Adaptive Models Require lifecycle monitoring (TPLC) 🌐 Global Views GDPR in EU, FDA in US, centralized innovation in China Best Ethical Practices # 🧠 Key Principles Define problems clearly Mitigate bias Report conflicts of interest Ensure transparency and stakeholder involvement "},{"id":19,"href":"/healthcare_courses/ai_healthcare_coursera/","title":"AI in Healthcare Specialization — Stanford","section":"Healthcare Courses","content":" AI in Healthcare Specialization — Stanford # Course 1/5: Introduction to Healthcare # Module 1: Overview of Health Care Systems and Key Challenges They Face # Learning Objectives # The Basic Structure of Health Care Systems # Video: Introduction Video: A Simple Interaction Between Providers and Patients Video: The Problem of Risk Video: Solving the Problem of Risk: Risk Pooling Video: Insurance and Intermediaries for Risk Pooling Video: Beyond Patients, Providers, and Intermediaries: Other Players in the Health Care System Video: Overview of the Types and Roles of Intermediaries Video: Overview of the Types and Roles of Providers Video: Providers and Levels of Care Three Key Challenges Facing Health Care Systems # Video: The Challenge of Rising Health Care Costs Video: The Challenges of Quality and Access Lessons for AI and Data # Module 2: Physicians, Physician Practices, and Physician Payment # Learning Objectives # Physician Practices # Video: Characteristics of Physician Practices Video: Physicians, Intermediaries, and Networks Physician Payment # Video: Fee for Service Payment Video: Procedure Codes and Diagnosis Codes Video: The Medicare Fee Schedule Video: Capitation Payment Systems: Overview and Structure Video: Capitation Payment Systems: Scope of Capitation Video: Episode-Based Payment Systems and Salary Systems Video: Risk Shifting in Physician Payment and Multi-Layered Physician Payment Arrangements Video: Incentives Created by Physician Payments Lessons for AI and Data # Module 3: Hospitals, Other Provider Organizations, and Related Payment Systems # Learning Objectives # Hospital Overview # Video: Basic Operations and Characteristics of Hospitals Video: How Hospitals Relate to Physicians and Intermediaries Hospital Payment # Video: Hospital Payment Methods: Charge Masters/FFS and Per Diem Video: Hospital Payment Methods: DRGs Video: Hospital Payment Methods: Global Budgets Video: Hospital Payment Topics: Payments for Inpatient vs Outpatient Services, Hospital vs Physician Payments; Charges and Payments Video: Risk and Incentives in Hospital Payment Non-Hospital Facilities # Video: Independent Facilities - Structure and Payment Health Care Systems and Larger Provider Organizations # Pay for Performance in Provider Payment # Providers and Electronic Records # Video: EMRs, EHRs, and PHRs Video: Providers, Provider Incentives, Data, and Tools Module 4: Intermediaries, Health Insurance Plans, and Health Care Financing # Learning Objectives # Intermediaries Overview # Video: Intermediaries and Their Goals Video: Intermediaries and the Broad Challenges Facing Health Care Systems Intermediary Approaches to Influencing Health Care Utilization and Spending # Video: Networks and Selective Contracting Video: Provider Payment Methods and Levels Video: Patient Cost Sharing Video: Utilization Review, Gatekeepers, and Other Methods of Directly Influencing Care Video: Coverage Decisions Video: Combinations and Tradeoffs Common Health Plan Designs # Video: Three Stereotypical Plan Designs: \u0026ldquo;Traditional,\u0026rdquo; HMO, and PPO Video: Some More Recent Trends in Plan Design Different Intermediaries Offering Health Care Coverage # Video: Public and Private Plans (and Employer-Provided Private Insurance in the U.S.) Video: The U.S. Medicare Program Video: The U.S. Medicaid Program Video: Intermediaries: Lessons for Innovators Lessons for AI and Data # Module 5: Health Care Products and Prescription Drugs, and Quality Measurement and Improvement # Learning Objectives # Health Care Product Regulation: Overview # Video: Health Care Products, Approvals, and Prescription Drugs Prescription Drug Regulation and Pricing # Video: Prescription Drug Approval Processes Video: Patents, Branded Drugs, and Generic Drugs Video: Patients, Insurance, Formularies, and Prescription Drugs Video: Intermediaries, Pharmacy Benefit Managers, Drug Prices, and Rebates Video: Products and Prescription Drugs Wrap-Up - Data and Opportunities for Innovation Quality Measurements and Improvements # Video: Quality of Care Overview and Key Organizing Concepts Video: Overview and Structural Quality Measures Video: Process Quality Measures Video: Outcome Quality Measures and Satisfaction Measures Module 6: Ethics # Overview of AI Applications in Healthcare Delivery and Ethical Issues Ethical Frameworks for Health Care and AI AI and Incentives in Health Care Delivery and Payment Structures More Examples of AI and Incentives in Health Care Delivery and Payment Structures Course 2/5: Introduction to Clinical Data # Module 1: Asking and Answering Questions via Clinical Data Mining # Learning Objectives # The Data Mining Workflow # Video: Real-Life Example Video: Example: Finding Similar Patients Video: Example: Estimating Risk Video: Putting Patient Data on Timeline Video: Revisit the Data Mining Workflow Steps Types of Research Questions # Video: Research Questions Suited for Clinical Data Video: Example: Making Decision to Treat Video: Properties That Make Answering a Research Question Useful Module 2: Data Available from Healthcare Systems # Learning Objectives # The Healthcare System # Video: Review of Key Entities and the Data They Collect Video: Actors with Different Interests Healthcare Data Types # Video: Common Data Types in Healthcare Video: Strengths and Weaknesses of Observational Data Sources of Biases and Error # Video: Bias and Error from the Healthcare System Perspective Video: Bias and Error of Exposures and Outcomes Video: How a Patient\u0026rsquo;s Exposure Might Be Misclassified Video: How a Patient\u0026rsquo;s Outcome Could Be Misclassified Healthcare Data Sources # Video: Electronic Medical Record Data Video: Claims Data Video: Pharmacy Video: Surveillance Datasets and Registries Video: Population Health Data Sets Video: A Framework to Assess If a Data Source Is Useful Module 3: Representing Time, and Timing of Events, for Clinical Data Mining # Learning Objectives # Healthcare Happens Over Time # Video: Introduction Video: Time, Timelines, Timescales, and Representations of Time Video: Timescale: Choosing the Relevant Units of Time Video: What Affects the Timescale Representation of Time # Video: Time Series and Non-Time Series Data Video: Order of Events Video: Implicit Representations of Time Video: Different Ways to Put Data in Bins Video: Timing of Exposures and Outcomes Data Change Over Time # Video: Clinical Processes Are Non-Stationary Module 4: Creating Analysis-Ready Datasets from Patient Timelines # Learning Objectives # Creating Features to Analyze # Video: Turning Clinical Data into Something You Can Analyze Video: Defining the Unit of Analysis Video: Using Features and the Presence of Features Video: How to Create Features from Structured Sources Video: Standardizing Features Video: Dealing with Too Many Features Missing Values # Video: The Origins of Missing Values Video: Dealing with Missing Values Video: Summary Recommendations for Missing Values Constructing New Features # Video: Examples of Engineered Features Video: When to Consider Engineered Features Video: Main Points About Creating Analysis-Ready Datasets Structured Knowledge Graphs # Video: What Exactly Is in a Knowledge Graph? Video: Important Knowledge Graphs Video: How to Choose a Knowledge Graph Module 5: Handling Unstructured Healthcare Data: Text, Images, Signals # Learning Objectives # Clinical Text # Video: The Value of Clinical Text Video: What Makes Clinical Text Difficult to Handle Video: Privacy and De-Identification Video: A Primer on Natural Language Processing Video: Practical Approach to Processing Clinical Text Video: Summary - Clinical Text Images # Video: Overview and Goals of Medical Imaging Video: Why Are Images Important? Video: What Are Images? Video: A Typical Image Management Process Video: Summary - Images Signals # Video: Overview of Biomedical Signals Video: Why Are Signals Important? Video: What Are Signals? Video: What Are the Major Issues with Using Signals? Video: Summary - Signals Module 6: Putting the Pieces Together: Electronic Phenotyping # Learning Objectives # Electronic Phenotyping # Video: Challenges in Electronic Phenotyping Video: Specifying an Electronic Phenotype Two Approaches to Phenotyping # Video: Rule-Based Electronic Phenotyping Video: Examples of Rule-Based Electronic Phenotype Definitions Video: Constructing a Rule-Based Phenotype Definition Video: Probabilistic Phenotyping Video: Approaches for Creating a Probabilistic Phenotype Definition Video: Software for Probabilistic Phenotype Definitions Module 7: Clinical Data Ethics # Learning Objectives # Research Ethics and AI # Video: Introduction to Research Ethics and AI Video: The Belmont Report: A Framework for Research Ethics Video: Ethical Issues in Data Sources for AI Video: Secondary Uses of Data Video: Return of Results Video: AI and The Learning Health System Video: Ethics Summary Course 3/5: Fundamentals of Machine Learning for Healthcare # Module 1: Why Machine Learning in Healthcare? # Learning Objectives # History of ML in Healthcare # Video: Why Machine Learning in Healthcare? Video: History of AI in Medicine The Magic of ML and Different Approaches # Video: Why Healthcare Needs Machine Learning Video: Machine Learning Magic Video: Machine Learning, Biostatistics, Programming Video: Can Machine Learning Solve Everything? Module 2: Concepts and Principles of Machine Learning in Healthcare Part 1 # Learning Objectives # Machine Learning Terms, Definitions, and Jargon How Machines Learn Supervised Machine Learning Approaches: Regression and the \u0026ldquo;No Free Lunch\u0026rdquo; Theorem Other Traditional Supervised Machine Learning Approaches Video: Support Vector Machine (SVM) Video: Unsupervised Machine Learning Module 3: Concepts and Principles of Machine Learning in Healthcare Part 2 # Learning Objectives # Introduction to Deep Learning and Neural Networks Important Concepts in DL Video: Deep Learning and Neural Networks Video: Cross Entropy Loss Video: Gradient Descent Video: Representing Unstructured Image and Text Data Types of NN and Applications Video: Convolutional Neural Networks Video: Natural Language Processing and Recurrent Neural Networks Video: The Transformer Architecture for Sequences Commonly Used and Advanced Neural Network Architectures Module 4: Evaluation and Metrics for Machine Learning in Healthcare # Learning Objectives # Critical Evaluation of Models and Strategies for Healthcare Applications Video: Introduction to Model Performance Evaluation Video: Overfitting and Underfitting Video: Strategies to Address Overfitting, Underfitting, and Introduction to Regularization Video: Statistical Approaches to Model Evaluation Important Metrics for Clinical Machine Learning Video: Receiver Operator and Precision Recall Curves as Evaluation Metrics Module 5: Strategies and Challenges in Machine Learning in Healthcare # Learning Objectives # Challenges and Strategies for Clinical ML Video: Introduction to Common Clinical Machine Learning Challenges Video: Utility of Causative Model Predictions Video: Context in Clinical Machine Learning Interpretability and Performance of ML Models in Healthcare Video: Intrinsic Interpretability Medical Data for ML Video: Medical Data Challenges in Machine Learning Part 1 Video: Medical Data Challenges in Machine Learning Part 2 Video: How Much Data Do We Need? Video: Retrospective Data in Medicine and \u0026ldquo;Shelf Life\u0026rdquo; for Data Video: Medical Data: Quality vs Quantity Module 6: Best Practices, Teams, and Launching Your Machine Learning Journey # Learning Objectives # Designing and Evaluating Clinical ML Applications Video: Clinical Utility and Output Action Pairing Video: Taking Action - Utilizing the OAP Framework Video: Building Multidisciplinary Teams for Clinical Machine Learning Video: Governance, Ethics, and Best Practices Human Factors in Clinical ML - From Job Displacement to Automation Bias Video: On Being Human in the Era of Clinical Machine Learning Video: Death by GPS and Other Lessons of Automation Bias Module 7: Foundation Models (Optional Content) # Video: Introduction to Foundation Models Video: Adapting to Technology Video: General AI and Emergent Behavior Video: How Foundation Models Work Video: Healthcare Use Cases for Text Data Video: Healthcare Use Cases for Non-textual Unstructured Data Video: Challenges and Pitfalls Video: Conclusion Course 4/5: Evaluations of AI Applications in Healthcare # Module 1: AI in Healthcare # Learning Objectives # AI in Healthcare Video: Learning Objectives Video: Common Definitions Video: Overview Video: Why AI is Needed in Healthcare Video: Examples of AI in Healthcare Growth of AI in Healthcare How to Know if an AI Model is Good Video: Questions Answered by AI Video: AI Output Video: Think Beyond Area Under the Curve Module 2: Evaluations of AI in Healthcare # Learning Objectives # A Framework for Evaluation Video: Stakeholders Video: Clinical Utility Outcome: Action Pairing, An Overview Video: Lead Time Video: Type of Action Clinical Utility Video: OAP Examples Video: Number Needed to Treat Video: Net Benefits Video: Decision Curves Feasibility Overview Video: Implementation Costs Video: Clinical Evaluation and Uptake Module 3: AI Deployment # Learning Objectives # AI Deployment Video: The Problem Video: Practical Questions Prior to Deployment Video: Deployment Pathway 1st Phase: Design and Development Video: Stakeholder Involvement Video: Data Type and Sources Video: Settings 2nd Phase: Evaluate and Validate Video: In Silico Evaluation Video: Net Utility \u0026amp; Work Capacity Product Validation Video: Statistical Validity Video: Care Integration, Silent Mode Video: Clinical Integration, Considerations Video: Technical Integration 3rd Phase: Deployment Modalities Continuous Monitoring and Maintenance Challenges of Deployment Video: Sepsis Example Module 4: Downstream Evaluations of AI in Healthcare: Bias and Fairness # Learning Objectives # Bias in AI Solutions Video: Real World Examples of AI Bias Types of Bias Video: Historical Bias Video: Representation Bias Video: Measurement Bias Video: Aggregation Bias Video: Evaluation Bias Video: Deployment Bias Algorithmic Fairness Video: Anti-classification Video: Parity Classification Video: Calibration Video: Applying Fairness Measures Lack of Transparency Video: Minimal Reporting Standards Downstream Evaluations Video: Opportunities and Challenges Module 5: The Regulatory Environment for AI in Healthcare # Learning Objectives # Overview Components of Regulation Video: International Definitions Used for Regulatory Purposes Video: Definition Statement \u0026amp; Risk Framework Clinical Evaluation Process Video: Valid Clinical Association Video: Analytical Evaluation Video: Clinical Evaluation Video: General Control FDA Application Video: de novo Notifications Video: Software Modification Product Approval Video: TPLC Video: Locked vs Adapted AI Solutions Video: Examples Video: Non-Regulated Products Global Environment Video: EU Regulations Video: Chinese Guidelines Video: OMB Guidelines Course 5/5: AI in Healthcare Capstone # Module 1: Getting Started, Phase 1: Data Collection # Reading: Introduction Reading: Phase 1: Data Collection Peer Review: Phase 1 Peer Review - Project 1 Peer Review: Phase 1 Peer Review - Project 2 Graded: Phase 1. Project 1 Graded: Phase 1. Project 2 Module 2: Phase 2: Model Training Part 1 # Reading: Phase 2: Model Training, Part 1 Peer Review: Phase 2 Peer Review - Project 1 Peer Review: Phase 2 Peer Review - Project 2 Graded: Phase 2. Project 1 Graded: Phase 2. Project 2 Module 3: Phase 3: Model Training Part 2 # Reading: Phase 3: Model Training, Part 2 Peer Review: Phase 3 Peer Review - Project 1 Peer Review: Phase 3 Peer Review - Project 2 Graded: Phase 3. Project 1 Graded: Phase 3. Project 2 Module 4: Phase 4: Model Evaluation # Reading: Phase 4: Model Evaluation Graded: Phase 4. Project 1 Graded: Phase 4. Project 2 Module 5: Phase 5: Model Deployment and Regulation, Wrap Up # Reading: Wrap Up Graded: Phase 5 "},{"id":20,"href":"/causal_reasoning/causal_ai/","title":"Causal AI","section":"Causal Reasoning","content":" Causal AI # "},{"id":21,"href":"/causal_reasoning/causal_inference/","title":"Causal Inference","section":"Causal Reasoning","content":" Causal Inference # "},{"id":22,"href":"/healthcare_data/healthcare_layers/","title":"Healthcare Data Layers","section":"Healthcare Data","content":" Healthcare Data Layers # 1️⃣ Data Sources (Raw Data \u0026amp; Collection Level) These are the foundational data sources used in healthcare analysis, originating from clinical trials, hospitals, insurance claims, and patient records.\nClinical Data (RCTs, EHR, OMOP, CDM) – Structured, controlled, and often randomized data used for regulatory and research applications. Real-World Data (RWD: EHR, Claims, Registries) – Observational and confounded, requiring advanced causal inference methods to extract meaningful insights.\n🔗 Relationship: Clinical Data is typically highly structured and standardized, whereas RWD is heterogeneous, requiring bias correction.\n2️⃣ Data Management \u0026amp; Standardization (Processing \u0026amp; Infrastructure Level) This layer ensures that raw clinical \u0026amp; real-world data are cleaned, structured, and made interoperable for analysis.\nHealthcare Informatics – The framework for data integration, ETL processes, standardization (OMOP, FHIR, CDMs), interoperability, and terminology mapping (SNOMED, LOINC, ICD).\n🔗 Relationship:\nHealthcare Informatics acts as a bridge between data collection (clinical \u0026amp; RWD) and analytics. Without informatics, AI models and statistical analyses would lack clean, structured, and standardized data. 3️⃣ Data Analytics \u0026amp; Decision Intelligence (AI \u0026amp; Statistical Analysis Level) This layer applies statistical, machine learning (ML), and deep learning (DL) models to structured and unstructured healthcare data for actionable insights.\nTraditional Data Science \u0026amp; Statistical Analysis (Used for both Clinical \u0026amp; RWD)\nBiostatistics, Bayesian Methods, Survival Analysis, Causal Inference (PSM, DAGs, DiD) Used to control bias, estimate treatment effects, and generate regulatory-grade evidence (RWE). AI in Healthcare (Machine Learning \u0026amp; Deep Learning Applications)\nSupervised Learning (Logistic Regression, Decision Trees, Random Forests) Deep Learning (CNNs, Transformers, NLP, Reinforcement Learning) Model Interpretability (SHAP, LIME) and AI Fairness (Bias Mitigation) 🔗 Relationship:\nAI \u0026amp; ML rely on structured, clean data (from Healthcare Informatics) and leverage Clinical Data \u0026amp; RWD to generate predictions and automate decision-making. Statistical analysis methods (causal inference, survival analysis) are critical for ensuring valid results before AI is applied. "},{"id":23,"href":"/healthcare_data/healthcare_sources/","title":"Healthcare Data Sources","section":"Healthcare Data","content":" Healthcare Data Sources # Phenotype KnowledgeBase (PheKB) # Description:\nA collaborative portal for sharing and validating electronic phenotype definitions used in observational health research.\nTags: phenotyping, EHR, cohort definitions\nUse Cases:\nStandardized phenotype definitions for conditions like diabetes, asthma, etc. Sharing phenotype algorithms across institutions MIMIC-IV (Medical Information Mart for Intensive Care) # Description:\nA large, publicly available critical care database containing de-identified health data from ICU patients at the Beth Israel Deaconess Medical Center.\nTags: ICU, de-identified data, clinical research\nUse Cases:\nPredictive modeling in critical care Benchmarking clinical algorithms Training deep learning models Access Requirements:\nRequires credentialed training and data use agreement via PhysioNet\nOHDSI / OMOP Common Data Model # Description:\nAn open community initiative and standard model for organizing observational health data across institutions and studies.\nTags: standardization, EHR, interoperability, CDM\nUse Cases:\nConverting disparate data sources into a consistent format Enabling federated analysis across healthcare systems Supporting tools like ATLAS for cohort building National COVID Cohort Collaborative (N3C) # Description:\nA centralized, secure platform for analyzing harmonized COVID-19 clinical data from dozens of healthcare providers across the US.\nTags: COVID-19, federated research, clinical data\nUse Cases:\nStudying disease trajectories and treatment effects Multisite analytics using harmonized EHR data Evaluating outcomes for long COVID Access Requirements:\nApplication and institutional affiliation required\nBioPortal # Description:\nA comprehensive repository of biomedical ontologies from the National Center for Biomedical Ontology.\nTags: ontologies, terminology, semantic web, linked data\nUse Cases:\nAccessing ontologies like SNOMED CT, ICD, LOINC, RxNorm Mapping data to standard vocabularies Enabling semantic interoperability Unified Medical Language System (UMLS) # Description:\nIntegrates over 200 biomedical vocabularies to support natural language processing, terminology mapping, and EHR data harmonization.\nTags: NLP, standard vocabularies, concept mapping\nUse Cases:\nLinking clinical terms to standard codes Enhancing search and retrieval in clinical systems Supporting NLP tools like MetaMap and cTAKES Access Requirements:\nFree license from NLM, requires annual agreement\nAphrodite # Description:\nAn R package developed by OHDSI that supports semi-supervised phenotype algorithm development using feature engineering and machine learning methods on OMOP Common Data Model (CDM) datasets.\nTags: phenotyping, machine learning, semi-supervised, OMOP, OHDSI\nUse Cases:\nRapid development of phenotype classifiers using imperfectly labeled data. Applying machine learning models to predict phenotypes based on structured EHR data. Feature extraction from OMOP CDM to support supervised or semi-supervised learning tasks. "},{"id":24,"href":"/ipark/","title":"Inhee Park, PhD - Resume","section":"","content":" "}]